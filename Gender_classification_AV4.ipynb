{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gender_classification_AV4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db-HpqFLSS-Y",
        "colab_type": "text"
      },
      "source": [
        "**Gender Prediction for E-Commerce** \n",
        "\n",
        "With the evolution of the information and communication technologies and the rapid growth of the Internet for the exchange and distribution of information, Electronic Commerce (e-commerce) has gained massive momentum globally, and attracted more and more worldwide users overcoming the time constraints and distance barriers.\n",
        "\n",
        "It is important to gain in-depth insights into e-commerce via data-driven analytics and identify the factors affecting product sales, the impact of characteristics of customers on their purchase habits.\n",
        "\n",
        "It is quite useful to understand the demand, habits, concern, perception, and interest of customers from the clue of genders for e-commerce companies. \n",
        "\n",
        "However, the genders of users are in general unavailable in e-commerce platforms. To address this gap the aim here is to predict the gender of e-commerce’s participants from their product viewing records.\n",
        "\n",
        "\n",
        "**Data Dictionary**\n",
        "\n",
        "**Train file**: \n",
        "\n",
        "CSV containing the product viewing data with gender as label\n",
        "\n",
        "\n",
        "<pre>\n",
        "Variable \t   Definition <br>\n",
        "session_id   Session ID <br>\n",
        "startTime\t   Start time of the session <br>\n",
        "endTime\t     End Time of the session <br>\n",
        "ProductList\t List of products viewed <br>\n",
        "gender\t     (Target) male/female <br>\n",
        "</pre>\n",
        "\n",
        "Product list contains list of products viewed by the user in the given session and it also contains the category, sub category, sub-sub category and the product all encoded and separated with a slash symbol. Each consecutive product is separated with a semicolon.\n",
        "\n",
        "**Test file**: <br> CSV containing sessions for which gender prediction is to be submitted\n",
        "\n",
        "<pre>\n",
        "Variable\t    Definition <br>\n",
        "session_id\t  Session ID <br>\n",
        "startTime\t    Start time of the session <br>\n",
        "endTime\t      End Time of the session <br>\n",
        "ProductList\t  List of products viewed <br>\n",
        "</pre>\n",
        "\n",
        "Submission file format\n",
        "\n",
        "<pre>\n",
        "Variable\t  Definition <br>\n",
        "session_id\tSession ID <br>\n",
        "gender\t    (Target) Male/Female \n",
        "</pre>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4amSuuUtVzTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "73307e6d-899d-4881-b892-705abba5f829"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsXe_YZ4Xbhv",
        "colab_type": "text"
      },
      "source": [
        "## Workbook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXDYuWl44pHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "import re\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXF9Cm7UXhO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Gender classification_AV3/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/Gender classification_AV3/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzj7QzlAblLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['IS_TRAIN'] = 1\n",
        "test['IS_TRAIN'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PQUhtfjXtV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat([train,test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fL085yuX9JB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns = [x.upper() for x in df.columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuLrhhZ1bybj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "30010bc4-00ed-458f-9536-da070326d3b4"
      },
      "source": [
        "df['IS_TRAIN'].value_counts()"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    10500\n",
              "0     4500\n",
              "Name: IS_TRAIN, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNXiYnVJ0ydz",
        "colab_type": "text"
      },
      "source": [
        "**Creating a product dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4MFS6r9U_6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "7cef58d5-b075-496a-f697-913b38621bad"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id</th>\n",
              "      <th>startTime</th>\n",
              "      <th>endTime</th>\n",
              "      <th>ProductList</th>\n",
              "      <th>gender</th>\n",
              "      <th>IS_TRAIN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u16159</td>\n",
              "      <td>15/12/14 18:11</td>\n",
              "      <td>15/12/14 18:12</td>\n",
              "      <td>A00002/B00003/C00006/D28435/;A00002/B00003/C00...</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u10253</td>\n",
              "      <td>16/12/14 14:35</td>\n",
              "      <td>16/12/14 14:41</td>\n",
              "      <td>A00001/B00009/C00031/D29404/;A00001/B00009/C00...</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u19037</td>\n",
              "      <td>01/12/14 15:58</td>\n",
              "      <td>01/12/14 15:58</td>\n",
              "      <td>A00002/B00001/C00020/D16944/</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u14556</td>\n",
              "      <td>23/11/14 2:57</td>\n",
              "      <td>23/11/14 3:00</td>\n",
              "      <td>A00002/B00004/C00018/D10284/;A00002/B00004/C00...</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>u24295</td>\n",
              "      <td>17/12/14 16:44</td>\n",
              "      <td>17/12/14 16:46</td>\n",
              "      <td>A00001/B00001/C00012/D30805/;A00001/B00001/C00...</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  session_id       startTime  ...  gender IS_TRAIN\n",
              "0     u16159  15/12/14 18:11  ...  female        1\n",
              "1     u10253  16/12/14 14:35  ...    male        1\n",
              "2     u19037  01/12/14 15:58  ...  female        1\n",
              "3     u14556   23/11/14 2:57  ...  female        1\n",
              "4     u24295  17/12/14 16:44  ...    male        1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N0u5iZzaLTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def product_list(df):\n",
        "  products = []\n",
        "\n",
        "  for e,i in enumerate(df['ProductList'].tolist()):\n",
        "    items = i.split(';')\n",
        "    products.extend(items)\n",
        "  return products\n",
        "\n",
        "products = product_list(train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9imJKFhcaxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def category_list(products):\n",
        "  \n",
        "  c1 = defaultdict(list)\n",
        "  c2 = defaultdict(list)\n",
        "  c3 = defaultdict(list)\n",
        "\n",
        "  for i in products:\n",
        "    value = i.split('/')\n",
        "    # print(value[0])\n",
        "    if value[1] not in c1[value[0]]:\n",
        "      c1[value[0]].append(value[1])\n",
        "    if value[2] not in c2[value[1]]:\n",
        "      c2[value[1]].append(value[2])\n",
        "    if value[3] not in c3[value[2]]:\n",
        "      c3[value[2]].append(value[3])   \n",
        "\n",
        "  return c1,c2,c3  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7JK8Bbucuzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c1,c2,c3 = category_list(products)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SkSNyZ8ddOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "1c0affb1-8171-4cd7-ce46-45ebbc9b4c6b"
      },
      "source": [
        "print('Number of categories', len(c1.keys()))\n",
        "print('Number of sub categories', len(c2.keys()))\n",
        "print('Number of sub sub categories',len(c3.keys()))\n"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of categories 11\n",
            "Number of sub categories 85\n",
            "Number of sub sub categories 360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZQScdDG0hKEO",
        "colab": {}
      },
      "source": [
        "def category_l3(c3):\n",
        "  c3_val = defaultdict(list)\n",
        "  for i in c3.keys():\n",
        "    c3_val[i] = len(c3[i])\n",
        "  return c3_val\n",
        "\n",
        "def category_l2(c2,c3_val):\n",
        "  c2_val = defaultdict(list)\n",
        "  for i in c2.keys():\n",
        "    count = 0\n",
        "    for j in c2[i]:\n",
        "      count += c3_val[j]\n",
        "    c2_val[i] = count\n",
        "  return c2_val\n",
        "\n",
        "def category_l1(c1, c2_val):\n",
        "  c1_val = defaultdict(list)\n",
        "  for i in c1.keys():\n",
        "    count = 0\n",
        "    for j in c1[i]:\n",
        "      count += c2_val[j]\n",
        "    c1_val[i] = count\n",
        "  return c1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpoXFlRugfz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c3_val = category_l3(c3)\n",
        "c2_val = category_l2(c2, c3_val)\n",
        "c1_val = category_l1(c1, c2_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjmmUQVkkSy8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "642ab716-c50b-453d-ee3a-1467405c9b8d"
      },
      "source": [
        "print(sum(c1_val.values()))"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR__Xdm2kYzB",
        "colab_type": "text"
      },
      "source": [
        "Including both training and test\n",
        "\n",
        "1. Total number of products available is 46998\n",
        "2. Number of categories 11\n",
        "3. Number of sub categories 86\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp42-nhkkxrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4bb77777-e48c-4e7b-98c5-adb8749ab93f"
      },
      "source": [
        "for i in c1.keys():\n",
        "  print('Number of sub categories in', i, len(c1[i]))"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sub categories in A00002 12\n",
            "Number of sub categories in A00001 8\n",
            "Number of sub categories in A00003 15\n",
            "Number of sub categories in A00004 3\n",
            "Number of sub categories in A00005 11\n",
            "Number of sub categories in A00006 10\n",
            "Number of sub categories in A00011 3\n",
            "Number of sub categories in A00007 5\n",
            "Number of sub categories in A00010 12\n",
            "Number of sub categories in A00008 2\n",
            "Number of sub categories in A00009 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cW7LJjFkPn2",
        "colab_type": "text"
      },
      "source": [
        "validating the above logic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3fWHXSJhbu0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "27c3cda4-04f8-4a25-8c9a-13874625c976"
      },
      "source": [
        "print(c1_val['A00008'])\n",
        "print(c2['B00029'], c2['B00043'])\n",
        "print(c2_val['B00029'], c2_val['B00043'])\n",
        "print(c3['C00144'], c3['C00088'], c3['C00143'])\n",
        "print(c3_val['C00144'], c3_val['C00088'], c3_val['C00143'])\n"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n",
            "['C00144', 'C00088'] ['C00143']\n",
            "19 12\n",
            "['D20717', 'D03029', 'D03030', 'D06539'] ['D21715', 'D05566', 'D02012', 'D18252', 'D14434', 'D18248', 'D06643', 'D18614', 'D01914', 'D01750', 'D34649', 'D05853', 'D01196', 'D01197', 'D05882'] ['D34503', 'D13109', 'D13116', 'D01199', 'D06536', 'D06537', 'D06538', 'D34494', 'D34495', 'D34496', 'D34500', 'D14732']\n",
            "4 15 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pld6ftSq1LNZ",
        "colab_type": "text"
      },
      "source": [
        "**Analysing the amount of time spent**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sww_X-RQ8gk7",
        "colab_type": "text"
      },
      "source": [
        "session_id is unique, ignore this feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-HXGTb-1W08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[['STARTTIME','ENDTIME']] = df[['STARTTIME','ENDTIME']].apply(pd.to_datetime, format = '%d/%m/%y %H:%M')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr3bDvLK1hvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['TIME_SPENT_MINS'] = (df['ENDTIME'] - df['STARTTIME']).dt.total_seconds()/60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQFRcTdj4HCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_datepart(df, fldname, drop=True):\n",
        "    fld = df[fldname]\n",
        "    if not np.issubdtype(fld.dtype, np.datetime64):\n",
        "        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
        "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
        "    for n in ('Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
        "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start'):\n",
        "        df[targ_pre+n] = getattr(fld.dt,n.lower())\n",
        "    # df[targ_pre+'Elapsed'] = fld.astype(np.int64) // 10**9\n",
        "    if drop: df.drop(fldname, axis=1, inplace=True)\n",
        "    df.columns = [x.upper() for x in df.columns]\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEPXcEdk38-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = add_datepart(df, 'STARTTIME', False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "big_wWw6VRpM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "fbd46456-213f-4dc7-be37-c74c81127370"
      },
      "source": [
        "df[df.select_dtypes(bool).columns].head()"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STARTTIMEIS_MONTH_END</th>\n",
              "      <th>STARTTIMEIS_MONTH_START</th>\n",
              "      <th>STARTTIMEIS_QUARTER_END</th>\n",
              "      <th>STARTTIMEIS_QUARTER_START</th>\n",
              "      <th>STARTTIMEIS_YEAR_END</th>\n",
              "      <th>STARTTIMEIS_YEAR_START</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   STARTTIMEIS_MONTH_END  ...  STARTTIMEIS_YEAR_START\n",
              "0                  False  ...                   False\n",
              "1                  False  ...                   False\n",
              "2                  False  ...                   False\n",
              "3                  False  ...                   False\n",
              "4                  False  ...                   False\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiPRaU5O7u0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[df.select_dtypes(bool).columns] = df[df.select_dtypes(bool).columns].astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNSfHWmxAwUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train['SESSION_HOUR']\n",
        "df['HOUR'] = df['STARTTIME'].dt.hour\n",
        "\n",
        "b = [-1,4,8,12,16,20,24]\n",
        "l = ['Late Night', 'Early Morning','Morning','Noon','Eve','Night']\n",
        "df['DAYTYPE'] = pd.cut(df['HOUR'], bins=b, labels=l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HLQcY-29OlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dayweek = df.groupby(['GENDER','STARTTIMEDAYOFWEEK']).agg({'SESSION_ID':'count'}).reset_index()\n",
        "dayweek.loc[(dayweek['GENDER']== 'female'),'PERCENTAGE'] = (dayweek['SESSION_ID'] / dayweek[dayweek['GENDER']=='female']['SESSION_ID'].sum())*100\n",
        "dayweek.loc[(dayweek['GENDER']== 'male'),'PERCENTAGE'] = (dayweek['SESSION_ID'] / dayweek[dayweek['GENDER']=='male']['SESSION_ID'].sum())*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcr5O_05CKIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "6d517b14-7bd7-4bcb-da04-2e3154386098"
      },
      "source": [
        "dayweek"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GENDER</th>\n",
              "      <th>STARTTIMEDAYOFWEEK</th>\n",
              "      <th>SESSION_ID</th>\n",
              "      <th>PERCENTAGE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>1538</td>\n",
              "      <td>18.774414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>1299</td>\n",
              "      <td>15.856934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>female</td>\n",
              "      <td>2</td>\n",
              "      <td>810</td>\n",
              "      <td>9.887695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>female</td>\n",
              "      <td>3</td>\n",
              "      <td>651</td>\n",
              "      <td>7.946777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>4</td>\n",
              "      <td>1510</td>\n",
              "      <td>18.432617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>female</td>\n",
              "      <td>5</td>\n",
              "      <td>1460</td>\n",
              "      <td>17.822266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>female</td>\n",
              "      <td>6</td>\n",
              "      <td>924</td>\n",
              "      <td>11.279297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>432</td>\n",
              "      <td>18.717504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>341</td>\n",
              "      <td>14.774697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>male</td>\n",
              "      <td>2</td>\n",
              "      <td>240</td>\n",
              "      <td>10.398614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>male</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>6.282496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>male</td>\n",
              "      <td>4</td>\n",
              "      <td>409</td>\n",
              "      <td>17.720971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>male</td>\n",
              "      <td>5</td>\n",
              "      <td>368</td>\n",
              "      <td>15.944541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>male</td>\n",
              "      <td>6</td>\n",
              "      <td>373</td>\n",
              "      <td>16.161179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    GENDER  STARTTIMEDAYOFWEEK  SESSION_ID  PERCENTAGE\n",
              "0   female                   0        1538   18.774414\n",
              "1   female                   1        1299   15.856934\n",
              "2   female                   2         810    9.887695\n",
              "3   female                   3         651    7.946777\n",
              "4   female                   4        1510   18.432617\n",
              "5   female                   5        1460   17.822266\n",
              "6   female                   6         924   11.279297\n",
              "7     male                   0         432   18.717504\n",
              "8     male                   1         341   14.774697\n",
              "9     male                   2         240   10.398614\n",
              "10    male                   3         145    6.282496\n",
              "11    male                   4         409   17.720971\n",
              "12    male                   5         368   15.944541\n",
              "13    male                   6         373   16.161179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAZH0MQEFXUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "daytype = df.groupby(['GENDER','HOUR']).agg({'SESSION_ID':'count'}).reset_index()\n",
        "daytype.loc[(daytype['GENDER']== 'female'),'PERCENTAGE'] = (daytype['SESSION_ID'] / daytype[daytype['GENDER']=='female']['SESSION_ID'].sum())*100\n",
        "daytype.loc[(daytype['GENDER']== 'male'),'PERCENTAGE'] = (daytype['SESSION_ID'] / daytype[daytype['GENDER']=='male']['SESSION_ID'].sum())*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYrRQWaXGpkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ca3f7fd-2a2a-49e2-bc04-4361a3320fd5"
      },
      "source": [
        "daytype"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GENDER</th>\n",
              "      <th>HOUR</th>\n",
              "      <th>SESSION_ID</th>\n",
              "      <th>PERCENTAGE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>98</td>\n",
              "      <td>1.196289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>0.598145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>female</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>0.231934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>female</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>0.280762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>0.195312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>female</td>\n",
              "      <td>5</td>\n",
              "      <td>34</td>\n",
              "      <td>0.415039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>female</td>\n",
              "      <td>6</td>\n",
              "      <td>58</td>\n",
              "      <td>0.708008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>female</td>\n",
              "      <td>7</td>\n",
              "      <td>166</td>\n",
              "      <td>2.026367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>female</td>\n",
              "      <td>8</td>\n",
              "      <td>483</td>\n",
              "      <td>5.895996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>female</td>\n",
              "      <td>9</td>\n",
              "      <td>623</td>\n",
              "      <td>7.604980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>female</td>\n",
              "      <td>10</td>\n",
              "      <td>668</td>\n",
              "      <td>8.154297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>female</td>\n",
              "      <td>11</td>\n",
              "      <td>569</td>\n",
              "      <td>6.945801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>female</td>\n",
              "      <td>12</td>\n",
              "      <td>485</td>\n",
              "      <td>5.920410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>female</td>\n",
              "      <td>13</td>\n",
              "      <td>588</td>\n",
              "      <td>7.177734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>female</td>\n",
              "      <td>14</td>\n",
              "      <td>644</td>\n",
              "      <td>7.861328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>female</td>\n",
              "      <td>15</td>\n",
              "      <td>646</td>\n",
              "      <td>7.885742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>female</td>\n",
              "      <td>16</td>\n",
              "      <td>533</td>\n",
              "      <td>6.506348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>female</td>\n",
              "      <td>17</td>\n",
              "      <td>274</td>\n",
              "      <td>3.344727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>female</td>\n",
              "      <td>18</td>\n",
              "      <td>254</td>\n",
              "      <td>3.100586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>female</td>\n",
              "      <td>19</td>\n",
              "      <td>343</td>\n",
              "      <td>4.187012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>female</td>\n",
              "      <td>20</td>\n",
              "      <td>520</td>\n",
              "      <td>6.347656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>female</td>\n",
              "      <td>21</td>\n",
              "      <td>452</td>\n",
              "      <td>5.517578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>female</td>\n",
              "      <td>22</td>\n",
              "      <td>405</td>\n",
              "      <td>4.943848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>female</td>\n",
              "      <td>23</td>\n",
              "      <td>242</td>\n",
              "      <td>2.954102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>2.166378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>0.779896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>male</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>0.736568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>male</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0.346620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>male</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0.606586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>male</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>0.563258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>male</td>\n",
              "      <td>6</td>\n",
              "      <td>17</td>\n",
              "      <td>0.736568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>male</td>\n",
              "      <td>7</td>\n",
              "      <td>70</td>\n",
              "      <td>3.032929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>male</td>\n",
              "      <td>8</td>\n",
              "      <td>71</td>\n",
              "      <td>3.076256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>male</td>\n",
              "      <td>9</td>\n",
              "      <td>125</td>\n",
              "      <td>5.415945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>male</td>\n",
              "      <td>10</td>\n",
              "      <td>132</td>\n",
              "      <td>5.719237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>male</td>\n",
              "      <td>11</td>\n",
              "      <td>172</td>\n",
              "      <td>7.452340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>male</td>\n",
              "      <td>12</td>\n",
              "      <td>121</td>\n",
              "      <td>5.242634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>male</td>\n",
              "      <td>13</td>\n",
              "      <td>118</td>\n",
              "      <td>5.112652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>male</td>\n",
              "      <td>14</td>\n",
              "      <td>135</td>\n",
              "      <td>5.849220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>146</td>\n",
              "      <td>6.325823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>male</td>\n",
              "      <td>16</td>\n",
              "      <td>137</td>\n",
              "      <td>5.935875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>male</td>\n",
              "      <td>17</td>\n",
              "      <td>101</td>\n",
              "      <td>4.376083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>male</td>\n",
              "      <td>18</td>\n",
              "      <td>106</td>\n",
              "      <td>4.592721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>male</td>\n",
              "      <td>19</td>\n",
              "      <td>149</td>\n",
              "      <td>6.455806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>male</td>\n",
              "      <td>20</td>\n",
              "      <td>197</td>\n",
              "      <td>8.535529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>male</td>\n",
              "      <td>21</td>\n",
              "      <td>181</td>\n",
              "      <td>7.842288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>male</td>\n",
              "      <td>22</td>\n",
              "      <td>119</td>\n",
              "      <td>5.155979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>male</td>\n",
              "      <td>23</td>\n",
              "      <td>91</td>\n",
              "      <td>3.942808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    GENDER  HOUR  SESSION_ID  PERCENTAGE\n",
              "0   female     0          98    1.196289\n",
              "1   female     1          49    0.598145\n",
              "2   female     2          19    0.231934\n",
              "3   female     3          23    0.280762\n",
              "4   female     4          16    0.195312\n",
              "5   female     5          34    0.415039\n",
              "6   female     6          58    0.708008\n",
              "7   female     7         166    2.026367\n",
              "8   female     8         483    5.895996\n",
              "9   female     9         623    7.604980\n",
              "10  female    10         668    8.154297\n",
              "11  female    11         569    6.945801\n",
              "12  female    12         485    5.920410\n",
              "13  female    13         588    7.177734\n",
              "14  female    14         644    7.861328\n",
              "15  female    15         646    7.885742\n",
              "16  female    16         533    6.506348\n",
              "17  female    17         274    3.344727\n",
              "18  female    18         254    3.100586\n",
              "19  female    19         343    4.187012\n",
              "20  female    20         520    6.347656\n",
              "21  female    21         452    5.517578\n",
              "22  female    22         405    4.943848\n",
              "23  female    23         242    2.954102\n",
              "24    male     0          50    2.166378\n",
              "25    male     1          18    0.779896\n",
              "26    male     2          17    0.736568\n",
              "27    male     3           8    0.346620\n",
              "28    male     4          14    0.606586\n",
              "29    male     5          13    0.563258\n",
              "30    male     6          17    0.736568\n",
              "31    male     7          70    3.032929\n",
              "32    male     8          71    3.076256\n",
              "33    male     9         125    5.415945\n",
              "34    male    10         132    5.719237\n",
              "35    male    11         172    7.452340\n",
              "36    male    12         121    5.242634\n",
              "37    male    13         118    5.112652\n",
              "38    male    14         135    5.849220\n",
              "39    male    15         146    6.325823\n",
              "40    male    16         137    5.935875\n",
              "41    male    17         101    4.376083\n",
              "42    male    18         106    4.592721\n",
              "43    male    19         149    6.455806\n",
              "44    male    20         197    8.535529\n",
              "45    male    21         181    7.842288\n",
              "46    male    22         119    5.155979\n",
              "47    male    23          91    3.942808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xW4UR8MJpxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "daytype1 = df.groupby(['GENDER','DAYTYPE']).agg({'SESSION_ID':'count'}).reset_index()\n",
        "daytype1.loc[(daytype1['GENDER']== 'female'),'PERCENTAGE'] = (daytype1['SESSION_ID'] / daytype1[daytype1['GENDER']=='female']['SESSION_ID'].sum())*100\n",
        "daytype1.loc[(daytype1['GENDER']== 'male'),'PERCENTAGE'] = (daytype1['SESSION_ID'] / daytype1[daytype1['GENDER']=='male']['SESSION_ID'].sum())*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r07BVMwJ899",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "4290fdf5-aa66-4620-ce63-c4181328ac1c"
      },
      "source": [
        "daytype1"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GENDER</th>\n",
              "      <th>DAYTYPE</th>\n",
              "      <th>SESSION_ID</th>\n",
              "      <th>PERCENTAGE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>female</td>\n",
              "      <td>Late Night</td>\n",
              "      <td>205</td>\n",
              "      <td>2.502441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>Early Morning</td>\n",
              "      <td>741</td>\n",
              "      <td>9.045410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>female</td>\n",
              "      <td>Morning</td>\n",
              "      <td>2345</td>\n",
              "      <td>28.625488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>female</td>\n",
              "      <td>Noon</td>\n",
              "      <td>2411</td>\n",
              "      <td>29.431152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>Eve</td>\n",
              "      <td>1391</td>\n",
              "      <td>16.979980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>female</td>\n",
              "      <td>Night</td>\n",
              "      <td>1099</td>\n",
              "      <td>13.415527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>male</td>\n",
              "      <td>Late Night</td>\n",
              "      <td>107</td>\n",
              "      <td>4.636049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>male</td>\n",
              "      <td>Early Morning</td>\n",
              "      <td>171</td>\n",
              "      <td>7.409012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>male</td>\n",
              "      <td>Morning</td>\n",
              "      <td>550</td>\n",
              "      <td>23.830156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>male</td>\n",
              "      <td>Noon</td>\n",
              "      <td>536</td>\n",
              "      <td>23.223570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>male</td>\n",
              "      <td>Eve</td>\n",
              "      <td>553</td>\n",
              "      <td>23.960139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>male</td>\n",
              "      <td>Night</td>\n",
              "      <td>391</td>\n",
              "      <td>16.941075</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    GENDER        DAYTYPE  SESSION_ID  PERCENTAGE\n",
              "0   female     Late Night         205    2.502441\n",
              "1   female  Early Morning         741    9.045410\n",
              "2   female        Morning        2345   28.625488\n",
              "3   female           Noon        2411   29.431152\n",
              "4   female            Eve        1391   16.979980\n",
              "5   female          Night        1099   13.415527\n",
              "6     male     Late Night         107    4.636049\n",
              "7     male  Early Morning         171    7.409012\n",
              "8     male        Morning         550   23.830156\n",
              "9     male           Noon         536   23.223570\n",
              "10    male            Eve         553   23.960139\n",
              "11    male          Night         391   16.941075"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_-GmdCl8FGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "fb5d4a4e-196f-4d4e-b8a0-899ed8b01f85"
      },
      "source": [
        "df[(df['TIME_SPENT_MINS']!=0) & (df['GENDER']=='male')].describe()"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IS_TRAIN</th>\n",
              "      <th>TIME_SPENT_MINS</th>\n",
              "      <th>STARTTIMEMONTH</th>\n",
              "      <th>STARTTIMEWEEK</th>\n",
              "      <th>STARTTIMEDAY</th>\n",
              "      <th>STARTTIMEDAYOFWEEK</th>\n",
              "      <th>STARTTIMEDAYOFYEAR</th>\n",
              "      <th>STARTTIMEIS_MONTH_END</th>\n",
              "      <th>STARTTIMEIS_MONTH_START</th>\n",
              "      <th>STARTTIMEIS_QUARTER_END</th>\n",
              "      <th>STARTTIMEIS_QUARTER_START</th>\n",
              "      <th>STARTTIMEIS_YEAR_END</th>\n",
              "      <th>STARTTIMEIS_YEAR_START</th>\n",
              "      <th>HOUR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1030.0</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.0</td>\n",
              "      <td>1030.0</td>\n",
              "      <td>1030.0</td>\n",
              "      <td>1030.0</td>\n",
              "      <td>1030.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.0</td>\n",
              "      <td>316.361165</td>\n",
              "      <td>11.596117</td>\n",
              "      <td>48.992233</td>\n",
              "      <td>16.111650</td>\n",
              "      <td>3.049515</td>\n",
              "      <td>337.995146</td>\n",
              "      <td>0.001942</td>\n",
              "      <td>0.021359</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.823301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2464.289052</td>\n",
              "      <td>0.490913</td>\n",
              "      <td>1.819327</td>\n",
              "      <td>6.613747</td>\n",
              "      <td>2.103372</td>\n",
              "      <td>12.304170</td>\n",
              "      <td>0.044044</td>\n",
              "      <td>0.144649</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.573769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>318.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>326.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>341.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>349.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "      <td>36982.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>356.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       IS_TRAIN  TIME_SPENT_MINS  ...  STARTTIMEIS_YEAR_START         HOUR\n",
              "count    1030.0      1030.000000  ...                  1030.0  1030.000000\n",
              "mean        1.0       316.361165  ...                     0.0    14.823301\n",
              "std         0.0      2464.289052  ...                     0.0     5.573769\n",
              "min         1.0         1.000000  ...                     0.0     0.000000\n",
              "25%         1.0         1.000000  ...                     0.0    11.000000\n",
              "50%         1.0         2.000000  ...                     0.0    15.000000\n",
              "75%         1.0         5.000000  ...                     0.0    20.000000\n",
              "max         1.0     36982.000000  ...                     0.0    23.000000\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd8hNhZr-RcJ",
        "colab_type": "text"
      },
      "source": [
        "Insights from date field\n",
        "1. 50% of records has same start time and end time\n",
        "2. In the remaining records female and male has pretty much have the same duration\n",
        "3. We can observe that from the above analysis female mostly browse on sunday, thursday, friday and monday where as male mostly browse on sunday, thursday, saturday and friday\n",
        "4. Womens mostly browse in the noon where as mens mostly browse in the evening\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-DD1TTS3Fns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "backup = df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvO3i5Kb05KJ",
        "colab_type": "text"
      },
      "source": [
        "**Features based on the product category**\n",
        "\n",
        "To analyse further based on the count products or type of products purchased"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGdg15vh04YY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating empty columns\n",
        "# for i in sorted(c1.keys()):\n",
        "#   df[i] = 0\n",
        "\n",
        "# sub_cat = ['_'.join([i,j]) for i in c1.keys() for j in c1[i]]\n",
        "\n",
        "# for sub in sub_cat:\n",
        "#   df[sub] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx46LDJ-rNdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nos_product(x):\n",
        "  prod_list = x.split(';')\n",
        "  return len(prod_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBWNpdmiyJTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['VIEWED_PRODUCT_NOS'] = df['PRODUCTLIST'].apply(lambda x: nos_product(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuRNogVtx0T3",
        "colab_type": "text"
      },
      "source": [
        "we can see there are three sub categories appearing under different categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIoBEAaPsShb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subcat = []\n",
        "for sub in c1.values():\n",
        "  subcat.extend(sub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOgh0gXmxAbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subcat_count = Counter(subcat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu1-mIR4xMIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6521c4ed-0842-48eb-e97f-502d092a54c3"
      },
      "source": [
        "for i in subcat_count.keys():\n",
        "  if subcat_count[i]>1:\n",
        "    print(i,subcat_count[i])"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B00001 2\n",
            "B00004 4\n",
            "B00011 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6DEPJMo0Ege",
        "colab_type": "text"
      },
      "source": [
        "Creating category as columns along with the count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs3smfiSzR_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# based on the analysis selected these columns \n",
        "req_columns = [ 'A00002_B00002_C00007', 'A00001_B00009_C00028', 'A00001_B00001_C00019',\\\n",
        "'A00002_B00002_C00007', 'A00002_B00002_C00002', 'A00002_B00002_C00003',\\\n",
        "'A00002_B00002', 'A00001_B00001', 'A00002_B00001', 'A00001_B00015',\\\n",
        "'A00001_B00004', 'A00001_B00031', 'A00003_B00012', 'A00002_B00007',\\\n",
        "'A00003_B00022', 'A00002_B00004','A00002_B00005', 'A00002_B00016', \\\n",
        "'A00002_B00017','A00002', 'A00001', 'A00003', 'A00004', 'A00005',\\\n",
        " 'A00006', 'A00011', 'A00007', 'A00010', 'A00008', 'A00009']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MBXf7ko27I0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for c in req_columns:\n",
        "  df[c]=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdaN0RxR0EXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def creating_col(item, count_item, req_columns):\n",
        "  if count_item == 2:\n",
        "    subitem = '_'.join([item[0],item[1]])\n",
        "  elif count_item == 3:\n",
        "    subitem = '_'.join([item[0],item[1],item[3]])\n",
        "  else:\n",
        "    subitem = item[0]  \n",
        "    if subitem in df.columns:\n",
        "      df.at[i,subitem] +=1\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-i5yWsvyt06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, row in df.iterrows():\n",
        "  ind_prod = row['PRODUCTLIST'].split(';')\n",
        "  for p in ind_prod:\n",
        "    item = p.split('/')\n",
        "    df = creating_col(item, 1, req_columns)\n",
        "    df = creating_col(item, 2, req_columns)\n",
        "    df = creating_col(item, 3, req_columns)\n",
        "    # subitem = '_'.join([item[0],item[1]])\n",
        "    # if subitem in req_columns:\n",
        "    #   df.at[i,subitem] +=1\n",
        "    # else:\n",
        "    #   df[subitem]=0\n",
        "    #   df.at[i,subitem] +=1\n",
        "    # df.at[i,item[0]] +=1\n",
        "    # if subitem in df.columns:\n",
        "      # df.at[i,subitem] +=1\n",
        "    # break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MICE34IZ9AVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "69fd00b0-6683-4ea3-c617-1877203b6675"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SESSION_ID</th>\n",
              "      <th>STARTTIME</th>\n",
              "      <th>ENDTIME</th>\n",
              "      <th>PRODUCTLIST</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>IS_TRAIN</th>\n",
              "      <th>TIME_SPENT_MINS</th>\n",
              "      <th>STARTTIMEMONTH</th>\n",
              "      <th>STARTTIMEWEEK</th>\n",
              "      <th>STARTTIMEDAY</th>\n",
              "      <th>STARTTIMEDAYOFWEEK</th>\n",
              "      <th>STARTTIMEDAYOFYEAR</th>\n",
              "      <th>STARTTIMEIS_MONTH_END</th>\n",
              "      <th>STARTTIMEIS_MONTH_START</th>\n",
              "      <th>STARTTIMEIS_QUARTER_END</th>\n",
              "      <th>STARTTIMEIS_QUARTER_START</th>\n",
              "      <th>STARTTIMEIS_YEAR_END</th>\n",
              "      <th>STARTTIMEIS_YEAR_START</th>\n",
              "      <th>HOUR</th>\n",
              "      <th>DAYTYPE</th>\n",
              "      <th>VIEWED_PRODUCT_NOS</th>\n",
              "      <th>A00002_B00002_C00007</th>\n",
              "      <th>A00001_B00009_C00028</th>\n",
              "      <th>A00001_B00001_C00019</th>\n",
              "      <th>A00002_B00002_C00002</th>\n",
              "      <th>A00002_B00002_C00003</th>\n",
              "      <th>A00002_B00002</th>\n",
              "      <th>A00001_B00001</th>\n",
              "      <th>A00002_B00001</th>\n",
              "      <th>A00001_B00015</th>\n",
              "      <th>A00001_B00004</th>\n",
              "      <th>A00001_B00031</th>\n",
              "      <th>A00003_B00012</th>\n",
              "      <th>A00002_B00007</th>\n",
              "      <th>A00003_B00022</th>\n",
              "      <th>A00002_B00004</th>\n",
              "      <th>A00002_B00005</th>\n",
              "      <th>A00002_B00016</th>\n",
              "      <th>A00002_B00017</th>\n",
              "      <th>A00002</th>\n",
              "      <th>A00001</th>\n",
              "      <th>A00003</th>\n",
              "      <th>A00004</th>\n",
              "      <th>A00005</th>\n",
              "      <th>A00006</th>\n",
              "      <th>A00011</th>\n",
              "      <th>A00007</th>\n",
              "      <th>A00010</th>\n",
              "      <th>A00008</th>\n",
              "      <th>A00009</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u16159</td>\n",
              "      <td>2014-12-15 18:11:00</td>\n",
              "      <td>2014-12-15 18:12:00</td>\n",
              "      <td>A00002/B00003/C00006/D28435/;A00002/B00003/C00...</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12</td>\n",
              "      <td>51</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>349</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>Eve</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u10253</td>\n",
              "      <td>2014-12-16 14:35:00</td>\n",
              "      <td>2014-12-16 14:41:00</td>\n",
              "      <td>A00001/B00009/C00031/D29404/;A00001/B00009/C00...</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12</td>\n",
              "      <td>51</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>350</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>Noon</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u19037</td>\n",
              "      <td>2014-12-01 15:58:00</td>\n",
              "      <td>2014-12-01 15:58:00</td>\n",
              "      <td>A00002/B00001/C00020/D16944/</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>335</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>Noon</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u14556</td>\n",
              "      <td>2014-11-23 02:57:00</td>\n",
              "      <td>2014-11-23 03:00:00</td>\n",
              "      <td>A00002/B00004/C00018/D10284/;A00002/B00004/C00...</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11</td>\n",
              "      <td>47</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>327</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Late Night</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>u24295</td>\n",
              "      <td>2014-12-17 16:44:00</td>\n",
              "      <td>2014-12-17 16:46:00</td>\n",
              "      <td>A00001/B00001/C00012/D30805/;A00001/B00001/C00...</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12</td>\n",
              "      <td>51</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>351</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>Noon</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  SESSION_ID           STARTTIME             ENDTIME  ... A00010 A00008  A00009\n",
              "0     u16159 2014-12-15 18:11:00 2014-12-15 18:12:00  ...      0      0       0\n",
              "1     u10253 2014-12-16 14:35:00 2014-12-16 14:41:00  ...      0      0       0\n",
              "2     u19037 2014-12-01 15:58:00 2014-12-01 15:58:00  ...      0      0       0\n",
              "3     u14556 2014-11-23 02:57:00 2014-11-23 03:00:00  ...      0      0       0\n",
              "4     u24295 2014-12-17 16:44:00 2014-12-17 16:46:00  ...      0      0       0\n",
              "\n",
              "[5 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uOTGXMdr7_-x"
      },
      "source": [
        "\n",
        "\n",
        "1.   A00002 25% of the men viewed this product atleast once and 75% of the women viewed this product atleast once\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHQmEDho8ILl",
        "colab_type": "text"
      },
      "source": [
        "Calculating the ratio of each category products on total number of products visited"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRMy8tR8zqM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in c1.keys():\n",
        "#   train[i] = train[i]*train['NUMBER_OF_PRODUCTS']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjeYdqb42lvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cat_products(df,c1_val, c2_val):\n",
        "  for i in sorted(c1_val.keys()):\n",
        "    df[i] = df[i]*c1_val[i]\n",
        "  # for j in sorted(c2_val.keys()):\n",
        "  #   col = [ c for c in df.columns  if j in c ]\n",
        "  #   df[col] = df[col]*c2_val[j]\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vHHnnoj3cfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df = cat_products(df,c1_val, c2_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsjZNUio3tfk",
        "colab_type": "text"
      },
      "source": [
        "Category selection analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcVEtFt4wCll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_rows',100)\n",
        "female = pd.DataFrame(df[df['GENDER'] == 'female'].sum(axis=0)[21:]).sort_values(by=[0], ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mobNT12VgSPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_rows',100)\n",
        "male = pd.DataFrame(df[df['GENDER'] == 'male'].sum(axis=0)[21:]).sort_values(by=[0], ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Jtdcz2wdnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "male['m_percent']=male[0]/male[0].sum()*100\n",
        "female['f_percent']=female[0]/female[0].sum()*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ssCVNzkxI6h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "0bb0f6bd-f0a7-4114-ccf8-0070bbb1e25e"
      },
      "source": [
        "male.sort_values(by=['m_percent'], ascending=False).head(10).index"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['A00002_B00002', 'A00001_B00001', 'A00002_B00001', 'A00001_B00015',\n",
              "       'A00001_B00004', 'A00001_B00031', 'A00003_B00012', 'A00002_B00007',\n",
              "       'A00003_B00022', 'A00002_B00004'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOdlmdr9w0Y8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "fedc1a22-2cb6-4629-db94-1aae668c2ee5"
      },
      "source": [
        "female.sort_values(by=['f_percent'], ascending=False).head(10).index"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['A00002_B00002', 'A00002_B00001', 'A00003_B00012', 'A00002_B00007',\n",
              "       'A00003_B00022', 'A00002_B00004', 'A00002_B00005', 'A00001_B00001',\n",
              "       'A00002_B00016', 'A00002_B00017'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzwZcOQj8sZF",
        "colab_type": "text"
      },
      "source": [
        "**TRAIN AND TEST** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-VLvbxF8hCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = df[df['IS_TRAIN']==1]\n",
        "test = df[df['IS_TRAIN']==0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCVP0b2p82H6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.drop(['SESSION_ID','STARTTIME','ENDTIME','PRODUCTLIST','IS_TRAIN'], axis=1, inplace=True)\n",
        "test.drop(['STARTTIME','ENDTIME','PRODUCTLIST','IS_TRAIN'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS766BJt9BLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['GENDER'] = train['GENDER'].replace({'male':0,'female':1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXxFlnSOvQM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2d7f02a4-6126-4796-b975-e6211f83e59a"
      },
      "source": [
        "\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "\n",
        "#test set has session id as extra column in this"
      ],
      "execution_count": 482,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10500, 45)\n",
            "(4500, 46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD63uN7uoGhV",
        "colab_type": "text"
      },
      "source": [
        "**FEATURE SCALING**\n",
        "\n",
        "For cyclic features using sin conversion and for huge values using standard scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKvqxFXyouoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cyclic_features = ['HOUR']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tb1Zaqm9Kxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[cyclic_features] = np.sin(train[cyclic_features])\n",
        "test[cyclic_features] = np.sin(test[cyclic_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vJQJ0kEYJ0bP",
        "colab": {}
      },
      "source": [
        "to_normalise = ['TIME_SPENT_MINS'] \n",
        "#+ sorted(c1.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqPq5ggzuhpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()\n",
        "train[to_normalise] = scaler.fit_transform(train[to_normalise])\n",
        "test[to_normalise] = scaler.transform(test[to_normalise])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-DlOi3Kvmei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "ebae3bb6-1eec-4282-8326-c71698b8a72a"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GENDER</th>\n",
              "      <th>TIME_SPENT_MINS</th>\n",
              "      <th>STARTTIMEMONTH</th>\n",
              "      <th>STARTTIMEWEEK</th>\n",
              "      <th>STARTTIMEDAY</th>\n",
              "      <th>STARTTIMEDAYOFWEEK</th>\n",
              "      <th>STARTTIMEDAYOFYEAR</th>\n",
              "      <th>STARTTIMEIS_MONTH_END</th>\n",
              "      <th>STARTTIMEIS_MONTH_START</th>\n",
              "      <th>STARTTIMEIS_QUARTER_END</th>\n",
              "      <th>STARTTIMEIS_QUARTER_START</th>\n",
              "      <th>STARTTIMEIS_YEAR_END</th>\n",
              "      <th>STARTTIMEIS_YEAR_START</th>\n",
              "      <th>HOUR</th>\n",
              "      <th>DAYTYPE</th>\n",
              "      <th>VIEWED_PRODUCT_NOS</th>\n",
              "      <th>A00002_B00002_C00007</th>\n",
              "      <th>A00001_B00009_C00028</th>\n",
              "      <th>A00001_B00001_C00019</th>\n",
              "      <th>A00002_B00002_C00002</th>\n",
              "      <th>A00002_B00002_C00003</th>\n",
              "      <th>A00002_B00002</th>\n",
              "      <th>A00001_B00001</th>\n",
              "      <th>A00002_B00001</th>\n",
              "      <th>A00001_B00015</th>\n",
              "      <th>A00001_B00004</th>\n",
              "      <th>A00001_B00031</th>\n",
              "      <th>A00003_B00012</th>\n",
              "      <th>A00002_B00007</th>\n",
              "      <th>A00003_B00022</th>\n",
              "      <th>A00002_B00004</th>\n",
              "      <th>A00002_B00005</th>\n",
              "      <th>A00002_B00016</th>\n",
              "      <th>A00002_B00017</th>\n",
              "      <th>A00002</th>\n",
              "      <th>A00001</th>\n",
              "      <th>A00003</th>\n",
              "      <th>A00004</th>\n",
              "      <th>A00005</th>\n",
              "      <th>A00006</th>\n",
              "      <th>A00011</th>\n",
              "      <th>A00007</th>\n",
              "      <th>A00010</th>\n",
              "      <th>A00008</th>\n",
              "      <th>A00009</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.068114</td>\n",
              "      <td>12</td>\n",
              "      <td>51</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>349</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.750987</td>\n",
              "      <td>Eve</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.065333</td>\n",
              "      <td>12</td>\n",
              "      <td>51</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>350</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.990607</td>\n",
              "      <td>Noon</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.068670</td>\n",
              "      <td>12</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>335</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.650288</td>\n",
              "      <td>Noon</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.067002</td>\n",
              "      <td>11</td>\n",
              "      <td>47</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>327</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.909297</td>\n",
              "      <td>Late Night</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.067558</td>\n",
              "      <td>12</td>\n",
              "      <td>51</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>351</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.287903</td>\n",
              "      <td>Noon</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   GENDER  TIME_SPENT_MINS  STARTTIMEMONTH  ...  A00010  A00008  A00009\n",
              "0       1        -0.068114              12  ...       0       0       0\n",
              "1       0        -0.065333              12  ...       0       0       0\n",
              "2       1        -0.068670              12  ...       0       0       0\n",
              "3       1        -0.067002              11  ...       0       0       0\n",
              "4       0        -0.067558              12  ...       0       0       0\n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 487
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cwMM4Dqw1I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['DAYTYPE'] = train['DAYTYPE'].astype('category')\n",
        "test['DAYTYPE'] = test['DAYTYPE'].astype('category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX6lXW_yb1oc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "0ad59358-e9df-4d28-83a2-db4af52c90c6"
      },
      "source": [
        "train.columns[10:30]"
      ],
      "execution_count": 489,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['STARTTIMEIS_QUARTER_START', 'STARTTIMEIS_YEAR_END',\n",
              "       'STARTTIMEIS_YEAR_START', 'HOUR', 'DAYTYPE', 'VIEWED_PRODUCT_NOS',\n",
              "       'A00002_B00002_C00007', 'A00001_B00009_C00028', 'A00001_B00001_C00019',\n",
              "       'A00002_B00002_C00002', 'A00002_B00002_C00003', 'A00002_B00002',\n",
              "       'A00001_B00001', 'A00002_B00001', 'A00001_B00015', 'A00001_B00004',\n",
              "       'A00001_B00031', 'A00003_B00012', 'A00002_B00007', 'A00003_B00022'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 489
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8-VI1V190Rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For Random forest and neural network implementation\n",
        "\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "train['DAYTYPE']= le.fit_transform(train['DAYTYPE'].astype('str'))\n",
        "test['DAYTYPE']= le.transform(test['DAYTYPE'].astype('str'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRxAEI8PxQ2s",
        "colab_type": "text"
      },
      "source": [
        "SPLITTING train and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJcFj5Vv95Kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(train.drop(['GENDER'], axis=1), \\\n",
        "                                                  train['GENDER'].astype('int'),\n",
        "                                                    test_size=0.2,shuffle=True,\n",
        "                                                    random_state=0,\n",
        "                                                    stratify=train['GENDER'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q6iOlmT5JwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "9b14dfdb-23fb-4855-c37e-e56f592dd843"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8400, 44)\n",
            "(8400,)\n",
            "(2100, 44)\n",
            "(2100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngEO3HgGGm5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,matthews_corrcoef\n",
        "import pandas as pd\n",
        "def evaluate_model(y_pred):\n",
        "  cm = confusion_matrix(y_val, y_pred)\n",
        "  cm_df = pd.DataFrame(cm.T)\n",
        "  cm_df.index.name = 'Predicted'\n",
        "  cm_df.columns.name = 'True'\n",
        "  print('CONFUSION MATRIX')\n",
        "  print(cm_df)\n",
        "  print('CLASSIFICATION REPORT')\n",
        "  print(classification_report(y_val,y_pred))\n",
        "  print('MATHEWS CORRELATION COEFFICIENT')\n",
        "  print(matthews_corrcoef(y_val,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJwG1lX44KaZ",
        "colab_type": "text"
      },
      "source": [
        "Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_syRYkyAY1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Activation, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lmPNyU9Bujh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "477fbe4e-ae08-486f-97a2-c784b9d6f255"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 256)               11520     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 931,585\n",
            "Trainable params: 931,585\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIdwPZrAKPyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop,SGD\n",
        "\n",
        "opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx3oviujBKbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.keras.optimizers import adam,SGD\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint('nn_weights.hdf5', monitor='val_acc', verbose=1, patience=20, save_best_only=True, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQsd2jt4C4kP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6c8cdcd-d31f-4dcf-fd27-61de552cdbee"
      },
      "source": [
        "model.fit(x=x_train, y=y_train, class_weight= {0:1,1:1},\n",
        "          batch_size=32,\n",
        "          epochs=50,callbacks=[checkpoint],\n",
        "          verbose=1,\n",
        "          validation_data=(x_val,y_val)\n",
        "                      )"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "255/263 [============================>.] - ETA: 0s - loss: 0.3989 - accuracy: 0.8466WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3962 - accuracy: 0.8479 - val_loss: 0.3831 - val_accuracy: 0.8557\n",
            "Epoch 2/50\n",
            "256/263 [============================>.] - ETA: 0s - loss: 0.3917 - accuracy: 0.8506WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3918 - accuracy: 0.8506 - val_loss: 0.3773 - val_accuracy: 0.8600\n",
            "Epoch 3/50\n",
            "250/263 [===========================>..] - ETA: 0s - loss: 0.3934 - accuracy: 0.8476WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3907 - accuracy: 0.8496 - val_loss: 0.3875 - val_accuracy: 0.8576\n",
            "Epoch 4/50\n",
            "262/263 [============================>.] - ETA: 0s - loss: 0.3900 - accuracy: 0.8532WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3896 - accuracy: 0.8533 - val_loss: 0.3832 - val_accuracy: 0.8567\n",
            "Epoch 5/50\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.3940 - accuracy: 0.8504WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3940 - accuracy: 0.8504 - val_loss: 0.3807 - val_accuracy: 0.8571\n",
            "Epoch 6/50\n",
            "251/263 [===========================>..] - ETA: 0s - loss: 0.3936 - accuracy: 0.8495WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3928 - accuracy: 0.8496 - val_loss: 0.3918 - val_accuracy: 0.8571\n",
            "Epoch 7/50\n",
            "261/263 [============================>.] - ETA: 0s - loss: 0.3928 - accuracy: 0.8482WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3935 - accuracy: 0.8480 - val_loss: 0.3848 - val_accuracy: 0.8548\n",
            "Epoch 8/50\n",
            "257/263 [============================>.] - ETA: 0s - loss: 0.3929 - accuracy: 0.8492WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3940 - accuracy: 0.8486 - val_loss: 0.3796 - val_accuracy: 0.8624\n",
            "Epoch 9/50\n",
            "260/263 [============================>.] - ETA: 0s - loss: 0.3931 - accuracy: 0.8502WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3920 - accuracy: 0.8508 - val_loss: 0.3820 - val_accuracy: 0.8581\n",
            "Epoch 10/50\n",
            "258/263 [============================>.] - ETA: 0s - loss: 0.3920 - accuracy: 0.8525WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3919 - accuracy: 0.8524 - val_loss: 0.3836 - val_accuracy: 0.8571\n",
            "Epoch 11/50\n",
            "261/263 [============================>.] - ETA: 0s - loss: 0.3918 - accuracy: 0.8491WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3908 - accuracy: 0.8495 - val_loss: 0.3823 - val_accuracy: 0.8571\n",
            "Epoch 12/50\n",
            "262/263 [============================>.] - ETA: 0s - loss: 0.3923 - accuracy: 0.8511WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3918 - accuracy: 0.8513 - val_loss: 0.3959 - val_accuracy: 0.8548\n",
            "Epoch 13/50\n",
            "262/263 [============================>.] - ETA: 0s - loss: 0.3908 - accuracy: 0.8529WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3906 - accuracy: 0.8530 - val_loss: 0.3869 - val_accuracy: 0.8519\n",
            "Epoch 14/50\n",
            "251/263 [===========================>..] - ETA: 0s - loss: 0.3880 - accuracy: 0.8522WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3919 - accuracy: 0.8499 - val_loss: 0.3868 - val_accuracy: 0.8581\n",
            "Epoch 15/50\n",
            "262/263 [============================>.] - ETA: 0s - loss: 0.3914 - accuracy: 0.8517WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3907 - accuracy: 0.8519 - val_loss: 0.3838 - val_accuracy: 0.8581\n",
            "Epoch 16/50\n",
            "251/263 [===========================>..] - ETA: 0s - loss: 0.3928 - accuracy: 0.8512WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3904 - accuracy: 0.8527 - val_loss: 0.3807 - val_accuracy: 0.8586\n",
            "Epoch 17/50\n",
            "251/263 [===========================>..] - ETA: 0s - loss: 0.3948 - accuracy: 0.8497WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3939 - accuracy: 0.8500 - val_loss: 0.3788 - val_accuracy: 0.8590\n",
            "Epoch 18/50\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.8526WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3914 - accuracy: 0.8526 - val_loss: 0.3822 - val_accuracy: 0.8610\n",
            "Epoch 19/50\n",
            "251/263 [===========================>..] - ETA: 0s - loss: 0.3919 - accuracy: 0.8511WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3928 - accuracy: 0.8508 - val_loss: 0.3788 - val_accuracy: 0.8595\n",
            "Epoch 20/50\n",
            "259/263 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8541WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3915 - accuracy: 0.8531 - val_loss: 0.3886 - val_accuracy: 0.8505\n",
            "Epoch 21/50\n",
            "251/263 [===========================>..] - ETA: 0s - loss: 0.3897 - accuracy: 0.8500WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3927 - accuracy: 0.8487 - val_loss: 0.3839 - val_accuracy: 0.8581\n",
            "Epoch 22/50\n",
            "255/263 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8528WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3895 - accuracy: 0.8526 - val_loss: 0.3799 - val_accuracy: 0.8586\n",
            "Epoch 23/50\n",
            "250/263 [===========================>..] - ETA: 0s - loss: 0.3894 - accuracy: 0.8529WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3896 - accuracy: 0.8535 - val_loss: 0.3804 - val_accuracy: 0.8590\n",
            "Epoch 24/50\n",
            "260/263 [============================>.] - ETA: 0s - loss: 0.3910 - accuracy: 0.8524WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3919 - accuracy: 0.8519 - val_loss: 0.3836 - val_accuracy: 0.8524\n",
            "Epoch 25/50\n",
            "260/263 [============================>.] - ETA: 0s - loss: 0.3978 - accuracy: 0.8451WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3968 - accuracy: 0.8454 - val_loss: 0.3802 - val_accuracy: 0.8552\n",
            "Epoch 26/50\n",
            "249/263 [===========================>..] - ETA: 0s - loss: 0.3964 - accuracy: 0.8504WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3953 - accuracy: 0.8498 - val_loss: 0.3827 - val_accuracy: 0.8571\n",
            "Epoch 27/50\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.3880 - accuracy: 0.8507WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3880 - accuracy: 0.8507 - val_loss: 0.3795 - val_accuracy: 0.8629\n",
            "Epoch 28/50\n",
            "249/263 [===========================>..] - ETA: 0s - loss: 0.3909 - accuracy: 0.8488WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3899 - accuracy: 0.8495 - val_loss: 0.3789 - val_accuracy: 0.8624\n",
            "Epoch 29/50\n",
            "253/263 [===========================>..] - ETA: 0s - loss: 0.3882 - accuracy: 0.8544WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3876 - accuracy: 0.8548 - val_loss: 0.3815 - val_accuracy: 0.8600\n",
            "Epoch 30/50\n",
            "260/263 [============================>.] - ETA: 0s - loss: 0.3907 - accuracy: 0.8531WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3901 - accuracy: 0.8530 - val_loss: 0.3828 - val_accuracy: 0.8519\n",
            "Epoch 31/50\n",
            "254/263 [===========================>..] - ETA: 0s - loss: 0.3887 - accuracy: 0.8508WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3889 - accuracy: 0.8507 - val_loss: 0.3818 - val_accuracy: 0.8538\n",
            "Epoch 32/50\n",
            "258/263 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8515WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3881 - accuracy: 0.8515 - val_loss: 0.3767 - val_accuracy: 0.8624\n",
            "Epoch 33/50\n",
            "255/263 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8536WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3874 - accuracy: 0.8539 - val_loss: 0.3770 - val_accuracy: 0.8605\n",
            "Epoch 34/50\n",
            "260/263 [============================>.] - ETA: 0s - loss: 0.3929 - accuracy: 0.8507WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3933 - accuracy: 0.8505 - val_loss: 0.3810 - val_accuracy: 0.8590\n",
            "Epoch 35/50\n",
            "249/263 [===========================>..] - ETA: 0s - loss: 0.3869 - accuracy: 0.8525WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3876 - accuracy: 0.8517 - val_loss: 0.3873 - val_accuracy: 0.8576\n",
            "Epoch 36/50\n",
            "257/263 [============================>.] - ETA: 0s - loss: 0.3913 - accuracy: 0.8520WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3893 - accuracy: 0.8526 - val_loss: 0.3868 - val_accuracy: 0.8557\n",
            "Epoch 37/50\n",
            "261/263 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8520WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3888 - accuracy: 0.8521 - val_loss: 0.4005 - val_accuracy: 0.8590\n",
            "Epoch 38/50\n",
            "249/263 [===========================>..] - ETA: 0s - loss: 0.3888 - accuracy: 0.8553WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3874 - accuracy: 0.8558 - val_loss: 0.3899 - val_accuracy: 0.8524\n",
            "Epoch 39/50\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.3880 - accuracy: 0.8515WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3880 - accuracy: 0.8515 - val_loss: 0.3784 - val_accuracy: 0.8576\n",
            "Epoch 40/50\n",
            "252/263 [===========================>..] - ETA: 0s - loss: 0.3859 - accuracy: 0.8571WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3853 - accuracy: 0.8571 - val_loss: 0.3970 - val_accuracy: 0.8510\n",
            "Epoch 41/50\n",
            "249/263 [===========================>..] - ETA: 0s - loss: 0.3889 - accuracy: 0.8514WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3909 - accuracy: 0.8506 - val_loss: 0.3852 - val_accuracy: 0.8614\n",
            "Epoch 42/50\n",
            "249/263 [===========================>..] - ETA: 0s - loss: 0.3894 - accuracy: 0.8553WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3895 - accuracy: 0.8546 - val_loss: 0.3943 - val_accuracy: 0.8424\n",
            "Epoch 43/50\n",
            "263/263 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.8557WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3887 - accuracy: 0.8557 - val_loss: 0.3798 - val_accuracy: 0.8600\n",
            "Epoch 44/50\n",
            "250/263 [===========================>..] - ETA: 0s - loss: 0.3882 - accuracy: 0.8499WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3855 - accuracy: 0.8513 - val_loss: 0.3935 - val_accuracy: 0.8476\n",
            "Epoch 45/50\n",
            "256/263 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8524WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3905 - accuracy: 0.8518 - val_loss: 0.3942 - val_accuracy: 0.8438\n",
            "Epoch 46/50\n",
            "262/263 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8566WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3844 - accuracy: 0.8562 - val_loss: 0.3866 - val_accuracy: 0.8586\n",
            "Epoch 47/50\n",
            "261/263 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8551WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3846 - accuracy: 0.8550 - val_loss: 0.4191 - val_accuracy: 0.8386\n",
            "Epoch 48/50\n",
            "250/263 [===========================>..] - ETA: 0s - loss: 0.3876 - accuracy: 0.8558WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3887 - accuracy: 0.8556 - val_loss: 0.3844 - val_accuracy: 0.8590\n",
            "Epoch 49/50\n",
            "250/263 [===========================>..] - ETA: 0s - loss: 0.3894 - accuracy: 0.8534WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3896 - accuracy: 0.8533 - val_loss: 0.3931 - val_accuracy: 0.8429\n",
            "Epoch 50/50\n",
            "261/263 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8487WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.3892 - accuracy: 0.8490 - val_loss: 0.3836 - val_accuracy: 0.8562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f74ec6ac668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxxVOxBcEngs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_pred = model.predict(x_val)\n",
        "y_pred = np.where(nn_pred<0.44,0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcZtsYZRcn05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_test = model.predict(test[x_train.columns])\n",
        "nn_res = np.where(nn_test<0.44,0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "692qr3CIFBjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "e22115a1-e0e7-40fe-a13a-9caf703e5809"
      },
      "source": [
        "evaluate_model(y_pred)"
      ],
      "execution_count": 574,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONFUSION MATRIX\n",
            "True         0     1\n",
            "Predicted           \n",
            "0          233    71\n",
            "1          229  1567\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.50      0.61       462\n",
            "           1       0.87      0.96      0.91      1638\n",
            "\n",
            "    accuracy                           0.86      2100\n",
            "   macro avg       0.82      0.73      0.76      2100\n",
            "weighted avg       0.85      0.86      0.85      2100\n",
            "\n",
            "MATHEWS CORRELATION COEFFICIENT\n",
            "0.5427168714513624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5CAQ33ZbeLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "ef21d2f6-c8db-4a27-993c-b1d60621cf09"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\t\n",
        "# fit model no training data\n",
        "model_xg = XGBClassifier(class_weight='balanced')\n",
        "model_xg.fit(x_train, y_train, eval_metric='auc')"
      ],
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',\n",
              "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
              "              gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg_rq8gDcnlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xg_pred = model_xg.predict_proba(x_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFcLro5T9_fo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "5a2af9d7-3fb2-47f7-b749-9cad3e0e5581"
      },
      "source": [
        "y_pred = np.argmax(xg_pred, axis=1)\n",
        "evaluate_model(y_pred)"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONFUSION MATRIX\n",
            "True         0     1\n",
            "Predicted           \n",
            "0          232    75\n",
            "1          230  1563\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.50      0.60       462\n",
            "           1       0.87      0.95      0.91      1638\n",
            "\n",
            "    accuracy                           0.85      2100\n",
            "   macro avg       0.81      0.73      0.76      2100\n",
            "weighted avg       0.85      0.85      0.84      2100\n",
            "\n",
            "MATHEWS CORRELATION COEFFICIENT\n",
            "0.535109069259659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUevpmMd-QIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "model_lgbm  = lgb.LGBMClassifier(class_weight='balanced',objective='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA_KhJ2V-jRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "525d862d-64cb-4f9b-8fac-641c30cb44a6"
      },
      "source": [
        "model_lgbm.fit(x_train, y_train, eval_set=(x_val,y_val), eval_metric='auc', categorical_feature=['DAYTYPE'])"
      ],
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's auc: 0.800331\tvalid_0's binary_logloss: 0.662337\n",
            "[2]\tvalid_0's auc: 0.806763\tvalid_0's binary_logloss: 0.637221\n",
            "[3]\tvalid_0's auc: 0.805199\tvalid_0's binary_logloss: 0.616786\n",
            "[4]\tvalid_0's auc: 0.80738\tvalid_0's binary_logloss: 0.599316\n",
            "[5]\tvalid_0's auc: 0.807008\tvalid_0's binary_logloss: 0.584727\n",
            "[6]\tvalid_0's auc: 0.805713\tvalid_0's binary_logloss: 0.572069\n",
            "[7]\tvalid_0's auc: 0.806722\tvalid_0's binary_logloss: 0.560972\n",
            "[8]\tvalid_0's auc: 0.809922\tvalid_0's binary_logloss: 0.551766\n",
            "[9]\tvalid_0's auc: 0.810615\tvalid_0's binary_logloss: 0.544268\n",
            "[10]\tvalid_0's auc: 0.812572\tvalid_0's binary_logloss: 0.537002\n",
            "[11]\tvalid_0's auc: 0.813289\tvalid_0's binary_logloss: 0.531145\n",
            "[12]\tvalid_0's auc: 0.814315\tvalid_0's binary_logloss: 0.526174\n",
            "[13]\tvalid_0's auc: 0.81614\tvalid_0's binary_logloss: 0.519747\n",
            "[14]\tvalid_0's auc: 0.816461\tvalid_0's binary_logloss: 0.515879\n",
            "[15]\tvalid_0's auc: 0.819393\tvalid_0's binary_logloss: 0.512167\n",
            "[16]\tvalid_0's auc: 0.818132\tvalid_0's binary_logloss: 0.508825\n",
            "[17]\tvalid_0's auc: 0.819025\tvalid_0's binary_logloss: 0.506461\n",
            "[18]\tvalid_0's auc: 0.820354\tvalid_0's binary_logloss: 0.504359\n",
            "[19]\tvalid_0's auc: 0.820634\tvalid_0's binary_logloss: 0.501863\n",
            "[20]\tvalid_0's auc: 0.820759\tvalid_0's binary_logloss: 0.500057\n",
            "[21]\tvalid_0's auc: 0.82144\tvalid_0's binary_logloss: 0.498121\n",
            "[22]\tvalid_0's auc: 0.822496\tvalid_0's binary_logloss: 0.495895\n",
            "[23]\tvalid_0's auc: 0.823466\tvalid_0's binary_logloss: 0.494615\n",
            "[24]\tvalid_0's auc: 0.823929\tvalid_0's binary_logloss: 0.493298\n",
            "[25]\tvalid_0's auc: 0.825269\tvalid_0's binary_logloss: 0.490408\n",
            "[26]\tvalid_0's auc: 0.825845\tvalid_0's binary_logloss: 0.487897\n",
            "[27]\tvalid_0's auc: 0.826507\tvalid_0's binary_logloss: 0.486257\n",
            "[28]\tvalid_0's auc: 0.826555\tvalid_0's binary_logloss: 0.485076\n",
            "[29]\tvalid_0's auc: 0.827126\tvalid_0's binary_logloss: 0.48315\n",
            "[30]\tvalid_0's auc: 0.827253\tvalid_0's binary_logloss: 0.48188\n",
            "[31]\tvalid_0's auc: 0.827676\tvalid_0's binary_logloss: 0.480641\n",
            "[32]\tvalid_0's auc: 0.828305\tvalid_0's binary_logloss: 0.479583\n",
            "[33]\tvalid_0's auc: 0.828316\tvalid_0's binary_logloss: 0.47891\n",
            "[34]\tvalid_0's auc: 0.828903\tvalid_0's binary_logloss: 0.477843\n",
            "[35]\tvalid_0's auc: 0.830147\tvalid_0's binary_logloss: 0.47685\n",
            "[36]\tvalid_0's auc: 0.829837\tvalid_0's binary_logloss: 0.476454\n",
            "[37]\tvalid_0's auc: 0.829644\tvalid_0's binary_logloss: 0.475668\n",
            "[38]\tvalid_0's auc: 0.829775\tvalid_0's binary_logloss: 0.474986\n",
            "[39]\tvalid_0's auc: 0.829491\tvalid_0's binary_logloss: 0.474899\n",
            "[40]\tvalid_0's auc: 0.829711\tvalid_0's binary_logloss: 0.47437\n",
            "[41]\tvalid_0's auc: 0.829105\tvalid_0's binary_logloss: 0.474191\n",
            "[42]\tvalid_0's auc: 0.829493\tvalid_0's binary_logloss: 0.473441\n",
            "[43]\tvalid_0's auc: 0.829651\tvalid_0's binary_logloss: 0.472999\n",
            "[44]\tvalid_0's auc: 0.828911\tvalid_0's binary_logloss: 0.472899\n",
            "[45]\tvalid_0's auc: 0.828777\tvalid_0's binary_logloss: 0.47243\n",
            "[46]\tvalid_0's auc: 0.82901\tvalid_0's binary_logloss: 0.47195\n",
            "[47]\tvalid_0's auc: 0.828934\tvalid_0's binary_logloss: 0.471886\n",
            "[48]\tvalid_0's auc: 0.829473\tvalid_0's binary_logloss: 0.471235\n",
            "[49]\tvalid_0's auc: 0.829518\tvalid_0's binary_logloss: 0.471002\n",
            "[50]\tvalid_0's auc: 0.829378\tvalid_0's binary_logloss: 0.470866\n",
            "[51]\tvalid_0's auc: 0.829582\tvalid_0's binary_logloss: 0.47071\n",
            "[52]\tvalid_0's auc: 0.829871\tvalid_0's binary_logloss: 0.470058\n",
            "[53]\tvalid_0's auc: 0.830192\tvalid_0's binary_logloss: 0.469544\n",
            "[54]\tvalid_0's auc: 0.830804\tvalid_0's binary_logloss: 0.469199\n",
            "[55]\tvalid_0's auc: 0.830628\tvalid_0's binary_logloss: 0.468772\n",
            "[56]\tvalid_0's auc: 0.830517\tvalid_0's binary_logloss: 0.468561\n",
            "[57]\tvalid_0's auc: 0.830407\tvalid_0's binary_logloss: 0.468388\n",
            "[58]\tvalid_0's auc: 0.830904\tvalid_0's binary_logloss: 0.467945\n",
            "[59]\tvalid_0's auc: 0.830692\tvalid_0's binary_logloss: 0.467729\n",
            "[60]\tvalid_0's auc: 0.831247\tvalid_0's binary_logloss: 0.467289\n",
            "[61]\tvalid_0's auc: 0.831257\tvalid_0's binary_logloss: 0.46697\n",
            "[62]\tvalid_0's auc: 0.831207\tvalid_0's binary_logloss: 0.466858\n",
            "[63]\tvalid_0's auc: 0.830069\tvalid_0's binary_logloss: 0.466983\n",
            "[64]\tvalid_0's auc: 0.82989\tvalid_0's binary_logloss: 0.466981\n",
            "[65]\tvalid_0's auc: 0.829869\tvalid_0's binary_logloss: 0.466934\n",
            "[66]\tvalid_0's auc: 0.830028\tvalid_0's binary_logloss: 0.466678\n",
            "[67]\tvalid_0's auc: 0.829926\tvalid_0's binary_logloss: 0.466455\n",
            "[68]\tvalid_0's auc: 0.829974\tvalid_0's binary_logloss: 0.466201\n",
            "[69]\tvalid_0's auc: 0.830419\tvalid_0's binary_logloss: 0.465582\n",
            "[70]\tvalid_0's auc: 0.830453\tvalid_0's binary_logloss: 0.465283\n",
            "[71]\tvalid_0's auc: 0.829896\tvalid_0's binary_logloss: 0.465305\n",
            "[72]\tvalid_0's auc: 0.830245\tvalid_0's binary_logloss: 0.465158\n",
            "[73]\tvalid_0's auc: 0.830525\tvalid_0's binary_logloss: 0.464427\n",
            "[74]\tvalid_0's auc: 0.82995\tvalid_0's binary_logloss: 0.464649\n",
            "[75]\tvalid_0's auc: 0.829828\tvalid_0's binary_logloss: 0.464605\n",
            "[76]\tvalid_0's auc: 0.829567\tvalid_0's binary_logloss: 0.464568\n",
            "[77]\tvalid_0's auc: 0.828932\tvalid_0's binary_logloss: 0.464715\n",
            "[78]\tvalid_0's auc: 0.828841\tvalid_0's binary_logloss: 0.464386\n",
            "[79]\tvalid_0's auc: 0.828757\tvalid_0's binary_logloss: 0.464119\n",
            "[80]\tvalid_0's auc: 0.82845\tvalid_0's binary_logloss: 0.463968\n",
            "[81]\tvalid_0's auc: 0.828116\tvalid_0's binary_logloss: 0.464057\n",
            "[82]\tvalid_0's auc: 0.828393\tvalid_0's binary_logloss: 0.463681\n",
            "[83]\tvalid_0's auc: 0.828846\tvalid_0's binary_logloss: 0.463532\n",
            "[84]\tvalid_0's auc: 0.828879\tvalid_0's binary_logloss: 0.463319\n",
            "[85]\tvalid_0's auc: 0.828609\tvalid_0's binary_logloss: 0.46287\n",
            "[86]\tvalid_0's auc: 0.828903\tvalid_0's binary_logloss: 0.462323\n",
            "[87]\tvalid_0's auc: 0.828196\tvalid_0's binary_logloss: 0.462361\n",
            "[88]\tvalid_0's auc: 0.828047\tvalid_0's binary_logloss: 0.462525\n",
            "[89]\tvalid_0's auc: 0.827376\tvalid_0's binary_logloss: 0.462659\n",
            "[90]\tvalid_0's auc: 0.82748\tvalid_0's binary_logloss: 0.462512\n",
            "[91]\tvalid_0's auc: 0.827184\tvalid_0's binary_logloss: 0.462392\n",
            "[92]\tvalid_0's auc: 0.827528\tvalid_0's binary_logloss: 0.462101\n",
            "[93]\tvalid_0's auc: 0.827275\tvalid_0's binary_logloss: 0.462155\n",
            "[94]\tvalid_0's auc: 0.826926\tvalid_0's binary_logloss: 0.461967\n",
            "[95]\tvalid_0's auc: 0.82665\tvalid_0's binary_logloss: 0.462009\n",
            "[96]\tvalid_0's auc: 0.826789\tvalid_0's binary_logloss: 0.461567\n",
            "[97]\tvalid_0's auc: 0.826377\tvalid_0's binary_logloss: 0.461659\n",
            "[98]\tvalid_0's auc: 0.826069\tvalid_0's binary_logloss: 0.462004\n",
            "[99]\tvalid_0's auc: 0.826423\tvalid_0's binary_logloss: 0.461571\n",
            "[100]\tvalid_0's auc: 0.826218\tvalid_0's binary_logloss: 0.461249\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
              "               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
              "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
              "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
              "               objective='binary', random_state=None, reg_alpha=0.0,\n",
              "               reg_lambda=0.0, silent=True, subsample=1.0,\n",
              "               subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 335
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW9BNFuP-pxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgb_pred = model_lgbm.predict_proba(x_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5saBZmWc-iq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "32d84907-e7bc-43c4-ca86-eaaffc91e016"
      },
      "source": [
        "y_pred = np.argmax(lgb_pred, axis=1)\n",
        "evaluate_model(y_pred)"
      ],
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONFUSION MATRIX\n",
            "True         0     1\n",
            "Predicted           \n",
            "0          302   197\n",
            "1          160  1441\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.65      0.63       462\n",
            "           1       0.90      0.88      0.89      1638\n",
            "\n",
            "    accuracy                           0.83      2100\n",
            "   macro avg       0.75      0.77      0.76      2100\n",
            "weighted avg       0.84      0.83      0.83      2100\n",
            "\n",
            "MATHEWS CORRELATION COEFFICIENT\n",
            "0.5191513556155081\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4PV5UaY-uEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "076c5552-ccbd-4b61-aea6-4801f91fc3de"
      },
      "source": [
        "lgb.plot_importance(model_lgbm, height=0.5,ignore_zero=True, figsize=(20,10))"
      ],
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74ebd38ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 338
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxhPyj3_DZCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install catboost\n",
        "import catboost\n",
        "model_cat = catboost.CatBoostClassifier(eval_metric='Logloss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnRuHm5UCnrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_features_indices = x_train.columns.get_indexer(['DAYTYPE'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MDg4Hq7DXF9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e089bf38-ab09-4c15-8467-c0bb835c3e06"
      },
      "source": [
        "model_cat.fit(x_train,y_train,cat_features=[13], eval_set=(x_val,y_val))"
      ],
      "execution_count": 548,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.053605\n",
            "0:\tlearn: 0.6592962\ttest: 0.6584736\tbest: 0.6584736 (0)\ttotal: 9.13ms\tremaining: 9.12s\n",
            "1:\tlearn: 0.6293053\ttest: 0.6279476\tbest: 0.6279476 (1)\ttotal: 19.7ms\tremaining: 9.85s\n",
            "2:\tlearn: 0.6041830\ttest: 0.6024489\tbest: 0.6024489 (2)\ttotal: 29.6ms\tremaining: 9.84s\n",
            "3:\tlearn: 0.5812301\ttest: 0.5789848\tbest: 0.5789848 (3)\ttotal: 39.2ms\tremaining: 9.75s\n",
            "4:\tlearn: 0.5623676\ttest: 0.5597811\tbest: 0.5597811 (4)\ttotal: 49ms\tremaining: 9.76s\n",
            "5:\tlearn: 0.5439208\ttest: 0.5407338\tbest: 0.5407338 (5)\ttotal: 58.1ms\tremaining: 9.63s\n",
            "6:\tlearn: 0.5283914\ttest: 0.5248865\tbest: 0.5248865 (6)\ttotal: 67.2ms\tremaining: 9.54s\n",
            "7:\tlearn: 0.5128228\ttest: 0.5087554\tbest: 0.5087554 (7)\ttotal: 76.1ms\tremaining: 9.44s\n",
            "8:\tlearn: 0.5013971\ttest: 0.4972222\tbest: 0.4972222 (8)\ttotal: 84.8ms\tremaining: 9.34s\n",
            "9:\tlearn: 0.4908716\ttest: 0.4866199\tbest: 0.4866199 (9)\ttotal: 93.3ms\tremaining: 9.23s\n",
            "10:\tlearn: 0.4810451\ttest: 0.4763755\tbest: 0.4763755 (10)\ttotal: 103ms\tremaining: 9.26s\n",
            "11:\tlearn: 0.4718870\ttest: 0.4667026\tbest: 0.4667026 (11)\ttotal: 112ms\tremaining: 9.19s\n",
            "12:\tlearn: 0.4642582\ttest: 0.4590608\tbest: 0.4590608 (12)\ttotal: 121ms\tremaining: 9.18s\n",
            "13:\tlearn: 0.4585066\ttest: 0.4528414\tbest: 0.4528414 (13)\ttotal: 127ms\tremaining: 8.97s\n",
            "14:\tlearn: 0.4527305\ttest: 0.4468576\tbest: 0.4468576 (14)\ttotal: 136ms\tremaining: 8.94s\n",
            "15:\tlearn: 0.4471868\ttest: 0.4413692\tbest: 0.4413692 (15)\ttotal: 147ms\tremaining: 9.04s\n",
            "16:\tlearn: 0.4423213\ttest: 0.4363694\tbest: 0.4363694 (16)\ttotal: 155ms\tremaining: 8.94s\n",
            "17:\tlearn: 0.4378927\ttest: 0.4320515\tbest: 0.4320515 (17)\ttotal: 163ms\tremaining: 8.87s\n",
            "18:\tlearn: 0.4338854\ttest: 0.4277393\tbest: 0.4277393 (18)\ttotal: 170ms\tremaining: 8.77s\n",
            "19:\tlearn: 0.4302512\ttest: 0.4237694\tbest: 0.4237694 (19)\ttotal: 179ms\tremaining: 8.79s\n",
            "20:\tlearn: 0.4265841\ttest: 0.4199753\tbest: 0.4199753 (20)\ttotal: 189ms\tremaining: 8.79s\n",
            "21:\tlearn: 0.4233834\ttest: 0.4169970\tbest: 0.4169970 (21)\ttotal: 202ms\tremaining: 8.97s\n",
            "22:\tlearn: 0.4202692\ttest: 0.4140458\tbest: 0.4140458 (22)\ttotal: 211ms\tremaining: 8.98s\n",
            "23:\tlearn: 0.4178780\ttest: 0.4115649\tbest: 0.4115649 (23)\ttotal: 222ms\tremaining: 9.03s\n",
            "24:\tlearn: 0.4149948\ttest: 0.4087721\tbest: 0.4087721 (24)\ttotal: 232ms\tremaining: 9.04s\n",
            "25:\tlearn: 0.4126653\ttest: 0.4064672\tbest: 0.4064672 (25)\ttotal: 240ms\tremaining: 8.99s\n",
            "26:\tlearn: 0.4106186\ttest: 0.4044130\tbest: 0.4044130 (26)\ttotal: 248ms\tremaining: 8.95s\n",
            "27:\tlearn: 0.4087721\ttest: 0.4024298\tbest: 0.4024298 (27)\ttotal: 257ms\tremaining: 8.94s\n",
            "28:\tlearn: 0.4075717\ttest: 0.4014337\tbest: 0.4014337 (28)\ttotal: 266ms\tremaining: 8.92s\n",
            "29:\tlearn: 0.4058784\ttest: 0.3996960\tbest: 0.3996960 (29)\ttotal: 275ms\tremaining: 8.89s\n",
            "30:\tlearn: 0.4045638\ttest: 0.3985762\tbest: 0.3985762 (30)\ttotal: 283ms\tremaining: 8.85s\n",
            "31:\tlearn: 0.4032704\ttest: 0.3972178\tbest: 0.3972178 (31)\ttotal: 292ms\tremaining: 8.83s\n",
            "32:\tlearn: 0.4013370\ttest: 0.3953230\tbest: 0.3953230 (32)\ttotal: 301ms\tremaining: 8.82s\n",
            "33:\tlearn: 0.3999416\ttest: 0.3940150\tbest: 0.3940150 (33)\ttotal: 310ms\tremaining: 8.8s\n",
            "34:\tlearn: 0.3984801\ttest: 0.3925272\tbest: 0.3925272 (34)\ttotal: 319ms\tremaining: 8.78s\n",
            "35:\tlearn: 0.3977396\ttest: 0.3919320\tbest: 0.3919320 (35)\ttotal: 327ms\tremaining: 8.77s\n",
            "36:\tlearn: 0.3968450\ttest: 0.3910326\tbest: 0.3910326 (36)\ttotal: 343ms\tremaining: 8.94s\n",
            "37:\tlearn: 0.3956561\ttest: 0.3900055\tbest: 0.3900055 (37)\ttotal: 358ms\tremaining: 9.06s\n",
            "38:\tlearn: 0.3946156\ttest: 0.3890090\tbest: 0.3890090 (38)\ttotal: 368ms\tremaining: 9.06s\n",
            "39:\tlearn: 0.3941468\ttest: 0.3888591\tbest: 0.3888591 (39)\ttotal: 376ms\tremaining: 9.03s\n",
            "40:\tlearn: 0.3931968\ttest: 0.3880450\tbest: 0.3880450 (40)\ttotal: 386ms\tremaining: 9.03s\n",
            "41:\tlearn: 0.3921366\ttest: 0.3874778\tbest: 0.3874778 (41)\ttotal: 394ms\tremaining: 8.99s\n",
            "42:\tlearn: 0.3913450\ttest: 0.3869088\tbest: 0.3869088 (42)\ttotal: 405ms\tremaining: 9.02s\n",
            "43:\tlearn: 0.3910880\ttest: 0.3866437\tbest: 0.3866437 (43)\ttotal: 415ms\tremaining: 9.01s\n",
            "44:\tlearn: 0.3904244\ttest: 0.3862477\tbest: 0.3862477 (44)\ttotal: 424ms\tremaining: 9s\n",
            "45:\tlearn: 0.3898607\ttest: 0.3858239\tbest: 0.3858239 (45)\ttotal: 433ms\tremaining: 8.98s\n",
            "46:\tlearn: 0.3893831\ttest: 0.3855446\tbest: 0.3855446 (46)\ttotal: 442ms\tremaining: 8.97s\n",
            "47:\tlearn: 0.3889048\ttest: 0.3851412\tbest: 0.3851412 (47)\ttotal: 449ms\tremaining: 8.91s\n",
            "48:\tlearn: 0.3883082\ttest: 0.3848745\tbest: 0.3848745 (48)\ttotal: 458ms\tremaining: 8.89s\n",
            "49:\tlearn: 0.3878309\ttest: 0.3847686\tbest: 0.3847686 (49)\ttotal: 467ms\tremaining: 8.88s\n",
            "50:\tlearn: 0.3874641\ttest: 0.3846389\tbest: 0.3846389 (50)\ttotal: 476ms\tremaining: 8.86s\n",
            "51:\tlearn: 0.3869400\ttest: 0.3843574\tbest: 0.3843574 (51)\ttotal: 485ms\tremaining: 8.84s\n",
            "52:\tlearn: 0.3865763\ttest: 0.3841533\tbest: 0.3841533 (52)\ttotal: 494ms\tremaining: 8.83s\n",
            "53:\tlearn: 0.3858819\ttest: 0.3833732\tbest: 0.3833732 (53)\ttotal: 503ms\tremaining: 8.81s\n",
            "54:\tlearn: 0.3852471\ttest: 0.3827051\tbest: 0.3827051 (54)\ttotal: 512ms\tremaining: 8.8s\n",
            "55:\tlearn: 0.3849316\ttest: 0.3826196\tbest: 0.3826196 (55)\ttotal: 520ms\tremaining: 8.77s\n",
            "56:\tlearn: 0.3845194\ttest: 0.3826328\tbest: 0.3826196 (55)\ttotal: 529ms\tremaining: 8.76s\n",
            "57:\tlearn: 0.3842743\ttest: 0.3825825\tbest: 0.3825825 (57)\ttotal: 539ms\tremaining: 8.76s\n",
            "58:\tlearn: 0.3841988\ttest: 0.3825983\tbest: 0.3825825 (57)\ttotal: 548ms\tremaining: 8.74s\n",
            "59:\tlearn: 0.3840705\ttest: 0.3826390\tbest: 0.3825825 (57)\ttotal: 559ms\tremaining: 8.76s\n",
            "60:\tlearn: 0.3838948\ttest: 0.3826393\tbest: 0.3825825 (57)\ttotal: 568ms\tremaining: 8.74s\n",
            "61:\tlearn: 0.3836669\ttest: 0.3825813\tbest: 0.3825813 (61)\ttotal: 577ms\tremaining: 8.73s\n",
            "62:\tlearn: 0.3832024\ttest: 0.3823559\tbest: 0.3823559 (62)\ttotal: 587ms\tremaining: 8.73s\n",
            "63:\tlearn: 0.3829441\ttest: 0.3822054\tbest: 0.3822054 (63)\ttotal: 596ms\tremaining: 8.71s\n",
            "64:\tlearn: 0.3825352\ttest: 0.3820717\tbest: 0.3820717 (64)\ttotal: 609ms\tremaining: 8.76s\n",
            "65:\tlearn: 0.3822318\ttest: 0.3818800\tbest: 0.3818800 (65)\ttotal: 620ms\tremaining: 8.77s\n",
            "66:\tlearn: 0.3816709\ttest: 0.3817996\tbest: 0.3817996 (66)\ttotal: 629ms\tremaining: 8.75s\n",
            "67:\tlearn: 0.3811518\ttest: 0.3813110\tbest: 0.3813110 (67)\ttotal: 638ms\tremaining: 8.75s\n",
            "68:\tlearn: 0.3809587\ttest: 0.3813676\tbest: 0.3813110 (67)\ttotal: 648ms\tremaining: 8.74s\n",
            "69:\tlearn: 0.3808935\ttest: 0.3813616\tbest: 0.3813110 (67)\ttotal: 655ms\tremaining: 8.7s\n",
            "70:\tlearn: 0.3804046\ttest: 0.3809674\tbest: 0.3809674 (70)\ttotal: 664ms\tremaining: 8.69s\n",
            "71:\tlearn: 0.3802453\ttest: 0.3808351\tbest: 0.3808351 (71)\ttotal: 674ms\tremaining: 8.69s\n",
            "72:\tlearn: 0.3796020\ttest: 0.3805379\tbest: 0.3805379 (72)\ttotal: 683ms\tremaining: 8.68s\n",
            "73:\tlearn: 0.3792821\ttest: 0.3805150\tbest: 0.3805150 (73)\ttotal: 692ms\tremaining: 8.65s\n",
            "74:\tlearn: 0.3790769\ttest: 0.3804658\tbest: 0.3804658 (74)\ttotal: 701ms\tremaining: 8.65s\n",
            "75:\tlearn: 0.3788170\ttest: 0.3803574\tbest: 0.3803574 (75)\ttotal: 710ms\tremaining: 8.64s\n",
            "76:\tlearn: 0.3784781\ttest: 0.3803494\tbest: 0.3803494 (76)\ttotal: 720ms\tremaining: 8.63s\n",
            "77:\tlearn: 0.3783261\ttest: 0.3802951\tbest: 0.3802951 (77)\ttotal: 729ms\tremaining: 8.61s\n",
            "78:\tlearn: 0.3781036\ttest: 0.3802102\tbest: 0.3802102 (78)\ttotal: 737ms\tremaining: 8.6s\n",
            "79:\tlearn: 0.3778646\ttest: 0.3799213\tbest: 0.3799213 (79)\ttotal: 747ms\tremaining: 8.6s\n",
            "80:\tlearn: 0.3775588\ttest: 0.3797648\tbest: 0.3797648 (80)\ttotal: 757ms\tremaining: 8.59s\n",
            "81:\tlearn: 0.3772590\ttest: 0.3795846\tbest: 0.3795846 (81)\ttotal: 767ms\tremaining: 8.58s\n",
            "82:\tlearn: 0.3771275\ttest: 0.3796303\tbest: 0.3795846 (81)\ttotal: 776ms\tremaining: 8.58s\n",
            "83:\tlearn: 0.3770254\ttest: 0.3796340\tbest: 0.3795846 (81)\ttotal: 785ms\tremaining: 8.56s\n",
            "84:\tlearn: 0.3768046\ttest: 0.3796261\tbest: 0.3795846 (81)\ttotal: 794ms\tremaining: 8.55s\n",
            "85:\tlearn: 0.3766956\ttest: 0.3796256\tbest: 0.3795846 (81)\ttotal: 803ms\tremaining: 8.53s\n",
            "86:\tlearn: 0.3764465\ttest: 0.3796589\tbest: 0.3795846 (81)\ttotal: 815ms\tremaining: 8.55s\n",
            "87:\tlearn: 0.3764261\ttest: 0.3796456\tbest: 0.3795846 (81)\ttotal: 824ms\tremaining: 8.54s\n",
            "88:\tlearn: 0.3762542\ttest: 0.3795703\tbest: 0.3795703 (88)\ttotal: 835ms\tremaining: 8.55s\n",
            "89:\tlearn: 0.3761853\ttest: 0.3795783\tbest: 0.3795703 (88)\ttotal: 849ms\tremaining: 8.58s\n",
            "90:\tlearn: 0.3761851\ttest: 0.3795772\tbest: 0.3795703 (88)\ttotal: 853ms\tremaining: 8.52s\n",
            "91:\tlearn: 0.3760542\ttest: 0.3795121\tbest: 0.3795121 (91)\ttotal: 862ms\tremaining: 8.5s\n",
            "92:\tlearn: 0.3757238\ttest: 0.3794222\tbest: 0.3794222 (92)\ttotal: 871ms\tremaining: 8.49s\n",
            "93:\tlearn: 0.3756707\ttest: 0.3793371\tbest: 0.3793371 (93)\ttotal: 880ms\tremaining: 8.48s\n",
            "94:\tlearn: 0.3753678\ttest: 0.3790648\tbest: 0.3790648 (94)\ttotal: 889ms\tremaining: 8.47s\n",
            "95:\tlearn: 0.3752547\ttest: 0.3790450\tbest: 0.3790450 (95)\ttotal: 897ms\tremaining: 8.45s\n",
            "96:\tlearn: 0.3751543\ttest: 0.3790270\tbest: 0.3790270 (96)\ttotal: 907ms\tremaining: 8.44s\n",
            "97:\tlearn: 0.3746986\ttest: 0.3788595\tbest: 0.3788595 (97)\ttotal: 915ms\tremaining: 8.43s\n",
            "98:\tlearn: 0.3744522\ttest: 0.3787058\tbest: 0.3787058 (98)\ttotal: 924ms\tremaining: 8.41s\n",
            "99:\tlearn: 0.3741856\ttest: 0.3785610\tbest: 0.3785610 (99)\ttotal: 934ms\tremaining: 8.41s\n",
            "100:\tlearn: 0.3739425\ttest: 0.3784892\tbest: 0.3784892 (100)\ttotal: 944ms\tremaining: 8.4s\n",
            "101:\tlearn: 0.3738097\ttest: 0.3786282\tbest: 0.3784892 (100)\ttotal: 960ms\tremaining: 8.45s\n",
            "102:\tlearn: 0.3736244\ttest: 0.3786548\tbest: 0.3784892 (100)\ttotal: 969ms\tremaining: 8.44s\n",
            "103:\tlearn: 0.3734975\ttest: 0.3786332\tbest: 0.3784892 (100)\ttotal: 977ms\tremaining: 8.42s\n",
            "104:\tlearn: 0.3734056\ttest: 0.3786019\tbest: 0.3784892 (100)\ttotal: 986ms\tremaining: 8.4s\n",
            "105:\tlearn: 0.3731888\ttest: 0.3784781\tbest: 0.3784781 (105)\ttotal: 993ms\tremaining: 8.38s\n",
            "106:\tlearn: 0.3730139\ttest: 0.3784025\tbest: 0.3784025 (106)\ttotal: 1s\tremaining: 8.38s\n",
            "107:\tlearn: 0.3730139\ttest: 0.3784025\tbest: 0.3784025 (107)\ttotal: 1.01s\tremaining: 8.33s\n",
            "108:\tlearn: 0.3728599\ttest: 0.3783266\tbest: 0.3783266 (108)\ttotal: 1.02s\tremaining: 8.36s\n",
            "109:\tlearn: 0.3727718\ttest: 0.3783172\tbest: 0.3783172 (109)\ttotal: 1.03s\tremaining: 8.34s\n",
            "110:\tlearn: 0.3726299\ttest: 0.3782885\tbest: 0.3782885 (110)\ttotal: 1.04s\tremaining: 8.33s\n",
            "111:\tlearn: 0.3725005\ttest: 0.3783492\tbest: 0.3782885 (110)\ttotal: 1.05s\tremaining: 8.31s\n",
            "112:\tlearn: 0.3724017\ttest: 0.3783322\tbest: 0.3782885 (110)\ttotal: 1.06s\tremaining: 8.29s\n",
            "113:\tlearn: 0.3722268\ttest: 0.3782632\tbest: 0.3782632 (113)\ttotal: 1.06s\tremaining: 8.28s\n",
            "114:\tlearn: 0.3721303\ttest: 0.3782908\tbest: 0.3782632 (113)\ttotal: 1.07s\tremaining: 8.26s\n",
            "115:\tlearn: 0.3720458\ttest: 0.3782592\tbest: 0.3782592 (115)\ttotal: 1.08s\tremaining: 8.25s\n",
            "116:\tlearn: 0.3719798\ttest: 0.3782933\tbest: 0.3782592 (115)\ttotal: 1.09s\tremaining: 8.24s\n",
            "117:\tlearn: 0.3719412\ttest: 0.3783008\tbest: 0.3782592 (115)\ttotal: 1.1s\tremaining: 8.22s\n",
            "118:\tlearn: 0.3717572\ttest: 0.3782974\tbest: 0.3782592 (115)\ttotal: 1.11s\tremaining: 8.21s\n",
            "119:\tlearn: 0.3716869\ttest: 0.3783182\tbest: 0.3782592 (115)\ttotal: 1.12s\tremaining: 8.19s\n",
            "120:\tlearn: 0.3715281\ttest: 0.3784119\tbest: 0.3782592 (115)\ttotal: 1.13s\tremaining: 8.18s\n",
            "121:\tlearn: 0.3714067\ttest: 0.3783754\tbest: 0.3782592 (115)\ttotal: 1.13s\tremaining: 8.16s\n",
            "122:\tlearn: 0.3712559\ttest: 0.3783856\tbest: 0.3782592 (115)\ttotal: 1.14s\tremaining: 8.15s\n",
            "123:\tlearn: 0.3710173\ttest: 0.3783630\tbest: 0.3782592 (115)\ttotal: 1.15s\tremaining: 8.15s\n",
            "124:\tlearn: 0.3705904\ttest: 0.3783044\tbest: 0.3782592 (115)\ttotal: 1.16s\tremaining: 8.13s\n",
            "125:\tlearn: 0.3704923\ttest: 0.3782947\tbest: 0.3782592 (115)\ttotal: 1.17s\tremaining: 8.12s\n",
            "126:\tlearn: 0.3702136\ttest: 0.3781583\tbest: 0.3781583 (126)\ttotal: 1.18s\tremaining: 8.11s\n",
            "127:\tlearn: 0.3701555\ttest: 0.3781558\tbest: 0.3781558 (127)\ttotal: 1.19s\tremaining: 8.09s\n",
            "128:\tlearn: 0.3699767\ttest: 0.3781199\tbest: 0.3781199 (128)\ttotal: 1.2s\tremaining: 8.07s\n",
            "129:\tlearn: 0.3698754\ttest: 0.3780475\tbest: 0.3780475 (129)\ttotal: 1.2s\tremaining: 8.06s\n",
            "130:\tlearn: 0.3695610\ttest: 0.3780114\tbest: 0.3780114 (130)\ttotal: 1.21s\tremaining: 8.05s\n",
            "131:\tlearn: 0.3693712\ttest: 0.3780560\tbest: 0.3780114 (130)\ttotal: 1.22s\tremaining: 8.04s\n",
            "132:\tlearn: 0.3692651\ttest: 0.3780275\tbest: 0.3780114 (130)\ttotal: 1.23s\tremaining: 8.03s\n",
            "133:\tlearn: 0.3691246\ttest: 0.3781368\tbest: 0.3780114 (130)\ttotal: 1.24s\tremaining: 8.02s\n",
            "134:\tlearn: 0.3690129\ttest: 0.3781846\tbest: 0.3780114 (130)\ttotal: 1.25s\tremaining: 8s\n",
            "135:\tlearn: 0.3687997\ttest: 0.3781196\tbest: 0.3780114 (130)\ttotal: 1.26s\tremaining: 7.99s\n",
            "136:\tlearn: 0.3687703\ttest: 0.3781293\tbest: 0.3780114 (130)\ttotal: 1.26s\tremaining: 7.97s\n",
            "137:\tlearn: 0.3686201\ttest: 0.3781739\tbest: 0.3780114 (130)\ttotal: 1.27s\tremaining: 7.96s\n",
            "138:\tlearn: 0.3684779\ttest: 0.3782095\tbest: 0.3780114 (130)\ttotal: 1.28s\tremaining: 7.95s\n",
            "139:\tlearn: 0.3683156\ttest: 0.3782068\tbest: 0.3780114 (130)\ttotal: 1.29s\tremaining: 7.93s\n",
            "140:\tlearn: 0.3681418\ttest: 0.3782245\tbest: 0.3780114 (130)\ttotal: 1.3s\tremaining: 7.92s\n",
            "141:\tlearn: 0.3678953\ttest: 0.3782506\tbest: 0.3780114 (130)\ttotal: 1.31s\tremaining: 7.91s\n",
            "142:\tlearn: 0.3677703\ttest: 0.3782375\tbest: 0.3780114 (130)\ttotal: 1.32s\tremaining: 7.9s\n",
            "143:\tlearn: 0.3676204\ttest: 0.3780497\tbest: 0.3780114 (130)\ttotal: 1.33s\tremaining: 7.88s\n",
            "144:\tlearn: 0.3675650\ttest: 0.3780020\tbest: 0.3780020 (144)\ttotal: 1.33s\tremaining: 7.87s\n",
            "145:\tlearn: 0.3674798\ttest: 0.3780222\tbest: 0.3780020 (144)\ttotal: 1.35s\tremaining: 7.88s\n",
            "146:\tlearn: 0.3674155\ttest: 0.3780326\tbest: 0.3780020 (144)\ttotal: 1.36s\tremaining: 7.88s\n",
            "147:\tlearn: 0.3673370\ttest: 0.3780708\tbest: 0.3780020 (144)\ttotal: 1.37s\tremaining: 7.9s\n",
            "148:\tlearn: 0.3671327\ttest: 0.3780893\tbest: 0.3780020 (144)\ttotal: 1.38s\tremaining: 7.88s\n",
            "149:\tlearn: 0.3670936\ttest: 0.3780500\tbest: 0.3780020 (144)\ttotal: 1.39s\tremaining: 7.87s\n",
            "150:\tlearn: 0.3668621\ttest: 0.3780586\tbest: 0.3780020 (144)\ttotal: 1.4s\tremaining: 7.86s\n",
            "151:\tlearn: 0.3666575\ttest: 0.3781129\tbest: 0.3780020 (144)\ttotal: 1.41s\tremaining: 7.85s\n",
            "152:\tlearn: 0.3665337\ttest: 0.3780931\tbest: 0.3780020 (144)\ttotal: 1.42s\tremaining: 7.84s\n",
            "153:\tlearn: 0.3662743\ttest: 0.3779776\tbest: 0.3779776 (153)\ttotal: 1.43s\tremaining: 7.85s\n",
            "154:\tlearn: 0.3661354\ttest: 0.3780337\tbest: 0.3779776 (153)\ttotal: 1.44s\tremaining: 7.84s\n",
            "155:\tlearn: 0.3660646\ttest: 0.3779678\tbest: 0.3779678 (155)\ttotal: 1.45s\tremaining: 7.83s\n",
            "156:\tlearn: 0.3658086\ttest: 0.3778508\tbest: 0.3778508 (156)\ttotal: 1.46s\tremaining: 7.81s\n",
            "157:\tlearn: 0.3656868\ttest: 0.3778552\tbest: 0.3778508 (156)\ttotal: 1.46s\tremaining: 7.8s\n",
            "158:\tlearn: 0.3655609\ttest: 0.3778362\tbest: 0.3778362 (158)\ttotal: 1.47s\tremaining: 7.79s\n",
            "159:\tlearn: 0.3652911\ttest: 0.3777663\tbest: 0.3777663 (159)\ttotal: 1.48s\tremaining: 7.77s\n",
            "160:\tlearn: 0.3651144\ttest: 0.3777564\tbest: 0.3777564 (160)\ttotal: 1.49s\tremaining: 7.76s\n",
            "161:\tlearn: 0.3649519\ttest: 0.3777481\tbest: 0.3777481 (161)\ttotal: 1.5s\tremaining: 7.75s\n",
            "162:\tlearn: 0.3644640\ttest: 0.3774719\tbest: 0.3774719 (162)\ttotal: 1.51s\tremaining: 7.75s\n",
            "163:\tlearn: 0.3643158\ttest: 0.3774682\tbest: 0.3774682 (163)\ttotal: 1.52s\tremaining: 7.74s\n",
            "164:\tlearn: 0.3640044\ttest: 0.3774664\tbest: 0.3774664 (164)\ttotal: 1.53s\tremaining: 7.73s\n",
            "165:\tlearn: 0.3639509\ttest: 0.3774963\tbest: 0.3774664 (164)\ttotal: 1.54s\tremaining: 7.72s\n",
            "166:\tlearn: 0.3637574\ttest: 0.3775750\tbest: 0.3774664 (164)\ttotal: 1.55s\tremaining: 7.71s\n",
            "167:\tlearn: 0.3636299\ttest: 0.3775938\tbest: 0.3774664 (164)\ttotal: 1.56s\tremaining: 7.71s\n",
            "168:\tlearn: 0.3635413\ttest: 0.3776169\tbest: 0.3774664 (164)\ttotal: 1.56s\tremaining: 7.69s\n",
            "169:\tlearn: 0.3635087\ttest: 0.3776344\tbest: 0.3774664 (164)\ttotal: 1.57s\tremaining: 7.68s\n",
            "170:\tlearn: 0.3634664\ttest: 0.3776324\tbest: 0.3774664 (164)\ttotal: 1.58s\tremaining: 7.67s\n",
            "171:\tlearn: 0.3632983\ttest: 0.3775790\tbest: 0.3774664 (164)\ttotal: 1.59s\tremaining: 7.66s\n",
            "172:\tlearn: 0.3631319\ttest: 0.3776391\tbest: 0.3774664 (164)\ttotal: 1.6s\tremaining: 7.64s\n",
            "173:\tlearn: 0.3631101\ttest: 0.3776356\tbest: 0.3774664 (164)\ttotal: 1.61s\tremaining: 7.63s\n",
            "174:\tlearn: 0.3628495\ttest: 0.3776545\tbest: 0.3774664 (164)\ttotal: 1.62s\tremaining: 7.64s\n",
            "175:\tlearn: 0.3627425\ttest: 0.3776298\tbest: 0.3774664 (164)\ttotal: 1.63s\tremaining: 7.64s\n",
            "176:\tlearn: 0.3624664\ttest: 0.3774974\tbest: 0.3774664 (164)\ttotal: 1.64s\tremaining: 7.63s\n",
            "177:\tlearn: 0.3622223\ttest: 0.3776004\tbest: 0.3774664 (164)\ttotal: 1.65s\tremaining: 7.62s\n",
            "178:\tlearn: 0.3622124\ttest: 0.3776003\tbest: 0.3774664 (164)\ttotal: 1.66s\tremaining: 7.6s\n",
            "179:\tlearn: 0.3620252\ttest: 0.3775789\tbest: 0.3774664 (164)\ttotal: 1.67s\tremaining: 7.59s\n",
            "180:\tlearn: 0.3618470\ttest: 0.3775015\tbest: 0.3774664 (164)\ttotal: 1.68s\tremaining: 7.58s\n",
            "181:\tlearn: 0.3618453\ttest: 0.3775020\tbest: 0.3774664 (164)\ttotal: 1.68s\tremaining: 7.55s\n",
            "182:\tlearn: 0.3617438\ttest: 0.3775403\tbest: 0.3774664 (164)\ttotal: 1.69s\tremaining: 7.54s\n",
            "183:\tlearn: 0.3615111\ttest: 0.3775880\tbest: 0.3774664 (164)\ttotal: 1.7s\tremaining: 7.55s\n",
            "184:\tlearn: 0.3612634\ttest: 0.3777148\tbest: 0.3774664 (164)\ttotal: 1.71s\tremaining: 7.54s\n",
            "185:\tlearn: 0.3611211\ttest: 0.3777113\tbest: 0.3774664 (164)\ttotal: 1.72s\tremaining: 7.53s\n",
            "186:\tlearn: 0.3610184\ttest: 0.3777634\tbest: 0.3774664 (164)\ttotal: 1.73s\tremaining: 7.52s\n",
            "187:\tlearn: 0.3609907\ttest: 0.3777050\tbest: 0.3774664 (164)\ttotal: 1.74s\tremaining: 7.5s\n",
            "188:\tlearn: 0.3608185\ttest: 0.3776286\tbest: 0.3774664 (164)\ttotal: 1.75s\tremaining: 7.49s\n",
            "189:\tlearn: 0.3605943\ttest: 0.3776942\tbest: 0.3774664 (164)\ttotal: 1.75s\tremaining: 7.48s\n",
            "190:\tlearn: 0.3603085\ttest: 0.3777051\tbest: 0.3774664 (164)\ttotal: 1.76s\tremaining: 7.47s\n",
            "191:\tlearn: 0.3602480\ttest: 0.3776758\tbest: 0.3774664 (164)\ttotal: 1.77s\tremaining: 7.46s\n",
            "192:\tlearn: 0.3601002\ttest: 0.3775669\tbest: 0.3774664 (164)\ttotal: 1.78s\tremaining: 7.44s\n",
            "193:\tlearn: 0.3600591\ttest: 0.3776391\tbest: 0.3774664 (164)\ttotal: 1.79s\tremaining: 7.43s\n",
            "194:\tlearn: 0.3596819\ttest: 0.3777820\tbest: 0.3774664 (164)\ttotal: 1.8s\tremaining: 7.42s\n",
            "195:\tlearn: 0.3594215\ttest: 0.3777794\tbest: 0.3774664 (164)\ttotal: 1.8s\tremaining: 7.41s\n",
            "196:\tlearn: 0.3591954\ttest: 0.3777581\tbest: 0.3774664 (164)\ttotal: 1.81s\tremaining: 7.4s\n",
            "197:\tlearn: 0.3591297\ttest: 0.3778053\tbest: 0.3774664 (164)\ttotal: 1.82s\tremaining: 7.38s\n",
            "198:\tlearn: 0.3588626\ttest: 0.3779699\tbest: 0.3774664 (164)\ttotal: 1.83s\tremaining: 7.38s\n",
            "199:\tlearn: 0.3584458\ttest: 0.3777548\tbest: 0.3774664 (164)\ttotal: 1.85s\tremaining: 7.39s\n",
            "200:\tlearn: 0.3583395\ttest: 0.3778508\tbest: 0.3774664 (164)\ttotal: 1.86s\tremaining: 7.38s\n",
            "201:\tlearn: 0.3582708\ttest: 0.3779388\tbest: 0.3774664 (164)\ttotal: 1.86s\tremaining: 7.37s\n",
            "202:\tlearn: 0.3580214\ttest: 0.3778920\tbest: 0.3774664 (164)\ttotal: 1.88s\tremaining: 7.36s\n",
            "203:\tlearn: 0.3578788\ttest: 0.3779197\tbest: 0.3774664 (164)\ttotal: 1.88s\tremaining: 7.35s\n",
            "204:\tlearn: 0.3577185\ttest: 0.3778449\tbest: 0.3774664 (164)\ttotal: 1.89s\tremaining: 7.34s\n",
            "205:\tlearn: 0.3574063\ttest: 0.3776949\tbest: 0.3774664 (164)\ttotal: 1.9s\tremaining: 7.33s\n",
            "206:\tlearn: 0.3572838\ttest: 0.3776999\tbest: 0.3774664 (164)\ttotal: 1.92s\tremaining: 7.34s\n",
            "207:\tlearn: 0.3572171\ttest: 0.3777270\tbest: 0.3774664 (164)\ttotal: 1.92s\tremaining: 7.33s\n",
            "208:\tlearn: 0.3570918\ttest: 0.3776533\tbest: 0.3774664 (164)\ttotal: 1.93s\tremaining: 7.32s\n",
            "209:\tlearn: 0.3570329\ttest: 0.3776607\tbest: 0.3774664 (164)\ttotal: 1.94s\tremaining: 7.31s\n",
            "210:\tlearn: 0.3569499\ttest: 0.3776775\tbest: 0.3774664 (164)\ttotal: 1.95s\tremaining: 7.3s\n",
            "211:\tlearn: 0.3566676\ttest: 0.3775409\tbest: 0.3774664 (164)\ttotal: 1.96s\tremaining: 7.29s\n",
            "212:\tlearn: 0.3566650\ttest: 0.3775471\tbest: 0.3774664 (164)\ttotal: 1.97s\tremaining: 7.27s\n",
            "213:\tlearn: 0.3564749\ttest: 0.3775609\tbest: 0.3774664 (164)\ttotal: 1.98s\tremaining: 7.26s\n",
            "214:\tlearn: 0.3561776\ttest: 0.3774497\tbest: 0.3774497 (214)\ttotal: 1.99s\tremaining: 7.27s\n",
            "215:\tlearn: 0.3560996\ttest: 0.3774789\tbest: 0.3774497 (214)\ttotal: 2s\tremaining: 7.26s\n",
            "216:\tlearn: 0.3560561\ttest: 0.3774686\tbest: 0.3774497 (214)\ttotal: 2.01s\tremaining: 7.25s\n",
            "217:\tlearn: 0.3558304\ttest: 0.3774402\tbest: 0.3774402 (217)\ttotal: 2.02s\tremaining: 7.24s\n",
            "218:\tlearn: 0.3555519\ttest: 0.3775155\tbest: 0.3774402 (217)\ttotal: 2.03s\tremaining: 7.24s\n",
            "219:\tlearn: 0.3552607\ttest: 0.3775273\tbest: 0.3774402 (217)\ttotal: 2.04s\tremaining: 7.23s\n",
            "220:\tlearn: 0.3548740\ttest: 0.3774227\tbest: 0.3774227 (220)\ttotal: 2.05s\tremaining: 7.22s\n",
            "221:\tlearn: 0.3548649\ttest: 0.3774279\tbest: 0.3774227 (220)\ttotal: 2.06s\tremaining: 7.21s\n",
            "222:\tlearn: 0.3546622\ttest: 0.3773496\tbest: 0.3773496 (222)\ttotal: 2.07s\tremaining: 7.2s\n",
            "223:\tlearn: 0.3544992\ttest: 0.3772772\tbest: 0.3772772 (223)\ttotal: 2.07s\tremaining: 7.19s\n",
            "224:\tlearn: 0.3543807\ttest: 0.3771577\tbest: 0.3771577 (224)\ttotal: 2.08s\tremaining: 7.18s\n",
            "225:\tlearn: 0.3543368\ttest: 0.3771567\tbest: 0.3771567 (225)\ttotal: 2.09s\tremaining: 7.17s\n",
            "226:\tlearn: 0.3543253\ttest: 0.3771486\tbest: 0.3771486 (226)\ttotal: 2.1s\tremaining: 7.15s\n",
            "227:\tlearn: 0.3541267\ttest: 0.3772406\tbest: 0.3771486 (226)\ttotal: 2.11s\tremaining: 7.14s\n",
            "228:\tlearn: 0.3539458\ttest: 0.3772063\tbest: 0.3771486 (226)\ttotal: 2.12s\tremaining: 7.13s\n",
            "229:\tlearn: 0.3537760\ttest: 0.3771866\tbest: 0.3771486 (226)\ttotal: 2.13s\tremaining: 7.12s\n",
            "230:\tlearn: 0.3536560\ttest: 0.3772334\tbest: 0.3771486 (226)\ttotal: 2.14s\tremaining: 7.11s\n",
            "231:\tlearn: 0.3536162\ttest: 0.3773187\tbest: 0.3771486 (226)\ttotal: 2.14s\tremaining: 7.1s\n",
            "232:\tlearn: 0.3535628\ttest: 0.3772350\tbest: 0.3771486 (226)\ttotal: 2.15s\tremaining: 7.09s\n",
            "233:\tlearn: 0.3533296\ttest: 0.3771910\tbest: 0.3771486 (226)\ttotal: 2.16s\tremaining: 7.07s\n",
            "234:\tlearn: 0.3528694\ttest: 0.3772655\tbest: 0.3771486 (226)\ttotal: 2.17s\tremaining: 7.06s\n",
            "235:\tlearn: 0.3527036\ttest: 0.3772599\tbest: 0.3771486 (226)\ttotal: 2.18s\tremaining: 7.05s\n",
            "236:\tlearn: 0.3525717\ttest: 0.3772069\tbest: 0.3771486 (226)\ttotal: 2.19s\tremaining: 7.04s\n",
            "237:\tlearn: 0.3524562\ttest: 0.3772579\tbest: 0.3771486 (226)\ttotal: 2.19s\tremaining: 7.03s\n",
            "238:\tlearn: 0.3523649\ttest: 0.3773072\tbest: 0.3771486 (226)\ttotal: 2.2s\tremaining: 7.02s\n",
            "239:\tlearn: 0.3519583\ttest: 0.3775115\tbest: 0.3771486 (226)\ttotal: 2.21s\tremaining: 7.01s\n",
            "240:\tlearn: 0.3517652\ttest: 0.3776018\tbest: 0.3771486 (226)\ttotal: 2.22s\tremaining: 7s\n",
            "241:\tlearn: 0.3516701\ttest: 0.3774881\tbest: 0.3771486 (226)\ttotal: 2.23s\tremaining: 6.99s\n",
            "242:\tlearn: 0.3514123\ttest: 0.3776230\tbest: 0.3771486 (226)\ttotal: 2.24s\tremaining: 6.98s\n",
            "243:\tlearn: 0.3514047\ttest: 0.3776287\tbest: 0.3771486 (226)\ttotal: 2.25s\tremaining: 6.97s\n",
            "244:\tlearn: 0.3513963\ttest: 0.3776285\tbest: 0.3771486 (226)\ttotal: 2.26s\tremaining: 6.96s\n",
            "245:\tlearn: 0.3512387\ttest: 0.3776174\tbest: 0.3771486 (226)\ttotal: 2.27s\tremaining: 6.95s\n",
            "246:\tlearn: 0.3511659\ttest: 0.3776637\tbest: 0.3771486 (226)\ttotal: 2.28s\tremaining: 6.94s\n",
            "247:\tlearn: 0.3508379\ttest: 0.3776653\tbest: 0.3771486 (226)\ttotal: 2.29s\tremaining: 6.93s\n",
            "248:\tlearn: 0.3507818\ttest: 0.3776514\tbest: 0.3771486 (226)\ttotal: 2.29s\tremaining: 6.92s\n",
            "249:\tlearn: 0.3506571\ttest: 0.3776566\tbest: 0.3771486 (226)\ttotal: 2.3s\tremaining: 6.91s\n",
            "250:\tlearn: 0.3504442\ttest: 0.3775398\tbest: 0.3771486 (226)\ttotal: 2.31s\tremaining: 6.9s\n",
            "251:\tlearn: 0.3502542\ttest: 0.3775205\tbest: 0.3771486 (226)\ttotal: 2.32s\tremaining: 6.89s\n",
            "252:\tlearn: 0.3501980\ttest: 0.3775633\tbest: 0.3771486 (226)\ttotal: 2.33s\tremaining: 6.88s\n",
            "253:\tlearn: 0.3500784\ttest: 0.3776716\tbest: 0.3771486 (226)\ttotal: 2.34s\tremaining: 6.86s\n",
            "254:\tlearn: 0.3499236\ttest: 0.3774994\tbest: 0.3771486 (226)\ttotal: 2.35s\tremaining: 6.85s\n",
            "255:\tlearn: 0.3498673\ttest: 0.3774962\tbest: 0.3771486 (226)\ttotal: 2.36s\tremaining: 6.86s\n",
            "256:\tlearn: 0.3496849\ttest: 0.3775360\tbest: 0.3771486 (226)\ttotal: 2.38s\tremaining: 6.87s\n",
            "257:\tlearn: 0.3493694\ttest: 0.3774953\tbest: 0.3771486 (226)\ttotal: 2.38s\tremaining: 6.86s\n",
            "258:\tlearn: 0.3491559\ttest: 0.3774251\tbest: 0.3771486 (226)\ttotal: 2.39s\tremaining: 6.85s\n",
            "259:\tlearn: 0.3490245\ttest: 0.3773200\tbest: 0.3771486 (226)\ttotal: 2.4s\tremaining: 6.84s\n",
            "260:\tlearn: 0.3488894\ttest: 0.3773029\tbest: 0.3771486 (226)\ttotal: 2.41s\tremaining: 6.83s\n",
            "261:\tlearn: 0.3487144\ttest: 0.3774240\tbest: 0.3771486 (226)\ttotal: 2.42s\tremaining: 6.82s\n",
            "262:\tlearn: 0.3485982\ttest: 0.3774434\tbest: 0.3771486 (226)\ttotal: 2.43s\tremaining: 6.81s\n",
            "263:\tlearn: 0.3483750\ttest: 0.3773616\tbest: 0.3771486 (226)\ttotal: 2.44s\tremaining: 6.81s\n",
            "264:\tlearn: 0.3481588\ttest: 0.3773393\tbest: 0.3771486 (226)\ttotal: 2.45s\tremaining: 6.8s\n",
            "265:\tlearn: 0.3481562\ttest: 0.3773518\tbest: 0.3771486 (226)\ttotal: 2.46s\tremaining: 6.79s\n",
            "266:\tlearn: 0.3480446\ttest: 0.3773589\tbest: 0.3771486 (226)\ttotal: 2.47s\tremaining: 6.79s\n",
            "267:\tlearn: 0.3478393\ttest: 0.3772309\tbest: 0.3771486 (226)\ttotal: 2.48s\tremaining: 6.78s\n",
            "268:\tlearn: 0.3476681\ttest: 0.3771961\tbest: 0.3771486 (226)\ttotal: 2.49s\tremaining: 6.76s\n",
            "269:\tlearn: 0.3476118\ttest: 0.3771767\tbest: 0.3771486 (226)\ttotal: 2.5s\tremaining: 6.75s\n",
            "270:\tlearn: 0.3475974\ttest: 0.3771695\tbest: 0.3771486 (226)\ttotal: 2.51s\tremaining: 6.74s\n",
            "271:\tlearn: 0.3475856\ttest: 0.3771686\tbest: 0.3771486 (226)\ttotal: 2.52s\tremaining: 6.73s\n",
            "272:\tlearn: 0.3475774\ttest: 0.3771760\tbest: 0.3771486 (226)\ttotal: 2.52s\tremaining: 6.72s\n",
            "273:\tlearn: 0.3472953\ttest: 0.3770775\tbest: 0.3770775 (273)\ttotal: 2.53s\tremaining: 6.71s\n",
            "274:\tlearn: 0.3469480\ttest: 0.3769952\tbest: 0.3769952 (274)\ttotal: 2.54s\tremaining: 6.7s\n",
            "275:\tlearn: 0.3468085\ttest: 0.3769537\tbest: 0.3769537 (275)\ttotal: 2.55s\tremaining: 6.69s\n",
            "276:\tlearn: 0.3465251\ttest: 0.3770079\tbest: 0.3769537 (275)\ttotal: 2.56s\tremaining: 6.68s\n",
            "277:\tlearn: 0.3463589\ttest: 0.3770455\tbest: 0.3769537 (275)\ttotal: 2.57s\tremaining: 6.67s\n",
            "278:\tlearn: 0.3462179\ttest: 0.3771861\tbest: 0.3769537 (275)\ttotal: 2.58s\tremaining: 6.66s\n",
            "279:\tlearn: 0.3460653\ttest: 0.3772423\tbest: 0.3769537 (275)\ttotal: 2.59s\tremaining: 6.65s\n",
            "280:\tlearn: 0.3459857\ttest: 0.3772605\tbest: 0.3769537 (275)\ttotal: 2.59s\tremaining: 6.64s\n",
            "281:\tlearn: 0.3458914\ttest: 0.3772509\tbest: 0.3769537 (275)\ttotal: 2.6s\tremaining: 6.63s\n",
            "282:\tlearn: 0.3456959\ttest: 0.3773538\tbest: 0.3769537 (275)\ttotal: 2.61s\tremaining: 6.62s\n",
            "283:\tlearn: 0.3455798\ttest: 0.3773187\tbest: 0.3769537 (275)\ttotal: 2.62s\tremaining: 6.61s\n",
            "284:\tlearn: 0.3453312\ttest: 0.3774233\tbest: 0.3769537 (275)\ttotal: 2.63s\tremaining: 6.6s\n",
            "285:\tlearn: 0.3451759\ttest: 0.3774836\tbest: 0.3769537 (275)\ttotal: 2.64s\tremaining: 6.59s\n",
            "286:\tlearn: 0.3450063\ttest: 0.3775139\tbest: 0.3769537 (275)\ttotal: 2.65s\tremaining: 6.59s\n",
            "287:\tlearn: 0.3449182\ttest: 0.3775340\tbest: 0.3769537 (275)\ttotal: 2.66s\tremaining: 6.59s\n",
            "288:\tlearn: 0.3447014\ttest: 0.3774262\tbest: 0.3769537 (275)\ttotal: 2.67s\tremaining: 6.58s\n",
            "289:\tlearn: 0.3445590\ttest: 0.3773836\tbest: 0.3769537 (275)\ttotal: 2.68s\tremaining: 6.57s\n",
            "290:\tlearn: 0.3443250\ttest: 0.3773005\tbest: 0.3769537 (275)\ttotal: 2.69s\tremaining: 6.56s\n",
            "291:\tlearn: 0.3443191\ttest: 0.3773064\tbest: 0.3769537 (275)\ttotal: 2.7s\tremaining: 6.55s\n",
            "292:\tlearn: 0.3443158\ttest: 0.3773214\tbest: 0.3769537 (275)\ttotal: 2.71s\tremaining: 6.54s\n",
            "293:\tlearn: 0.3443046\ttest: 0.3773276\tbest: 0.3769537 (275)\ttotal: 2.72s\tremaining: 6.53s\n",
            "294:\tlearn: 0.3440986\ttest: 0.3771301\tbest: 0.3769537 (275)\ttotal: 2.73s\tremaining: 6.52s\n",
            "295:\tlearn: 0.3439685\ttest: 0.3771639\tbest: 0.3769537 (275)\ttotal: 2.74s\tremaining: 6.52s\n",
            "296:\tlearn: 0.3438153\ttest: 0.3771760\tbest: 0.3769537 (275)\ttotal: 2.75s\tremaining: 6.51s\n",
            "297:\tlearn: 0.3437912\ttest: 0.3771856\tbest: 0.3769537 (275)\ttotal: 2.76s\tremaining: 6.5s\n",
            "298:\tlearn: 0.3435875\ttest: 0.3772626\tbest: 0.3769537 (275)\ttotal: 2.77s\tremaining: 6.48s\n",
            "299:\tlearn: 0.3434540\ttest: 0.3771776\tbest: 0.3769537 (275)\ttotal: 2.77s\tremaining: 6.48s\n",
            "300:\tlearn: 0.3432095\ttest: 0.3771751\tbest: 0.3769537 (275)\ttotal: 2.78s\tremaining: 6.47s\n",
            "301:\tlearn: 0.3430419\ttest: 0.3771316\tbest: 0.3769537 (275)\ttotal: 2.79s\tremaining: 6.46s\n",
            "302:\tlearn: 0.3429442\ttest: 0.3771350\tbest: 0.3769537 (275)\ttotal: 2.8s\tremaining: 6.45s\n",
            "303:\tlearn: 0.3427148\ttest: 0.3772050\tbest: 0.3769537 (275)\ttotal: 2.81s\tremaining: 6.44s\n",
            "304:\tlearn: 0.3426115\ttest: 0.3771616\tbest: 0.3769537 (275)\ttotal: 2.82s\tremaining: 6.43s\n",
            "305:\tlearn: 0.3423384\ttest: 0.3771738\tbest: 0.3769537 (275)\ttotal: 2.83s\tremaining: 6.42s\n",
            "306:\tlearn: 0.3421654\ttest: 0.3770973\tbest: 0.3769537 (275)\ttotal: 2.85s\tremaining: 6.42s\n",
            "307:\tlearn: 0.3421538\ttest: 0.3770964\tbest: 0.3769537 (275)\ttotal: 2.86s\tremaining: 6.42s\n",
            "308:\tlearn: 0.3421437\ttest: 0.3770966\tbest: 0.3769537 (275)\ttotal: 2.87s\tremaining: 6.41s\n",
            "309:\tlearn: 0.3419481\ttest: 0.3770897\tbest: 0.3769537 (275)\ttotal: 2.88s\tremaining: 6.4s\n",
            "310:\tlearn: 0.3418781\ttest: 0.3771124\tbest: 0.3769537 (275)\ttotal: 2.89s\tremaining: 6.4s\n",
            "311:\tlearn: 0.3416653\ttest: 0.3769494\tbest: 0.3769494 (311)\ttotal: 2.9s\tremaining: 6.39s\n",
            "312:\tlearn: 0.3414583\ttest: 0.3769390\tbest: 0.3769390 (312)\ttotal: 2.9s\tremaining: 6.38s\n",
            "313:\tlearn: 0.3414532\ttest: 0.3769449\tbest: 0.3769390 (312)\ttotal: 2.91s\tremaining: 6.37s\n",
            "314:\tlearn: 0.3414520\ttest: 0.3769464\tbest: 0.3769390 (312)\ttotal: 2.92s\tremaining: 6.35s\n",
            "315:\tlearn: 0.3414300\ttest: 0.3769235\tbest: 0.3769235 (315)\ttotal: 2.93s\tremaining: 6.34s\n",
            "316:\tlearn: 0.3412627\ttest: 0.3770321\tbest: 0.3769235 (315)\ttotal: 2.94s\tremaining: 6.33s\n",
            "317:\tlearn: 0.3408850\ttest: 0.3770002\tbest: 0.3769235 (315)\ttotal: 2.95s\tremaining: 6.32s\n",
            "318:\tlearn: 0.3406967\ttest: 0.3769744\tbest: 0.3769235 (315)\ttotal: 2.96s\tremaining: 6.31s\n",
            "319:\tlearn: 0.3405449\ttest: 0.3771345\tbest: 0.3769235 (315)\ttotal: 2.96s\tremaining: 6.3s\n",
            "320:\tlearn: 0.3403331\ttest: 0.3770713\tbest: 0.3769235 (315)\ttotal: 2.98s\tremaining: 6.29s\n",
            "321:\tlearn: 0.3403093\ttest: 0.3770789\tbest: 0.3769235 (315)\ttotal: 2.98s\tremaining: 6.28s\n",
            "322:\tlearn: 0.3401175\ttest: 0.3769357\tbest: 0.3769235 (315)\ttotal: 2.99s\tremaining: 6.28s\n",
            "323:\tlearn: 0.3399553\ttest: 0.3769211\tbest: 0.3769211 (323)\ttotal: 3s\tremaining: 6.26s\n",
            "324:\tlearn: 0.3397311\ttest: 0.3769573\tbest: 0.3769211 (323)\ttotal: 3.01s\tremaining: 6.25s\n",
            "325:\tlearn: 0.3396719\ttest: 0.3768139\tbest: 0.3768139 (325)\ttotal: 3.02s\tremaining: 6.25s\n",
            "326:\tlearn: 0.3395608\ttest: 0.3769246\tbest: 0.3768139 (325)\ttotal: 3.03s\tremaining: 6.24s\n",
            "327:\tlearn: 0.3393667\ttest: 0.3769865\tbest: 0.3768139 (325)\ttotal: 3.04s\tremaining: 6.23s\n",
            "328:\tlearn: 0.3392183\ttest: 0.3770999\tbest: 0.3768139 (325)\ttotal: 3.05s\tremaining: 6.22s\n",
            "329:\tlearn: 0.3389711\ttest: 0.3770936\tbest: 0.3768139 (325)\ttotal: 3.06s\tremaining: 6.21s\n",
            "330:\tlearn: 0.3387579\ttest: 0.3770885\tbest: 0.3768139 (325)\ttotal: 3.07s\tremaining: 6.2s\n",
            "331:\tlearn: 0.3386041\ttest: 0.3771263\tbest: 0.3768139 (325)\ttotal: 3.08s\tremaining: 6.19s\n",
            "332:\tlearn: 0.3385003\ttest: 0.3771625\tbest: 0.3768139 (325)\ttotal: 3.08s\tremaining: 6.18s\n",
            "333:\tlearn: 0.3383642\ttest: 0.3771283\tbest: 0.3768139 (325)\ttotal: 3.09s\tremaining: 6.17s\n",
            "334:\tlearn: 0.3382241\ttest: 0.3770509\tbest: 0.3768139 (325)\ttotal: 3.1s\tremaining: 6.16s\n",
            "335:\tlearn: 0.3378524\ttest: 0.3769002\tbest: 0.3768139 (325)\ttotal: 3.11s\tremaining: 6.15s\n",
            "336:\tlearn: 0.3376621\ttest: 0.3768398\tbest: 0.3768139 (325)\ttotal: 3.12s\tremaining: 6.14s\n",
            "337:\tlearn: 0.3374811\ttest: 0.3768585\tbest: 0.3768139 (325)\ttotal: 3.13s\tremaining: 6.13s\n",
            "338:\tlearn: 0.3373625\ttest: 0.3768795\tbest: 0.3768139 (325)\ttotal: 3.14s\tremaining: 6.13s\n",
            "339:\tlearn: 0.3371667\ttest: 0.3767984\tbest: 0.3767984 (339)\ttotal: 3.15s\tremaining: 6.12s\n",
            "340:\tlearn: 0.3371569\ttest: 0.3767977\tbest: 0.3767977 (340)\ttotal: 3.16s\tremaining: 6.11s\n",
            "341:\tlearn: 0.3369172\ttest: 0.3767361\tbest: 0.3767361 (341)\ttotal: 3.17s\tremaining: 6.1s\n",
            "342:\tlearn: 0.3368538\ttest: 0.3767770\tbest: 0.3767361 (341)\ttotal: 3.18s\tremaining: 6.09s\n",
            "343:\tlearn: 0.3367045\ttest: 0.3767865\tbest: 0.3767361 (341)\ttotal: 3.19s\tremaining: 6.08s\n",
            "344:\tlearn: 0.3366043\ttest: 0.3767607\tbest: 0.3767361 (341)\ttotal: 3.2s\tremaining: 6.07s\n",
            "345:\tlearn: 0.3364998\ttest: 0.3767886\tbest: 0.3767361 (341)\ttotal: 3.21s\tremaining: 6.06s\n",
            "346:\tlearn: 0.3363968\ttest: 0.3768796\tbest: 0.3767361 (341)\ttotal: 3.21s\tremaining: 6.05s\n",
            "347:\tlearn: 0.3362919\ttest: 0.3768526\tbest: 0.3767361 (341)\ttotal: 3.22s\tremaining: 6.04s\n",
            "348:\tlearn: 0.3361962\ttest: 0.3768479\tbest: 0.3767361 (341)\ttotal: 3.23s\tremaining: 6.03s\n",
            "349:\tlearn: 0.3359559\ttest: 0.3769791\tbest: 0.3767361 (341)\ttotal: 3.25s\tremaining: 6.03s\n",
            "350:\tlearn: 0.3358569\ttest: 0.3770629\tbest: 0.3767361 (341)\ttotal: 3.25s\tremaining: 6.02s\n",
            "351:\tlearn: 0.3358455\ttest: 0.3770871\tbest: 0.3767361 (341)\ttotal: 3.27s\tremaining: 6.01s\n",
            "352:\tlearn: 0.3358372\ttest: 0.3771051\tbest: 0.3767361 (341)\ttotal: 3.28s\tremaining: 6s\n",
            "353:\tlearn: 0.3358116\ttest: 0.3771359\tbest: 0.3767361 (341)\ttotal: 3.28s\tremaining: 5.99s\n",
            "354:\tlearn: 0.3356088\ttest: 0.3771487\tbest: 0.3767361 (341)\ttotal: 3.29s\tremaining: 5.98s\n",
            "355:\tlearn: 0.3354897\ttest: 0.3771811\tbest: 0.3767361 (341)\ttotal: 3.3s\tremaining: 5.97s\n",
            "356:\tlearn: 0.3354856\ttest: 0.3771863\tbest: 0.3767361 (341)\ttotal: 3.31s\tremaining: 5.96s\n",
            "357:\tlearn: 0.3352662\ttest: 0.3771303\tbest: 0.3767361 (341)\ttotal: 3.32s\tremaining: 5.95s\n",
            "358:\tlearn: 0.3351089\ttest: 0.3771170\tbest: 0.3767361 (341)\ttotal: 3.33s\tremaining: 5.94s\n",
            "359:\tlearn: 0.3349421\ttest: 0.3770326\tbest: 0.3767361 (341)\ttotal: 3.34s\tremaining: 5.93s\n",
            "360:\tlearn: 0.3349334\ttest: 0.3770124\tbest: 0.3767361 (341)\ttotal: 3.35s\tremaining: 5.92s\n",
            "361:\tlearn: 0.3349297\ttest: 0.3770194\tbest: 0.3767361 (341)\ttotal: 3.35s\tremaining: 5.91s\n",
            "362:\tlearn: 0.3346809\ttest: 0.3769813\tbest: 0.3767361 (341)\ttotal: 3.37s\tremaining: 5.92s\n",
            "363:\tlearn: 0.3345179\ttest: 0.3769733\tbest: 0.3767361 (341)\ttotal: 3.38s\tremaining: 5.92s\n",
            "364:\tlearn: 0.3343618\ttest: 0.3770112\tbest: 0.3767361 (341)\ttotal: 3.39s\tremaining: 5.91s\n",
            "365:\tlearn: 0.3340667\ttest: 0.3771675\tbest: 0.3767361 (341)\ttotal: 3.4s\tremaining: 5.89s\n",
            "366:\tlearn: 0.3338840\ttest: 0.3772773\tbest: 0.3767361 (341)\ttotal: 3.41s\tremaining: 5.88s\n",
            "367:\tlearn: 0.3338075\ttest: 0.3772494\tbest: 0.3767361 (341)\ttotal: 3.42s\tremaining: 5.87s\n",
            "368:\tlearn: 0.3337491\ttest: 0.3772049\tbest: 0.3767361 (341)\ttotal: 3.43s\tremaining: 5.86s\n",
            "369:\tlearn: 0.3336558\ttest: 0.3772922\tbest: 0.3767361 (341)\ttotal: 3.44s\tremaining: 5.86s\n",
            "370:\tlearn: 0.3335893\ttest: 0.3772813\tbest: 0.3767361 (341)\ttotal: 3.45s\tremaining: 5.85s\n",
            "371:\tlearn: 0.3333777\ttest: 0.3772542\tbest: 0.3767361 (341)\ttotal: 3.47s\tremaining: 5.85s\n",
            "372:\tlearn: 0.3332873\ttest: 0.3773189\tbest: 0.3767361 (341)\ttotal: 3.48s\tremaining: 5.84s\n",
            "373:\tlearn: 0.3331785\ttest: 0.3772414\tbest: 0.3767361 (341)\ttotal: 3.48s\tremaining: 5.83s\n",
            "374:\tlearn: 0.3330448\ttest: 0.3770995\tbest: 0.3767361 (341)\ttotal: 3.49s\tremaining: 5.82s\n",
            "375:\tlearn: 0.3329776\ttest: 0.3771093\tbest: 0.3767361 (341)\ttotal: 3.5s\tremaining: 5.81s\n",
            "376:\tlearn: 0.3328088\ttest: 0.3770644\tbest: 0.3767361 (341)\ttotal: 3.51s\tremaining: 5.8s\n",
            "377:\tlearn: 0.3325444\ttest: 0.3771853\tbest: 0.3767361 (341)\ttotal: 3.52s\tremaining: 5.79s\n",
            "378:\tlearn: 0.3324702\ttest: 0.3771501\tbest: 0.3767361 (341)\ttotal: 3.53s\tremaining: 5.78s\n",
            "379:\tlearn: 0.3323740\ttest: 0.3770704\tbest: 0.3767361 (341)\ttotal: 3.54s\tremaining: 5.77s\n",
            "380:\tlearn: 0.3322857\ttest: 0.3770510\tbest: 0.3767361 (341)\ttotal: 3.55s\tremaining: 5.76s\n",
            "381:\tlearn: 0.3320179\ttest: 0.3771739\tbest: 0.3767361 (341)\ttotal: 3.56s\tremaining: 5.75s\n",
            "382:\tlearn: 0.3319570\ttest: 0.3771937\tbest: 0.3767361 (341)\ttotal: 3.57s\tremaining: 5.75s\n",
            "383:\tlearn: 0.3319478\ttest: 0.3772173\tbest: 0.3767361 (341)\ttotal: 3.58s\tremaining: 5.74s\n",
            "384:\tlearn: 0.3317758\ttest: 0.3771893\tbest: 0.3767361 (341)\ttotal: 3.58s\tremaining: 5.72s\n",
            "385:\tlearn: 0.3315932\ttest: 0.3771418\tbest: 0.3767361 (341)\ttotal: 3.59s\tremaining: 5.72s\n",
            "386:\tlearn: 0.3314631\ttest: 0.3770720\tbest: 0.3767361 (341)\ttotal: 3.6s\tremaining: 5.71s\n",
            "387:\tlearn: 0.3313051\ttest: 0.3770672\tbest: 0.3767361 (341)\ttotal: 3.61s\tremaining: 5.7s\n",
            "388:\tlearn: 0.3309840\ttest: 0.3770067\tbest: 0.3767361 (341)\ttotal: 3.62s\tremaining: 5.69s\n",
            "389:\tlearn: 0.3308974\ttest: 0.3770096\tbest: 0.3767361 (341)\ttotal: 3.63s\tremaining: 5.68s\n",
            "390:\tlearn: 0.3308048\ttest: 0.3768238\tbest: 0.3767361 (341)\ttotal: 3.64s\tremaining: 5.67s\n",
            "391:\tlearn: 0.3306887\ttest: 0.3768404\tbest: 0.3767361 (341)\ttotal: 3.65s\tremaining: 5.66s\n",
            "392:\tlearn: 0.3306821\ttest: 0.3768433\tbest: 0.3767361 (341)\ttotal: 3.66s\tremaining: 5.66s\n",
            "393:\tlearn: 0.3306016\ttest: 0.3768743\tbest: 0.3767361 (341)\ttotal: 3.68s\tremaining: 5.66s\n",
            "394:\tlearn: 0.3305990\ttest: 0.3768747\tbest: 0.3767361 (341)\ttotal: 3.69s\tremaining: 5.64s\n",
            "395:\tlearn: 0.3304454\ttest: 0.3769237\tbest: 0.3767361 (341)\ttotal: 3.7s\tremaining: 5.64s\n",
            "396:\tlearn: 0.3302689\ttest: 0.3768880\tbest: 0.3767361 (341)\ttotal: 3.71s\tremaining: 5.63s\n",
            "397:\tlearn: 0.3301537\ttest: 0.3767655\tbest: 0.3767361 (341)\ttotal: 3.71s\tremaining: 5.62s\n",
            "398:\tlearn: 0.3299444\ttest: 0.3768605\tbest: 0.3767361 (341)\ttotal: 3.72s\tremaining: 5.61s\n",
            "399:\tlearn: 0.3298424\ttest: 0.3768797\tbest: 0.3767361 (341)\ttotal: 3.73s\tremaining: 5.6s\n",
            "400:\tlearn: 0.3298292\ttest: 0.3768872\tbest: 0.3767361 (341)\ttotal: 3.74s\tremaining: 5.59s\n",
            "401:\tlearn: 0.3296747\ttest: 0.3770014\tbest: 0.3767361 (341)\ttotal: 3.75s\tremaining: 5.58s\n",
            "402:\tlearn: 0.3295532\ttest: 0.3770469\tbest: 0.3767361 (341)\ttotal: 3.76s\tremaining: 5.57s\n",
            "403:\tlearn: 0.3294158\ttest: 0.3770450\tbest: 0.3767361 (341)\ttotal: 3.77s\tremaining: 5.56s\n",
            "404:\tlearn: 0.3293122\ttest: 0.3770437\tbest: 0.3767361 (341)\ttotal: 3.78s\tremaining: 5.55s\n",
            "405:\tlearn: 0.3292361\ttest: 0.3770522\tbest: 0.3767361 (341)\ttotal: 3.79s\tremaining: 5.54s\n",
            "406:\tlearn: 0.3291139\ttest: 0.3770639\tbest: 0.3767361 (341)\ttotal: 3.79s\tremaining: 5.53s\n",
            "407:\tlearn: 0.3289420\ttest: 0.3770159\tbest: 0.3767361 (341)\ttotal: 3.8s\tremaining: 5.52s\n",
            "408:\tlearn: 0.3289393\ttest: 0.3770196\tbest: 0.3767361 (341)\ttotal: 3.81s\tremaining: 5.51s\n",
            "409:\tlearn: 0.3288939\ttest: 0.3770319\tbest: 0.3767361 (341)\ttotal: 3.82s\tremaining: 5.5s\n",
            "410:\tlearn: 0.3288906\ttest: 0.3770322\tbest: 0.3767361 (341)\ttotal: 3.83s\tremaining: 5.49s\n",
            "411:\tlearn: 0.3286511\ttest: 0.3770840\tbest: 0.3767361 (341)\ttotal: 3.85s\tremaining: 5.49s\n",
            "412:\tlearn: 0.3286135\ttest: 0.3771214\tbest: 0.3767361 (341)\ttotal: 3.86s\tremaining: 5.48s\n",
            "413:\tlearn: 0.3286107\ttest: 0.3771216\tbest: 0.3767361 (341)\ttotal: 3.87s\tremaining: 5.47s\n",
            "414:\tlearn: 0.3285337\ttest: 0.3771625\tbest: 0.3767361 (341)\ttotal: 3.87s\tremaining: 5.46s\n",
            "415:\tlearn: 0.3284685\ttest: 0.3772077\tbest: 0.3767361 (341)\ttotal: 3.89s\tremaining: 5.46s\n",
            "416:\tlearn: 0.3284350\ttest: 0.3772521\tbest: 0.3767361 (341)\ttotal: 3.9s\tremaining: 5.45s\n",
            "417:\tlearn: 0.3283557\ttest: 0.3772922\tbest: 0.3767361 (341)\ttotal: 3.9s\tremaining: 5.44s\n",
            "418:\tlearn: 0.3283109\ttest: 0.3773348\tbest: 0.3767361 (341)\ttotal: 3.91s\tremaining: 5.43s\n",
            "419:\tlearn: 0.3281478\ttest: 0.3773134\tbest: 0.3767361 (341)\ttotal: 3.92s\tremaining: 5.42s\n",
            "420:\tlearn: 0.3280703\ttest: 0.3773930\tbest: 0.3767361 (341)\ttotal: 3.93s\tremaining: 5.41s\n",
            "421:\tlearn: 0.3279695\ttest: 0.3774013\tbest: 0.3767361 (341)\ttotal: 3.94s\tremaining: 5.4s\n",
            "422:\tlearn: 0.3278633\ttest: 0.3773576\tbest: 0.3767361 (341)\ttotal: 3.95s\tremaining: 5.39s\n",
            "423:\tlearn: 0.3276485\ttest: 0.3773874\tbest: 0.3767361 (341)\ttotal: 3.96s\tremaining: 5.38s\n",
            "424:\tlearn: 0.3273909\ttest: 0.3775067\tbest: 0.3767361 (341)\ttotal: 3.97s\tremaining: 5.37s\n",
            "425:\tlearn: 0.3273872\ttest: 0.3775130\tbest: 0.3767361 (341)\ttotal: 3.98s\tremaining: 5.36s\n",
            "426:\tlearn: 0.3273797\ttest: 0.3775126\tbest: 0.3767361 (341)\ttotal: 3.99s\tremaining: 5.35s\n",
            "427:\tlearn: 0.3271947\ttest: 0.3775749\tbest: 0.3767361 (341)\ttotal: 4s\tremaining: 5.34s\n",
            "428:\tlearn: 0.3271313\ttest: 0.3775148\tbest: 0.3767361 (341)\ttotal: 4s\tremaining: 5.33s\n",
            "429:\tlearn: 0.3270095\ttest: 0.3775549\tbest: 0.3767361 (341)\ttotal: 4.01s\tremaining: 5.32s\n",
            "430:\tlearn: 0.3269391\ttest: 0.3775431\tbest: 0.3767361 (341)\ttotal: 4.02s\tremaining: 5.31s\n",
            "431:\tlearn: 0.3268491\ttest: 0.3775277\tbest: 0.3767361 (341)\ttotal: 4.03s\tremaining: 5.3s\n",
            "432:\tlearn: 0.3267540\ttest: 0.3774896\tbest: 0.3767361 (341)\ttotal: 4.04s\tremaining: 5.29s\n",
            "433:\tlearn: 0.3266324\ttest: 0.3775247\tbest: 0.3767361 (341)\ttotal: 4.05s\tremaining: 5.28s\n",
            "434:\tlearn: 0.3265800\ttest: 0.3774984\tbest: 0.3767361 (341)\ttotal: 4.06s\tremaining: 5.27s\n",
            "435:\tlearn: 0.3263700\ttest: 0.3774566\tbest: 0.3767361 (341)\ttotal: 4.07s\tremaining: 5.26s\n",
            "436:\tlearn: 0.3261118\ttest: 0.3774423\tbest: 0.3767361 (341)\ttotal: 4.08s\tremaining: 5.25s\n",
            "437:\tlearn: 0.3259458\ttest: 0.3774323\tbest: 0.3767361 (341)\ttotal: 4.08s\tremaining: 5.24s\n",
            "438:\tlearn: 0.3257786\ttest: 0.3774956\tbest: 0.3767361 (341)\ttotal: 4.1s\tremaining: 5.24s\n",
            "439:\tlearn: 0.3257221\ttest: 0.3774469\tbest: 0.3767361 (341)\ttotal: 4.11s\tremaining: 5.23s\n",
            "440:\tlearn: 0.3257204\ttest: 0.3774537\tbest: 0.3767361 (341)\ttotal: 4.12s\tremaining: 5.22s\n",
            "441:\tlearn: 0.3256231\ttest: 0.3774513\tbest: 0.3767361 (341)\ttotal: 4.12s\tremaining: 5.21s\n",
            "442:\tlearn: 0.3255419\ttest: 0.3774545\tbest: 0.3767361 (341)\ttotal: 4.13s\tremaining: 5.2s\n",
            "443:\tlearn: 0.3255205\ttest: 0.3774663\tbest: 0.3767361 (341)\ttotal: 4.14s\tremaining: 5.19s\n",
            "444:\tlearn: 0.3253988\ttest: 0.3775033\tbest: 0.3767361 (341)\ttotal: 4.16s\tremaining: 5.18s\n",
            "445:\tlearn: 0.3253255\ttest: 0.3774869\tbest: 0.3767361 (341)\ttotal: 4.16s\tremaining: 5.17s\n",
            "446:\tlearn: 0.3252655\ttest: 0.3775266\tbest: 0.3767361 (341)\ttotal: 4.17s\tremaining: 5.16s\n",
            "447:\tlearn: 0.3252645\ttest: 0.3775367\tbest: 0.3767361 (341)\ttotal: 4.18s\tremaining: 5.15s\n",
            "448:\tlearn: 0.3252020\ttest: 0.3775451\tbest: 0.3767361 (341)\ttotal: 4.19s\tremaining: 5.14s\n",
            "449:\tlearn: 0.3251997\ttest: 0.3775514\tbest: 0.3767361 (341)\ttotal: 4.2s\tremaining: 5.13s\n",
            "450:\tlearn: 0.3251956\ttest: 0.3775637\tbest: 0.3767361 (341)\ttotal: 4.21s\tremaining: 5.12s\n",
            "451:\tlearn: 0.3251723\ttest: 0.3775582\tbest: 0.3767361 (341)\ttotal: 4.22s\tremaining: 5.11s\n",
            "452:\tlearn: 0.3251165\ttest: 0.3775734\tbest: 0.3767361 (341)\ttotal: 4.23s\tremaining: 5.1s\n",
            "453:\tlearn: 0.3250488\ttest: 0.3775737\tbest: 0.3767361 (341)\ttotal: 4.24s\tremaining: 5.09s\n",
            "454:\tlearn: 0.3249524\ttest: 0.3775130\tbest: 0.3767361 (341)\ttotal: 4.24s\tremaining: 5.08s\n",
            "455:\tlearn: 0.3248654\ttest: 0.3774761\tbest: 0.3767361 (341)\ttotal: 4.25s\tremaining: 5.07s\n",
            "456:\tlearn: 0.3246663\ttest: 0.3775610\tbest: 0.3767361 (341)\ttotal: 4.26s\tremaining: 5.06s\n",
            "457:\tlearn: 0.3246597\ttest: 0.3775819\tbest: 0.3767361 (341)\ttotal: 4.27s\tremaining: 5.05s\n",
            "458:\tlearn: 0.3244670\ttest: 0.3775299\tbest: 0.3767361 (341)\ttotal: 4.28s\tremaining: 5.04s\n",
            "459:\tlearn: 0.3243318\ttest: 0.3774462\tbest: 0.3767361 (341)\ttotal: 4.29s\tremaining: 5.04s\n",
            "460:\tlearn: 0.3241015\ttest: 0.3775899\tbest: 0.3767361 (341)\ttotal: 4.3s\tremaining: 5.03s\n",
            "461:\tlearn: 0.3240878\ttest: 0.3776262\tbest: 0.3767361 (341)\ttotal: 4.31s\tremaining: 5.02s\n",
            "462:\tlearn: 0.3239188\ttest: 0.3778692\tbest: 0.3767361 (341)\ttotal: 4.32s\tremaining: 5.01s\n",
            "463:\tlearn: 0.3238392\ttest: 0.3778574\tbest: 0.3767361 (341)\ttotal: 4.33s\tremaining: 5s\n",
            "464:\tlearn: 0.3236913\ttest: 0.3779290\tbest: 0.3767361 (341)\ttotal: 4.34s\tremaining: 4.99s\n",
            "465:\tlearn: 0.3234833\ttest: 0.3778780\tbest: 0.3767361 (341)\ttotal: 4.35s\tremaining: 4.98s\n",
            "466:\tlearn: 0.3233188\ttest: 0.3779343\tbest: 0.3767361 (341)\ttotal: 4.36s\tremaining: 4.97s\n",
            "467:\tlearn: 0.3231557\ttest: 0.3779014\tbest: 0.3767361 (341)\ttotal: 4.36s\tremaining: 4.96s\n",
            "468:\tlearn: 0.3230762\ttest: 0.3779766\tbest: 0.3767361 (341)\ttotal: 4.38s\tremaining: 4.96s\n",
            "469:\tlearn: 0.3227862\ttest: 0.3778672\tbest: 0.3767361 (341)\ttotal: 4.39s\tremaining: 4.95s\n",
            "470:\tlearn: 0.3226467\ttest: 0.3778459\tbest: 0.3767361 (341)\ttotal: 4.4s\tremaining: 4.95s\n",
            "471:\tlearn: 0.3225351\ttest: 0.3778436\tbest: 0.3767361 (341)\ttotal: 4.41s\tremaining: 4.94s\n",
            "472:\tlearn: 0.3224389\ttest: 0.3778123\tbest: 0.3767361 (341)\ttotal: 4.42s\tremaining: 4.93s\n",
            "473:\tlearn: 0.3223936\ttest: 0.3779109\tbest: 0.3767361 (341)\ttotal: 4.43s\tremaining: 4.92s\n",
            "474:\tlearn: 0.3223068\ttest: 0.3777902\tbest: 0.3767361 (341)\ttotal: 4.44s\tremaining: 4.91s\n",
            "475:\tlearn: 0.3222669\ttest: 0.3778094\tbest: 0.3767361 (341)\ttotal: 4.45s\tremaining: 4.9s\n",
            "476:\tlearn: 0.3222043\ttest: 0.3779227\tbest: 0.3767361 (341)\ttotal: 4.46s\tremaining: 4.89s\n",
            "477:\tlearn: 0.3222027\ttest: 0.3779324\tbest: 0.3767361 (341)\ttotal: 4.47s\tremaining: 4.88s\n",
            "478:\tlearn: 0.3220388\ttest: 0.3779448\tbest: 0.3767361 (341)\ttotal: 4.48s\tremaining: 4.87s\n",
            "479:\tlearn: 0.3219921\ttest: 0.3779395\tbest: 0.3767361 (341)\ttotal: 4.49s\tremaining: 4.86s\n",
            "480:\tlearn: 0.3219910\ttest: 0.3779459\tbest: 0.3767361 (341)\ttotal: 4.5s\tremaining: 4.86s\n",
            "481:\tlearn: 0.3218808\ttest: 0.3780843\tbest: 0.3767361 (341)\ttotal: 4.51s\tremaining: 4.85s\n",
            "482:\tlearn: 0.3217793\ttest: 0.3780653\tbest: 0.3767361 (341)\ttotal: 4.52s\tremaining: 4.84s\n",
            "483:\tlearn: 0.3215820\ttest: 0.3780240\tbest: 0.3767361 (341)\ttotal: 4.53s\tremaining: 4.83s\n",
            "484:\tlearn: 0.3214580\ttest: 0.3780941\tbest: 0.3767361 (341)\ttotal: 4.54s\tremaining: 4.82s\n",
            "485:\tlearn: 0.3213369\ttest: 0.3781050\tbest: 0.3767361 (341)\ttotal: 4.55s\tremaining: 4.81s\n",
            "486:\tlearn: 0.3212695\ttest: 0.3781661\tbest: 0.3767361 (341)\ttotal: 4.56s\tremaining: 4.8s\n",
            "487:\tlearn: 0.3211953\ttest: 0.3781235\tbest: 0.3767361 (341)\ttotal: 4.57s\tremaining: 4.79s\n",
            "488:\tlearn: 0.3210568\ttest: 0.3780283\tbest: 0.3767361 (341)\ttotal: 4.57s\tremaining: 4.78s\n",
            "489:\tlearn: 0.3208721\ttest: 0.3779984\tbest: 0.3767361 (341)\ttotal: 4.58s\tremaining: 4.77s\n",
            "490:\tlearn: 0.3208704\ttest: 0.3779988\tbest: 0.3767361 (341)\ttotal: 4.59s\tremaining: 4.76s\n",
            "491:\tlearn: 0.3207264\ttest: 0.3780482\tbest: 0.3767361 (341)\ttotal: 4.6s\tremaining: 4.75s\n",
            "492:\tlearn: 0.3206463\ttest: 0.3779322\tbest: 0.3767361 (341)\ttotal: 4.61s\tremaining: 4.74s\n",
            "493:\tlearn: 0.3205391\ttest: 0.3780046\tbest: 0.3767361 (341)\ttotal: 4.62s\tremaining: 4.73s\n",
            "494:\tlearn: 0.3204862\ttest: 0.3780225\tbest: 0.3767361 (341)\ttotal: 4.63s\tremaining: 4.72s\n",
            "495:\tlearn: 0.3203244\ttest: 0.3780187\tbest: 0.3767361 (341)\ttotal: 4.64s\tremaining: 4.71s\n",
            "496:\tlearn: 0.3201871\ttest: 0.3779789\tbest: 0.3767361 (341)\ttotal: 4.65s\tremaining: 4.7s\n",
            "497:\tlearn: 0.3200587\ttest: 0.3780030\tbest: 0.3767361 (341)\ttotal: 4.66s\tremaining: 4.69s\n",
            "498:\tlearn: 0.3198791\ttest: 0.3780015\tbest: 0.3767361 (341)\ttotal: 4.67s\tremaining: 4.68s\n",
            "499:\tlearn: 0.3198220\ttest: 0.3779703\tbest: 0.3767361 (341)\ttotal: 4.67s\tremaining: 4.67s\n",
            "500:\tlearn: 0.3197408\ttest: 0.3779635\tbest: 0.3767361 (341)\ttotal: 4.68s\tremaining: 4.67s\n",
            "501:\tlearn: 0.3196553\ttest: 0.3779634\tbest: 0.3767361 (341)\ttotal: 4.69s\tremaining: 4.65s\n",
            "502:\tlearn: 0.3194114\ttest: 0.3780263\tbest: 0.3767361 (341)\ttotal: 4.71s\tremaining: 4.65s\n",
            "503:\tlearn: 0.3193244\ttest: 0.3780268\tbest: 0.3767361 (341)\ttotal: 4.71s\tremaining: 4.64s\n",
            "504:\tlearn: 0.3191910\ttest: 0.3779839\tbest: 0.3767361 (341)\ttotal: 4.72s\tremaining: 4.63s\n",
            "505:\tlearn: 0.3191472\ttest: 0.3780028\tbest: 0.3767361 (341)\ttotal: 4.73s\tremaining: 4.62s\n",
            "506:\tlearn: 0.3190999\ttest: 0.3780129\tbest: 0.3767361 (341)\ttotal: 4.74s\tremaining: 4.61s\n",
            "507:\tlearn: 0.3189766\ttest: 0.3780375\tbest: 0.3767361 (341)\ttotal: 4.75s\tremaining: 4.6s\n",
            "508:\tlearn: 0.3189148\ttest: 0.3780323\tbest: 0.3767361 (341)\ttotal: 4.76s\tremaining: 4.59s\n",
            "509:\tlearn: 0.3186418\ttest: 0.3781570\tbest: 0.3767361 (341)\ttotal: 4.76s\tremaining: 4.58s\n",
            "510:\tlearn: 0.3184851\ttest: 0.3783187\tbest: 0.3767361 (341)\ttotal: 4.77s\tremaining: 4.57s\n",
            "511:\tlearn: 0.3183940\ttest: 0.3783526\tbest: 0.3767361 (341)\ttotal: 4.78s\tremaining: 4.56s\n",
            "512:\tlearn: 0.3183096\ttest: 0.3784293\tbest: 0.3767361 (341)\ttotal: 4.79s\tremaining: 4.55s\n",
            "513:\tlearn: 0.3182930\ttest: 0.3784672\tbest: 0.3767361 (341)\ttotal: 4.8s\tremaining: 4.54s\n",
            "514:\tlearn: 0.3182007\ttest: 0.3784275\tbest: 0.3767361 (341)\ttotal: 4.81s\tremaining: 4.53s\n",
            "515:\tlearn: 0.3181112\ttest: 0.3785679\tbest: 0.3767361 (341)\ttotal: 4.82s\tremaining: 4.52s\n",
            "516:\tlearn: 0.3179753\ttest: 0.3785659\tbest: 0.3767361 (341)\ttotal: 4.83s\tremaining: 4.51s\n",
            "517:\tlearn: 0.3178160\ttest: 0.3785360\tbest: 0.3767361 (341)\ttotal: 4.84s\tremaining: 4.5s\n",
            "518:\tlearn: 0.3177020\ttest: 0.3786241\tbest: 0.3767361 (341)\ttotal: 4.85s\tremaining: 4.49s\n",
            "519:\tlearn: 0.3175672\ttest: 0.3786803\tbest: 0.3767361 (341)\ttotal: 4.86s\tremaining: 4.49s\n",
            "520:\tlearn: 0.3174727\ttest: 0.3786565\tbest: 0.3767361 (341)\ttotal: 4.87s\tremaining: 4.48s\n",
            "521:\tlearn: 0.3173421\ttest: 0.3786618\tbest: 0.3767361 (341)\ttotal: 4.88s\tremaining: 4.47s\n",
            "522:\tlearn: 0.3173401\ttest: 0.3786658\tbest: 0.3767361 (341)\ttotal: 4.89s\tremaining: 4.46s\n",
            "523:\tlearn: 0.3171849\ttest: 0.3786034\tbest: 0.3767361 (341)\ttotal: 4.9s\tremaining: 4.45s\n",
            "524:\tlearn: 0.3171361\ttest: 0.3786039\tbest: 0.3767361 (341)\ttotal: 4.91s\tremaining: 4.44s\n",
            "525:\tlearn: 0.3170502\ttest: 0.3786054\tbest: 0.3767361 (341)\ttotal: 4.92s\tremaining: 4.43s\n",
            "526:\tlearn: 0.3169816\ttest: 0.3786371\tbest: 0.3767361 (341)\ttotal: 4.93s\tremaining: 4.42s\n",
            "527:\tlearn: 0.3169693\ttest: 0.3786913\tbest: 0.3767361 (341)\ttotal: 4.93s\tremaining: 4.41s\n",
            "528:\tlearn: 0.3168663\ttest: 0.3786998\tbest: 0.3767361 (341)\ttotal: 4.94s\tremaining: 4.4s\n",
            "529:\tlearn: 0.3168190\ttest: 0.3786864\tbest: 0.3767361 (341)\ttotal: 4.95s\tremaining: 4.39s\n",
            "530:\tlearn: 0.3167982\ttest: 0.3787388\tbest: 0.3767361 (341)\ttotal: 4.96s\tremaining: 4.38s\n",
            "531:\tlearn: 0.3167056\ttest: 0.3788648\tbest: 0.3767361 (341)\ttotal: 4.97s\tremaining: 4.37s\n",
            "532:\tlearn: 0.3167041\ttest: 0.3788710\tbest: 0.3767361 (341)\ttotal: 4.98s\tremaining: 4.36s\n",
            "533:\tlearn: 0.3165379\ttest: 0.3789628\tbest: 0.3767361 (341)\ttotal: 4.99s\tremaining: 4.36s\n",
            "534:\tlearn: 0.3163720\ttest: 0.3789892\tbest: 0.3767361 (341)\ttotal: 5s\tremaining: 4.35s\n",
            "535:\tlearn: 0.3162512\ttest: 0.3790254\tbest: 0.3767361 (341)\ttotal: 5.01s\tremaining: 4.34s\n",
            "536:\tlearn: 0.3161667\ttest: 0.3790911\tbest: 0.3767361 (341)\ttotal: 5.02s\tremaining: 4.33s\n",
            "537:\tlearn: 0.3161648\ttest: 0.3790965\tbest: 0.3767361 (341)\ttotal: 5.03s\tremaining: 4.32s\n",
            "538:\tlearn: 0.3160502\ttest: 0.3791401\tbest: 0.3767361 (341)\ttotal: 5.04s\tremaining: 4.31s\n",
            "539:\tlearn: 0.3158764\ttest: 0.3790805\tbest: 0.3767361 (341)\ttotal: 5.05s\tremaining: 4.3s\n",
            "540:\tlearn: 0.3157092\ttest: 0.3791391\tbest: 0.3767361 (341)\ttotal: 5.05s\tremaining: 4.29s\n",
            "541:\tlearn: 0.3156011\ttest: 0.3791708\tbest: 0.3767361 (341)\ttotal: 5.06s\tremaining: 4.28s\n",
            "542:\tlearn: 0.3154393\ttest: 0.3792531\tbest: 0.3767361 (341)\ttotal: 5.07s\tremaining: 4.27s\n",
            "543:\tlearn: 0.3152885\ttest: 0.3792806\tbest: 0.3767361 (341)\ttotal: 5.08s\tremaining: 4.26s\n",
            "544:\tlearn: 0.3151385\ttest: 0.3792268\tbest: 0.3767361 (341)\ttotal: 5.09s\tremaining: 4.25s\n",
            "545:\tlearn: 0.3150409\ttest: 0.3792701\tbest: 0.3767361 (341)\ttotal: 5.1s\tremaining: 4.24s\n",
            "546:\tlearn: 0.3149074\ttest: 0.3793078\tbest: 0.3767361 (341)\ttotal: 5.11s\tremaining: 4.23s\n",
            "547:\tlearn: 0.3148771\ttest: 0.3793374\tbest: 0.3767361 (341)\ttotal: 5.12s\tremaining: 4.22s\n",
            "548:\tlearn: 0.3148714\ttest: 0.3793427\tbest: 0.3767361 (341)\ttotal: 5.13s\tremaining: 4.21s\n",
            "549:\tlearn: 0.3146979\ttest: 0.3794175\tbest: 0.3767361 (341)\ttotal: 5.14s\tremaining: 4.21s\n",
            "550:\tlearn: 0.3145255\ttest: 0.3795005\tbest: 0.3767361 (341)\ttotal: 5.15s\tremaining: 4.2s\n",
            "551:\tlearn: 0.3143599\ttest: 0.3795452\tbest: 0.3767361 (341)\ttotal: 5.16s\tremaining: 4.18s\n",
            "552:\tlearn: 0.3143043\ttest: 0.3795606\tbest: 0.3767361 (341)\ttotal: 5.17s\tremaining: 4.18s\n",
            "553:\tlearn: 0.3141916\ttest: 0.3795859\tbest: 0.3767361 (341)\ttotal: 5.18s\tremaining: 4.17s\n",
            "554:\tlearn: 0.3140323\ttest: 0.3796408\tbest: 0.3767361 (341)\ttotal: 5.18s\tremaining: 4.16s\n",
            "555:\tlearn: 0.3139784\ttest: 0.3797155\tbest: 0.3767361 (341)\ttotal: 5.19s\tremaining: 4.15s\n",
            "556:\tlearn: 0.3138265\ttest: 0.3797560\tbest: 0.3767361 (341)\ttotal: 5.2s\tremaining: 4.14s\n",
            "557:\tlearn: 0.3137398\ttest: 0.3797964\tbest: 0.3767361 (341)\ttotal: 5.21s\tremaining: 4.13s\n",
            "558:\tlearn: 0.3136082\ttest: 0.3798653\tbest: 0.3767361 (341)\ttotal: 5.22s\tremaining: 4.12s\n",
            "559:\tlearn: 0.3135360\ttest: 0.3799140\tbest: 0.3767361 (341)\ttotal: 5.24s\tremaining: 4.12s\n",
            "560:\tlearn: 0.3134812\ttest: 0.3799416\tbest: 0.3767361 (341)\ttotal: 5.25s\tremaining: 4.11s\n",
            "561:\tlearn: 0.3133721\ttest: 0.3798802\tbest: 0.3767361 (341)\ttotal: 5.25s\tremaining: 4.09s\n",
            "562:\tlearn: 0.3132003\ttest: 0.3797801\tbest: 0.3767361 (341)\ttotal: 5.26s\tremaining: 4.09s\n",
            "563:\tlearn: 0.3131294\ttest: 0.3798388\tbest: 0.3767361 (341)\ttotal: 5.27s\tremaining: 4.08s\n",
            "564:\tlearn: 0.3129898\ttest: 0.3799756\tbest: 0.3767361 (341)\ttotal: 5.28s\tremaining: 4.07s\n",
            "565:\tlearn: 0.3128523\ttest: 0.3800836\tbest: 0.3767361 (341)\ttotal: 5.29s\tremaining: 4.06s\n",
            "566:\tlearn: 0.3127967\ttest: 0.3801414\tbest: 0.3767361 (341)\ttotal: 5.3s\tremaining: 4.05s\n",
            "567:\tlearn: 0.3127623\ttest: 0.3801353\tbest: 0.3767361 (341)\ttotal: 5.31s\tremaining: 4.04s\n",
            "568:\tlearn: 0.3125577\ttest: 0.3800669\tbest: 0.3767361 (341)\ttotal: 5.32s\tremaining: 4.03s\n",
            "569:\tlearn: 0.3124708\ttest: 0.3800565\tbest: 0.3767361 (341)\ttotal: 5.33s\tremaining: 4.02s\n",
            "570:\tlearn: 0.3123525\ttest: 0.3801080\tbest: 0.3767361 (341)\ttotal: 5.34s\tremaining: 4.01s\n",
            "571:\tlearn: 0.3121711\ttest: 0.3799558\tbest: 0.3767361 (341)\ttotal: 5.35s\tremaining: 4s\n",
            "572:\tlearn: 0.3120596\ttest: 0.3798944\tbest: 0.3767361 (341)\ttotal: 5.36s\tremaining: 3.99s\n",
            "573:\tlearn: 0.3119955\ttest: 0.3799155\tbest: 0.3767361 (341)\ttotal: 5.37s\tremaining: 3.98s\n",
            "574:\tlearn: 0.3119464\ttest: 0.3798952\tbest: 0.3767361 (341)\ttotal: 5.38s\tremaining: 3.97s\n",
            "575:\tlearn: 0.3119040\ttest: 0.3798742\tbest: 0.3767361 (341)\ttotal: 5.39s\tremaining: 3.97s\n",
            "576:\tlearn: 0.3117296\ttest: 0.3798895\tbest: 0.3767361 (341)\ttotal: 5.41s\tremaining: 3.96s\n",
            "577:\tlearn: 0.3116638\ttest: 0.3798700\tbest: 0.3767361 (341)\ttotal: 5.41s\tremaining: 3.95s\n",
            "578:\tlearn: 0.3116591\ttest: 0.3798833\tbest: 0.3767361 (341)\ttotal: 5.42s\tremaining: 3.94s\n",
            "579:\tlearn: 0.3114835\ttest: 0.3798889\tbest: 0.3767361 (341)\ttotal: 5.43s\tremaining: 3.93s\n",
            "580:\tlearn: 0.3113686\ttest: 0.3799508\tbest: 0.3767361 (341)\ttotal: 5.44s\tremaining: 3.92s\n",
            "581:\tlearn: 0.3113678\ttest: 0.3799556\tbest: 0.3767361 (341)\ttotal: 5.45s\tremaining: 3.91s\n",
            "582:\tlearn: 0.3112187\ttest: 0.3798978\tbest: 0.3767361 (341)\ttotal: 5.46s\tremaining: 3.9s\n",
            "583:\tlearn: 0.3111443\ttest: 0.3799439\tbest: 0.3767361 (341)\ttotal: 5.47s\tremaining: 3.9s\n",
            "584:\tlearn: 0.3110477\ttest: 0.3798768\tbest: 0.3767361 (341)\ttotal: 5.48s\tremaining: 3.89s\n",
            "585:\tlearn: 0.3109328\ttest: 0.3799008\tbest: 0.3767361 (341)\ttotal: 5.49s\tremaining: 3.88s\n",
            "586:\tlearn: 0.3107644\ttest: 0.3798214\tbest: 0.3767361 (341)\ttotal: 5.5s\tremaining: 3.87s\n",
            "587:\tlearn: 0.3105934\ttest: 0.3798088\tbest: 0.3767361 (341)\ttotal: 5.5s\tremaining: 3.86s\n",
            "588:\tlearn: 0.3104006\ttest: 0.3798124\tbest: 0.3767361 (341)\ttotal: 5.51s\tremaining: 3.85s\n",
            "589:\tlearn: 0.3102831\ttest: 0.3799030\tbest: 0.3767361 (341)\ttotal: 5.53s\tremaining: 3.84s\n",
            "590:\tlearn: 0.3101393\ttest: 0.3799099\tbest: 0.3767361 (341)\ttotal: 5.54s\tremaining: 3.83s\n",
            "591:\tlearn: 0.3101017\ttest: 0.3799706\tbest: 0.3767361 (341)\ttotal: 5.55s\tremaining: 3.82s\n",
            "592:\tlearn: 0.3099395\ttest: 0.3798382\tbest: 0.3767361 (341)\ttotal: 5.56s\tremaining: 3.81s\n",
            "593:\tlearn: 0.3097714\ttest: 0.3797703\tbest: 0.3767361 (341)\ttotal: 5.57s\tremaining: 3.81s\n",
            "594:\tlearn: 0.3097425\ttest: 0.3797624\tbest: 0.3767361 (341)\ttotal: 5.58s\tremaining: 3.8s\n",
            "595:\tlearn: 0.3096292\ttest: 0.3797088\tbest: 0.3767361 (341)\ttotal: 5.59s\tremaining: 3.79s\n",
            "596:\tlearn: 0.3094941\ttest: 0.3795816\tbest: 0.3767361 (341)\ttotal: 5.6s\tremaining: 3.78s\n",
            "597:\tlearn: 0.3092948\ttest: 0.3796885\tbest: 0.3767361 (341)\ttotal: 5.61s\tremaining: 3.77s\n",
            "598:\tlearn: 0.3092802\ttest: 0.3796818\tbest: 0.3767361 (341)\ttotal: 5.62s\tremaining: 3.76s\n",
            "599:\tlearn: 0.3092213\ttest: 0.3796526\tbest: 0.3767361 (341)\ttotal: 5.63s\tremaining: 3.75s\n",
            "600:\tlearn: 0.3091862\ttest: 0.3797091\tbest: 0.3767361 (341)\ttotal: 5.64s\tremaining: 3.74s\n",
            "601:\tlearn: 0.3091135\ttest: 0.3796199\tbest: 0.3767361 (341)\ttotal: 5.64s\tremaining: 3.73s\n",
            "602:\tlearn: 0.3089893\ttest: 0.3796750\tbest: 0.3767361 (341)\ttotal: 5.65s\tremaining: 3.72s\n",
            "603:\tlearn: 0.3088478\ttest: 0.3797870\tbest: 0.3767361 (341)\ttotal: 5.66s\tremaining: 3.71s\n",
            "604:\tlearn: 0.3087749\ttest: 0.3798618\tbest: 0.3767361 (341)\ttotal: 5.67s\tremaining: 3.7s\n",
            "605:\tlearn: 0.3085519\ttest: 0.3800296\tbest: 0.3767361 (341)\ttotal: 5.68s\tremaining: 3.69s\n",
            "606:\tlearn: 0.3083988\ttest: 0.3799996\tbest: 0.3767361 (341)\ttotal: 5.69s\tremaining: 3.68s\n",
            "607:\tlearn: 0.3083235\ttest: 0.3800764\tbest: 0.3767361 (341)\ttotal: 5.7s\tremaining: 3.67s\n",
            "608:\tlearn: 0.3082692\ttest: 0.3800497\tbest: 0.3767361 (341)\ttotal: 5.71s\tremaining: 3.67s\n",
            "609:\tlearn: 0.3082296\ttest: 0.3800555\tbest: 0.3767361 (341)\ttotal: 5.72s\tremaining: 3.66s\n",
            "610:\tlearn: 0.3080691\ttest: 0.3800068\tbest: 0.3767361 (341)\ttotal: 5.74s\tremaining: 3.65s\n",
            "611:\tlearn: 0.3079883\ttest: 0.3800170\tbest: 0.3767361 (341)\ttotal: 5.75s\tremaining: 3.64s\n",
            "612:\tlearn: 0.3077689\ttest: 0.3800312\tbest: 0.3767361 (341)\ttotal: 5.75s\tremaining: 3.63s\n",
            "613:\tlearn: 0.3075364\ttest: 0.3800476\tbest: 0.3767361 (341)\ttotal: 5.76s\tremaining: 3.62s\n",
            "614:\tlearn: 0.3075350\ttest: 0.3800510\tbest: 0.3767361 (341)\ttotal: 5.77s\tremaining: 3.61s\n",
            "615:\tlearn: 0.3074692\ttest: 0.3800380\tbest: 0.3767361 (341)\ttotal: 5.78s\tremaining: 3.6s\n",
            "616:\tlearn: 0.3073715\ttest: 0.3800147\tbest: 0.3767361 (341)\ttotal: 5.79s\tremaining: 3.6s\n",
            "617:\tlearn: 0.3071682\ttest: 0.3798743\tbest: 0.3767361 (341)\ttotal: 5.8s\tremaining: 3.58s\n",
            "618:\tlearn: 0.3071083\ttest: 0.3798774\tbest: 0.3767361 (341)\ttotal: 5.81s\tremaining: 3.58s\n",
            "619:\tlearn: 0.3069661\ttest: 0.3799251\tbest: 0.3767361 (341)\ttotal: 5.82s\tremaining: 3.57s\n",
            "620:\tlearn: 0.3069623\ttest: 0.3799471\tbest: 0.3767361 (341)\ttotal: 5.84s\tremaining: 3.56s\n",
            "621:\tlearn: 0.3068066\ttest: 0.3799262\tbest: 0.3767361 (341)\ttotal: 5.85s\tremaining: 3.55s\n",
            "622:\tlearn: 0.3066578\ttest: 0.3798401\tbest: 0.3767361 (341)\ttotal: 5.86s\tremaining: 3.54s\n",
            "623:\tlearn: 0.3064696\ttest: 0.3798208\tbest: 0.3767361 (341)\ttotal: 5.87s\tremaining: 3.54s\n",
            "624:\tlearn: 0.3063638\ttest: 0.3799720\tbest: 0.3767361 (341)\ttotal: 5.88s\tremaining: 3.53s\n",
            "625:\tlearn: 0.3062365\ttest: 0.3800354\tbest: 0.3767361 (341)\ttotal: 5.89s\tremaining: 3.52s\n",
            "626:\tlearn: 0.3061996\ttest: 0.3799964\tbest: 0.3767361 (341)\ttotal: 5.9s\tremaining: 3.51s\n",
            "627:\tlearn: 0.3061961\ttest: 0.3799951\tbest: 0.3767361 (341)\ttotal: 5.91s\tremaining: 3.5s\n",
            "628:\tlearn: 0.3060503\ttest: 0.3799492\tbest: 0.3767361 (341)\ttotal: 5.92s\tremaining: 3.49s\n",
            "629:\tlearn: 0.3060047\ttest: 0.3799254\tbest: 0.3767361 (341)\ttotal: 5.92s\tremaining: 3.48s\n",
            "630:\tlearn: 0.3059606\ttest: 0.3799043\tbest: 0.3767361 (341)\ttotal: 5.93s\tremaining: 3.47s\n",
            "631:\tlearn: 0.3058818\ttest: 0.3799548\tbest: 0.3767361 (341)\ttotal: 5.95s\tremaining: 3.46s\n",
            "632:\tlearn: 0.3057984\ttest: 0.3798973\tbest: 0.3767361 (341)\ttotal: 5.96s\tremaining: 3.45s\n",
            "633:\tlearn: 0.3057302\ttest: 0.3798413\tbest: 0.3767361 (341)\ttotal: 5.97s\tremaining: 3.44s\n",
            "634:\tlearn: 0.3055990\ttest: 0.3798214\tbest: 0.3767361 (341)\ttotal: 5.97s\tremaining: 3.43s\n",
            "635:\tlearn: 0.3054671\ttest: 0.3798233\tbest: 0.3767361 (341)\ttotal: 5.98s\tremaining: 3.42s\n",
            "636:\tlearn: 0.3052901\ttest: 0.3798190\tbest: 0.3767361 (341)\ttotal: 5.99s\tremaining: 3.42s\n",
            "637:\tlearn: 0.3052053\ttest: 0.3797962\tbest: 0.3767361 (341)\ttotal: 6s\tremaining: 3.4s\n",
            "638:\tlearn: 0.3050870\ttest: 0.3798726\tbest: 0.3767361 (341)\ttotal: 6.01s\tremaining: 3.4s\n",
            "639:\tlearn: 0.3049778\ttest: 0.3798869\tbest: 0.3767361 (341)\ttotal: 6.02s\tremaining: 3.39s\n",
            "640:\tlearn: 0.3048594\ttest: 0.3798921\tbest: 0.3767361 (341)\ttotal: 6.03s\tremaining: 3.38s\n",
            "641:\tlearn: 0.3048545\ttest: 0.3798926\tbest: 0.3767361 (341)\ttotal: 6.04s\tremaining: 3.37s\n",
            "642:\tlearn: 0.3047962\ttest: 0.3798774\tbest: 0.3767361 (341)\ttotal: 6.05s\tremaining: 3.36s\n",
            "643:\tlearn: 0.3046145\ttest: 0.3800565\tbest: 0.3767361 (341)\ttotal: 6.06s\tremaining: 3.35s\n",
            "644:\tlearn: 0.3045866\ttest: 0.3801408\tbest: 0.3767361 (341)\ttotal: 6.07s\tremaining: 3.34s\n",
            "645:\tlearn: 0.3045313\ttest: 0.3802658\tbest: 0.3767361 (341)\ttotal: 6.07s\tremaining: 3.33s\n",
            "646:\tlearn: 0.3045017\ttest: 0.3802702\tbest: 0.3767361 (341)\ttotal: 6.08s\tremaining: 3.32s\n",
            "647:\tlearn: 0.3044054\ttest: 0.3801926\tbest: 0.3767361 (341)\ttotal: 6.09s\tremaining: 3.31s\n",
            "648:\tlearn: 0.3043501\ttest: 0.3801830\tbest: 0.3767361 (341)\ttotal: 6.1s\tremaining: 3.3s\n",
            "649:\tlearn: 0.3043009\ttest: 0.3802130\tbest: 0.3767361 (341)\ttotal: 6.11s\tremaining: 3.29s\n",
            "650:\tlearn: 0.3043000\ttest: 0.3802161\tbest: 0.3767361 (341)\ttotal: 6.12s\tremaining: 3.28s\n",
            "651:\tlearn: 0.3042084\ttest: 0.3802754\tbest: 0.3767361 (341)\ttotal: 6.13s\tremaining: 3.27s\n",
            "652:\tlearn: 0.3041771\ttest: 0.3802834\tbest: 0.3767361 (341)\ttotal: 6.14s\tremaining: 3.26s\n",
            "653:\tlearn: 0.3040747\ttest: 0.3803493\tbest: 0.3767361 (341)\ttotal: 6.15s\tremaining: 3.25s\n",
            "654:\tlearn: 0.3039465\ttest: 0.3803975\tbest: 0.3767361 (341)\ttotal: 6.16s\tremaining: 3.24s\n",
            "655:\tlearn: 0.3037854\ttest: 0.3803022\tbest: 0.3767361 (341)\ttotal: 6.17s\tremaining: 3.23s\n",
            "656:\tlearn: 0.3037162\ttest: 0.3803889\tbest: 0.3767361 (341)\ttotal: 6.18s\tremaining: 3.23s\n",
            "657:\tlearn: 0.3036968\ttest: 0.3804245\tbest: 0.3767361 (341)\ttotal: 6.19s\tremaining: 3.22s\n",
            "658:\tlearn: 0.3036152\ttest: 0.3803777\tbest: 0.3767361 (341)\ttotal: 6.2s\tremaining: 3.21s\n",
            "659:\tlearn: 0.3034284\ttest: 0.3802600\tbest: 0.3767361 (341)\ttotal: 6.21s\tremaining: 3.2s\n",
            "660:\tlearn: 0.3033501\ttest: 0.3802520\tbest: 0.3767361 (341)\ttotal: 6.22s\tremaining: 3.19s\n",
            "661:\tlearn: 0.3033259\ttest: 0.3802479\tbest: 0.3767361 (341)\ttotal: 6.23s\tremaining: 3.18s\n",
            "662:\tlearn: 0.3032137\ttest: 0.3803164\tbest: 0.3767361 (341)\ttotal: 6.24s\tremaining: 3.17s\n",
            "663:\tlearn: 0.3031019\ttest: 0.3802460\tbest: 0.3767361 (341)\ttotal: 6.25s\tremaining: 3.16s\n",
            "664:\tlearn: 0.3030880\ttest: 0.3802534\tbest: 0.3767361 (341)\ttotal: 6.25s\tremaining: 3.15s\n",
            "665:\tlearn: 0.3029766\ttest: 0.3802349\tbest: 0.3767361 (341)\ttotal: 6.26s\tremaining: 3.14s\n",
            "666:\tlearn: 0.3029254\ttest: 0.3802750\tbest: 0.3767361 (341)\ttotal: 6.27s\tremaining: 3.13s\n",
            "667:\tlearn: 0.3028583\ttest: 0.3802869\tbest: 0.3767361 (341)\ttotal: 6.28s\tremaining: 3.12s\n",
            "668:\tlearn: 0.3027514\ttest: 0.3803785\tbest: 0.3767361 (341)\ttotal: 6.29s\tremaining: 3.11s\n",
            "669:\tlearn: 0.3026298\ttest: 0.3803487\tbest: 0.3767361 (341)\ttotal: 6.3s\tremaining: 3.1s\n",
            "670:\tlearn: 0.3025210\ttest: 0.3804269\tbest: 0.3767361 (341)\ttotal: 6.31s\tremaining: 3.09s\n",
            "671:\tlearn: 0.3024576\ttest: 0.3804586\tbest: 0.3767361 (341)\ttotal: 6.32s\tremaining: 3.08s\n",
            "672:\tlearn: 0.3023318\ttest: 0.3805145\tbest: 0.3767361 (341)\ttotal: 6.33s\tremaining: 3.08s\n",
            "673:\tlearn: 0.3022898\ttest: 0.3805333\tbest: 0.3767361 (341)\ttotal: 6.34s\tremaining: 3.06s\n",
            "674:\tlearn: 0.3021851\ttest: 0.3804868\tbest: 0.3767361 (341)\ttotal: 6.35s\tremaining: 3.06s\n",
            "675:\tlearn: 0.3019989\ttest: 0.3803753\tbest: 0.3767361 (341)\ttotal: 6.36s\tremaining: 3.05s\n",
            "676:\tlearn: 0.3019032\ttest: 0.3803376\tbest: 0.3767361 (341)\ttotal: 6.37s\tremaining: 3.04s\n",
            "677:\tlearn: 0.3018187\ttest: 0.3803115\tbest: 0.3767361 (341)\ttotal: 6.38s\tremaining: 3.03s\n",
            "678:\tlearn: 0.3017374\ttest: 0.3804237\tbest: 0.3767361 (341)\ttotal: 6.39s\tremaining: 3.02s\n",
            "679:\tlearn: 0.3016132\ttest: 0.3805444\tbest: 0.3767361 (341)\ttotal: 6.41s\tremaining: 3.01s\n",
            "680:\tlearn: 0.3015944\ttest: 0.3805189\tbest: 0.3767361 (341)\ttotal: 6.42s\tremaining: 3.01s\n",
            "681:\tlearn: 0.3015936\ttest: 0.3805263\tbest: 0.3767361 (341)\ttotal: 6.43s\tremaining: 3s\n",
            "682:\tlearn: 0.3015075\ttest: 0.3804860\tbest: 0.3767361 (341)\ttotal: 6.43s\tremaining: 2.99s\n",
            "683:\tlearn: 0.3013685\ttest: 0.3804574\tbest: 0.3767361 (341)\ttotal: 6.44s\tremaining: 2.98s\n",
            "684:\tlearn: 0.3012394\ttest: 0.3804882\tbest: 0.3767361 (341)\ttotal: 6.45s\tremaining: 2.97s\n",
            "685:\tlearn: 0.3012387\ttest: 0.3804925\tbest: 0.3767361 (341)\ttotal: 6.46s\tremaining: 2.96s\n",
            "686:\tlearn: 0.3011906\ttest: 0.3804935\tbest: 0.3767361 (341)\ttotal: 6.47s\tremaining: 2.95s\n",
            "687:\tlearn: 0.3011404\ttest: 0.3804993\tbest: 0.3767361 (341)\ttotal: 6.48s\tremaining: 2.94s\n",
            "688:\tlearn: 0.3010388\ttest: 0.3805058\tbest: 0.3767361 (341)\ttotal: 6.49s\tremaining: 2.93s\n",
            "689:\tlearn: 0.3009152\ttest: 0.3804558\tbest: 0.3767361 (341)\ttotal: 6.5s\tremaining: 2.92s\n",
            "690:\tlearn: 0.3009060\ttest: 0.3804669\tbest: 0.3767361 (341)\ttotal: 6.51s\tremaining: 2.91s\n",
            "691:\tlearn: 0.3008274\ttest: 0.3805210\tbest: 0.3767361 (341)\ttotal: 6.52s\tremaining: 2.9s\n",
            "692:\tlearn: 0.3007816\ttest: 0.3805239\tbest: 0.3767361 (341)\ttotal: 6.53s\tremaining: 2.89s\n",
            "693:\tlearn: 0.3006586\ttest: 0.3804512\tbest: 0.3767361 (341)\ttotal: 6.54s\tremaining: 2.88s\n",
            "694:\tlearn: 0.3005644\ttest: 0.3805100\tbest: 0.3767361 (341)\ttotal: 6.55s\tremaining: 2.87s\n",
            "695:\tlearn: 0.3004831\ttest: 0.3805275\tbest: 0.3767361 (341)\ttotal: 6.55s\tremaining: 2.86s\n",
            "696:\tlearn: 0.3003634\ttest: 0.3805433\tbest: 0.3767361 (341)\ttotal: 6.57s\tremaining: 2.86s\n",
            "697:\tlearn: 0.3003397\ttest: 0.3805443\tbest: 0.3767361 (341)\ttotal: 6.58s\tremaining: 2.85s\n",
            "698:\tlearn: 0.3002816\ttest: 0.3806383\tbest: 0.3767361 (341)\ttotal: 6.59s\tremaining: 2.84s\n",
            "699:\tlearn: 0.3002808\ttest: 0.3806416\tbest: 0.3767361 (341)\ttotal: 6.6s\tremaining: 2.83s\n",
            "700:\tlearn: 0.3002354\ttest: 0.3806548\tbest: 0.3767361 (341)\ttotal: 6.61s\tremaining: 2.82s\n",
            "701:\tlearn: 0.3000611\ttest: 0.3807108\tbest: 0.3767361 (341)\ttotal: 6.62s\tremaining: 2.81s\n",
            "702:\tlearn: 0.3000477\ttest: 0.3807058\tbest: 0.3767361 (341)\ttotal: 6.63s\tremaining: 2.8s\n",
            "703:\tlearn: 0.3000456\ttest: 0.3807188\tbest: 0.3767361 (341)\ttotal: 6.64s\tremaining: 2.79s\n",
            "704:\tlearn: 0.3000449\ttest: 0.3807260\tbest: 0.3767361 (341)\ttotal: 6.65s\tremaining: 2.78s\n",
            "705:\tlearn: 0.2999403\ttest: 0.3807744\tbest: 0.3767361 (341)\ttotal: 6.66s\tremaining: 2.77s\n",
            "706:\tlearn: 0.2998537\ttest: 0.3808631\tbest: 0.3767361 (341)\ttotal: 6.67s\tremaining: 2.76s\n",
            "707:\tlearn: 0.2997342\ttest: 0.3809966\tbest: 0.3767361 (341)\ttotal: 6.68s\tremaining: 2.75s\n",
            "708:\tlearn: 0.2996702\ttest: 0.3810060\tbest: 0.3767361 (341)\ttotal: 6.69s\tremaining: 2.75s\n",
            "709:\tlearn: 0.2995818\ttest: 0.3809178\tbest: 0.3767361 (341)\ttotal: 6.7s\tremaining: 2.73s\n",
            "710:\tlearn: 0.2994939\ttest: 0.3809851\tbest: 0.3767361 (341)\ttotal: 6.71s\tremaining: 2.73s\n",
            "711:\tlearn: 0.2992825\ttest: 0.3810852\tbest: 0.3767361 (341)\ttotal: 6.72s\tremaining: 2.72s\n",
            "712:\tlearn: 0.2991205\ttest: 0.3810600\tbest: 0.3767361 (341)\ttotal: 6.72s\tremaining: 2.71s\n",
            "713:\tlearn: 0.2991072\ttest: 0.3811156\tbest: 0.3767361 (341)\ttotal: 6.74s\tremaining: 2.7s\n",
            "714:\tlearn: 0.2990664\ttest: 0.3810719\tbest: 0.3767361 (341)\ttotal: 6.74s\tremaining: 2.69s\n",
            "715:\tlearn: 0.2990292\ttest: 0.3810870\tbest: 0.3767361 (341)\ttotal: 6.75s\tremaining: 2.68s\n",
            "716:\tlearn: 0.2988384\ttest: 0.3811143\tbest: 0.3767361 (341)\ttotal: 6.76s\tremaining: 2.67s\n",
            "717:\tlearn: 0.2987722\ttest: 0.3811135\tbest: 0.3767361 (341)\ttotal: 6.78s\tremaining: 2.66s\n",
            "718:\tlearn: 0.2987168\ttest: 0.3812535\tbest: 0.3767361 (341)\ttotal: 6.78s\tremaining: 2.65s\n",
            "719:\tlearn: 0.2986824\ttest: 0.3812781\tbest: 0.3767361 (341)\ttotal: 6.79s\tremaining: 2.64s\n",
            "720:\tlearn: 0.2986649\ttest: 0.3812772\tbest: 0.3767361 (341)\ttotal: 6.8s\tremaining: 2.63s\n",
            "721:\tlearn: 0.2985713\ttest: 0.3813017\tbest: 0.3767361 (341)\ttotal: 6.81s\tremaining: 2.62s\n",
            "722:\tlearn: 0.2984811\ttest: 0.3812763\tbest: 0.3767361 (341)\ttotal: 6.82s\tremaining: 2.61s\n",
            "723:\tlearn: 0.2984269\ttest: 0.3812290\tbest: 0.3767361 (341)\ttotal: 6.83s\tremaining: 2.6s\n",
            "724:\tlearn: 0.2983803\ttest: 0.3812219\tbest: 0.3767361 (341)\ttotal: 6.85s\tremaining: 2.6s\n",
            "725:\tlearn: 0.2983771\ttest: 0.3812284\tbest: 0.3767361 (341)\ttotal: 6.86s\tremaining: 2.59s\n",
            "726:\tlearn: 0.2983758\ttest: 0.3812323\tbest: 0.3767361 (341)\ttotal: 6.87s\tremaining: 2.58s\n",
            "727:\tlearn: 0.2982588\ttest: 0.3812605\tbest: 0.3767361 (341)\ttotal: 6.88s\tremaining: 2.57s\n",
            "728:\tlearn: 0.2981957\ttest: 0.3813247\tbest: 0.3767361 (341)\ttotal: 6.88s\tremaining: 2.56s\n",
            "729:\tlearn: 0.2981077\ttest: 0.3814159\tbest: 0.3767361 (341)\ttotal: 6.89s\tremaining: 2.55s\n",
            "730:\tlearn: 0.2979860\ttest: 0.3814141\tbest: 0.3767361 (341)\ttotal: 6.9s\tremaining: 2.54s\n",
            "731:\tlearn: 0.2978705\ttest: 0.3814039\tbest: 0.3767361 (341)\ttotal: 6.91s\tremaining: 2.53s\n",
            "732:\tlearn: 0.2978432\ttest: 0.3814176\tbest: 0.3767361 (341)\ttotal: 6.92s\tremaining: 2.52s\n",
            "733:\tlearn: 0.2977568\ttest: 0.3813692\tbest: 0.3767361 (341)\ttotal: 6.93s\tremaining: 2.51s\n",
            "734:\tlearn: 0.2975235\ttest: 0.3814062\tbest: 0.3767361 (341)\ttotal: 6.94s\tremaining: 2.5s\n",
            "735:\tlearn: 0.2973700\ttest: 0.3813922\tbest: 0.3767361 (341)\ttotal: 6.95s\tremaining: 2.49s\n",
            "736:\tlearn: 0.2973400\ttest: 0.3814605\tbest: 0.3767361 (341)\ttotal: 6.96s\tremaining: 2.48s\n",
            "737:\tlearn: 0.2972655\ttest: 0.3814916\tbest: 0.3767361 (341)\ttotal: 6.97s\tremaining: 2.47s\n",
            "738:\tlearn: 0.2971568\ttest: 0.3815143\tbest: 0.3767361 (341)\ttotal: 6.97s\tremaining: 2.46s\n",
            "739:\tlearn: 0.2970556\ttest: 0.3814855\tbest: 0.3767361 (341)\ttotal: 6.99s\tremaining: 2.45s\n",
            "740:\tlearn: 0.2970191\ttest: 0.3814810\tbest: 0.3767361 (341)\ttotal: 7s\tremaining: 2.44s\n",
            "741:\tlearn: 0.2969313\ttest: 0.3814821\tbest: 0.3767361 (341)\ttotal: 7s\tremaining: 2.44s\n",
            "742:\tlearn: 0.2969124\ttest: 0.3814490\tbest: 0.3767361 (341)\ttotal: 7.01s\tremaining: 2.42s\n",
            "743:\tlearn: 0.2968458\ttest: 0.3814188\tbest: 0.3767361 (341)\ttotal: 7.02s\tremaining: 2.42s\n",
            "744:\tlearn: 0.2966648\ttest: 0.3815042\tbest: 0.3767361 (341)\ttotal: 7.03s\tremaining: 2.41s\n",
            "745:\tlearn: 0.2965683\ttest: 0.3815352\tbest: 0.3767361 (341)\ttotal: 7.04s\tremaining: 2.4s\n",
            "746:\tlearn: 0.2965258\ttest: 0.3815699\tbest: 0.3767361 (341)\ttotal: 7.05s\tremaining: 2.39s\n",
            "747:\tlearn: 0.2964301\ttest: 0.3815756\tbest: 0.3767361 (341)\ttotal: 7.06s\tremaining: 2.38s\n",
            "748:\tlearn: 0.2962481\ttest: 0.3816462\tbest: 0.3767361 (341)\ttotal: 7.07s\tremaining: 2.37s\n",
            "749:\tlearn: 0.2962274\ttest: 0.3816660\tbest: 0.3767361 (341)\ttotal: 7.08s\tremaining: 2.36s\n",
            "750:\tlearn: 0.2961351\ttest: 0.3816388\tbest: 0.3767361 (341)\ttotal: 7.09s\tremaining: 2.35s\n",
            "751:\tlearn: 0.2960467\ttest: 0.3815995\tbest: 0.3767361 (341)\ttotal: 7.09s\tremaining: 2.34s\n",
            "752:\tlearn: 0.2959211\ttest: 0.3815970\tbest: 0.3767361 (341)\ttotal: 7.11s\tremaining: 2.33s\n",
            "753:\tlearn: 0.2957896\ttest: 0.3816782\tbest: 0.3767361 (341)\ttotal: 7.12s\tremaining: 2.32s\n",
            "754:\tlearn: 0.2957175\ttest: 0.3816460\tbest: 0.3767361 (341)\ttotal: 7.13s\tremaining: 2.31s\n",
            "755:\tlearn: 0.2954448\ttest: 0.3817402\tbest: 0.3767361 (341)\ttotal: 7.14s\tremaining: 2.3s\n",
            "756:\tlearn: 0.2953530\ttest: 0.3818198\tbest: 0.3767361 (341)\ttotal: 7.15s\tremaining: 2.29s\n",
            "757:\tlearn: 0.2953293\ttest: 0.3818287\tbest: 0.3767361 (341)\ttotal: 7.16s\tremaining: 2.28s\n",
            "758:\tlearn: 0.2952344\ttest: 0.3819429\tbest: 0.3767361 (341)\ttotal: 7.17s\tremaining: 2.27s\n",
            "759:\tlearn: 0.2951536\ttest: 0.3819954\tbest: 0.3767361 (341)\ttotal: 7.18s\tremaining: 2.27s\n",
            "760:\tlearn: 0.2950505\ttest: 0.3819741\tbest: 0.3767361 (341)\ttotal: 7.19s\tremaining: 2.26s\n",
            "761:\tlearn: 0.2950012\ttest: 0.3820226\tbest: 0.3767361 (341)\ttotal: 7.2s\tremaining: 2.25s\n",
            "762:\tlearn: 0.2949532\ttest: 0.3819471\tbest: 0.3767361 (341)\ttotal: 7.21s\tremaining: 2.24s\n",
            "763:\tlearn: 0.2948598\ttest: 0.3819214\tbest: 0.3767361 (341)\ttotal: 7.21s\tremaining: 2.23s\n",
            "764:\tlearn: 0.2946500\ttest: 0.3819393\tbest: 0.3767361 (341)\ttotal: 7.22s\tremaining: 2.22s\n",
            "765:\tlearn: 0.2946356\ttest: 0.3819234\tbest: 0.3767361 (341)\ttotal: 7.23s\tremaining: 2.21s\n",
            "766:\tlearn: 0.2945208\ttest: 0.3819684\tbest: 0.3767361 (341)\ttotal: 7.24s\tremaining: 2.2s\n",
            "767:\tlearn: 0.2944446\ttest: 0.3820087\tbest: 0.3767361 (341)\ttotal: 7.25s\tremaining: 2.19s\n",
            "768:\tlearn: 0.2944287\ttest: 0.3820099\tbest: 0.3767361 (341)\ttotal: 7.26s\tremaining: 2.18s\n",
            "769:\tlearn: 0.2943636\ttest: 0.3820645\tbest: 0.3767361 (341)\ttotal: 7.27s\tremaining: 2.17s\n",
            "770:\tlearn: 0.2942626\ttest: 0.3820548\tbest: 0.3767361 (341)\ttotal: 7.28s\tremaining: 2.16s\n",
            "771:\tlearn: 0.2940913\ttest: 0.3819698\tbest: 0.3767361 (341)\ttotal: 7.29s\tremaining: 2.15s\n",
            "772:\tlearn: 0.2940889\ttest: 0.3819788\tbest: 0.3767361 (341)\ttotal: 7.3s\tremaining: 2.14s\n",
            "773:\tlearn: 0.2938514\ttest: 0.3819751\tbest: 0.3767361 (341)\ttotal: 7.3s\tremaining: 2.13s\n",
            "774:\tlearn: 0.2937756\ttest: 0.3818988\tbest: 0.3767361 (341)\ttotal: 7.31s\tremaining: 2.12s\n",
            "775:\tlearn: 0.2936626\ttest: 0.3819573\tbest: 0.3767361 (341)\ttotal: 7.32s\tremaining: 2.11s\n",
            "776:\tlearn: 0.2936204\ttest: 0.3819206\tbest: 0.3767361 (341)\ttotal: 7.33s\tremaining: 2.1s\n",
            "777:\tlearn: 0.2935885\ttest: 0.3819436\tbest: 0.3767361 (341)\ttotal: 7.34s\tremaining: 2.09s\n",
            "778:\tlearn: 0.2934776\ttest: 0.3819100\tbest: 0.3767361 (341)\ttotal: 7.35s\tremaining: 2.08s\n",
            "779:\tlearn: 0.2934377\ttest: 0.3818734\tbest: 0.3767361 (341)\ttotal: 7.36s\tremaining: 2.08s\n",
            "780:\tlearn: 0.2933871\ttest: 0.3819108\tbest: 0.3767361 (341)\ttotal: 7.37s\tremaining: 2.07s\n",
            "781:\tlearn: 0.2933832\ttest: 0.3819136\tbest: 0.3767361 (341)\ttotal: 7.38s\tremaining: 2.06s\n",
            "782:\tlearn: 0.2933404\ttest: 0.3819616\tbest: 0.3767361 (341)\ttotal: 7.39s\tremaining: 2.05s\n",
            "783:\tlearn: 0.2931834\ttest: 0.3820703\tbest: 0.3767361 (341)\ttotal: 7.4s\tremaining: 2.04s\n",
            "784:\tlearn: 0.2931728\ttest: 0.3820772\tbest: 0.3767361 (341)\ttotal: 7.41s\tremaining: 2.03s\n",
            "785:\tlearn: 0.2930211\ttest: 0.3819627\tbest: 0.3767361 (341)\ttotal: 7.42s\tremaining: 2.02s\n",
            "786:\tlearn: 0.2929421\ttest: 0.3818482\tbest: 0.3767361 (341)\ttotal: 7.43s\tremaining: 2.01s\n",
            "787:\tlearn: 0.2928619\ttest: 0.3818592\tbest: 0.3767361 (341)\ttotal: 7.44s\tremaining: 2s\n",
            "788:\tlearn: 0.2927833\ttest: 0.3818278\tbest: 0.3767361 (341)\ttotal: 7.45s\tremaining: 1.99s\n",
            "789:\tlearn: 0.2927825\ttest: 0.3818308\tbest: 0.3767361 (341)\ttotal: 7.46s\tremaining: 1.98s\n",
            "790:\tlearn: 0.2926005\ttest: 0.3819648\tbest: 0.3767361 (341)\ttotal: 7.47s\tremaining: 1.97s\n",
            "791:\tlearn: 0.2924481\ttest: 0.3819563\tbest: 0.3767361 (341)\ttotal: 7.48s\tremaining: 1.96s\n",
            "792:\tlearn: 0.2923910\ttest: 0.3819290\tbest: 0.3767361 (341)\ttotal: 7.49s\tremaining: 1.95s\n",
            "793:\tlearn: 0.2923445\ttest: 0.3819805\tbest: 0.3767361 (341)\ttotal: 7.49s\tremaining: 1.94s\n",
            "794:\tlearn: 0.2922307\ttest: 0.3819479\tbest: 0.3767361 (341)\ttotal: 7.5s\tremaining: 1.93s\n",
            "795:\tlearn: 0.2920408\ttest: 0.3820281\tbest: 0.3767361 (341)\ttotal: 7.51s\tremaining: 1.92s\n",
            "796:\tlearn: 0.2919932\ttest: 0.3820974\tbest: 0.3767361 (341)\ttotal: 7.52s\tremaining: 1.92s\n",
            "797:\tlearn: 0.2919082\ttest: 0.3820691\tbest: 0.3767361 (341)\ttotal: 7.53s\tremaining: 1.91s\n",
            "798:\tlearn: 0.2918374\ttest: 0.3821203\tbest: 0.3767361 (341)\ttotal: 7.54s\tremaining: 1.9s\n",
            "799:\tlearn: 0.2918342\ttest: 0.3821209\tbest: 0.3767361 (341)\ttotal: 7.55s\tremaining: 1.89s\n",
            "800:\tlearn: 0.2917480\ttest: 0.3820987\tbest: 0.3767361 (341)\ttotal: 7.56s\tremaining: 1.88s\n",
            "801:\tlearn: 0.2917393\ttest: 0.3820989\tbest: 0.3767361 (341)\ttotal: 7.57s\tremaining: 1.87s\n",
            "802:\tlearn: 0.2916494\ttest: 0.3821097\tbest: 0.3767361 (341)\ttotal: 7.57s\tremaining: 1.86s\n",
            "803:\tlearn: 0.2916404\ttest: 0.3821064\tbest: 0.3767361 (341)\ttotal: 7.59s\tremaining: 1.85s\n",
            "804:\tlearn: 0.2916125\ttest: 0.3820680\tbest: 0.3767361 (341)\ttotal: 7.6s\tremaining: 1.84s\n",
            "805:\tlearn: 0.2915731\ttest: 0.3821307\tbest: 0.3767361 (341)\ttotal: 7.61s\tremaining: 1.83s\n",
            "806:\tlearn: 0.2915720\ttest: 0.3821365\tbest: 0.3767361 (341)\ttotal: 7.61s\tremaining: 1.82s\n",
            "807:\tlearn: 0.2914617\ttest: 0.3821934\tbest: 0.3767361 (341)\ttotal: 7.62s\tremaining: 1.81s\n",
            "808:\tlearn: 0.2914166\ttest: 0.3822569\tbest: 0.3767361 (341)\ttotal: 7.63s\tremaining: 1.8s\n",
            "809:\tlearn: 0.2913880\ttest: 0.3822309\tbest: 0.3767361 (341)\ttotal: 7.64s\tremaining: 1.79s\n",
            "810:\tlearn: 0.2913348\ttest: 0.3821903\tbest: 0.3767361 (341)\ttotal: 7.65s\tremaining: 1.78s\n",
            "811:\tlearn: 0.2912652\ttest: 0.3822354\tbest: 0.3767361 (341)\ttotal: 7.66s\tremaining: 1.77s\n",
            "812:\tlearn: 0.2912141\ttest: 0.3822582\tbest: 0.3767361 (341)\ttotal: 7.67s\tremaining: 1.76s\n",
            "813:\tlearn: 0.2910394\ttest: 0.3821893\tbest: 0.3767361 (341)\ttotal: 7.68s\tremaining: 1.75s\n",
            "814:\tlearn: 0.2909459\ttest: 0.3821623\tbest: 0.3767361 (341)\ttotal: 7.69s\tremaining: 1.74s\n",
            "815:\tlearn: 0.2908973\ttest: 0.3821904\tbest: 0.3767361 (341)\ttotal: 7.69s\tremaining: 1.74s\n",
            "816:\tlearn: 0.2907881\ttest: 0.3821762\tbest: 0.3767361 (341)\ttotal: 7.7s\tremaining: 1.73s\n",
            "817:\tlearn: 0.2905803\ttest: 0.3822269\tbest: 0.3767361 (341)\ttotal: 7.71s\tremaining: 1.72s\n",
            "818:\tlearn: 0.2904649\ttest: 0.3822793\tbest: 0.3767361 (341)\ttotal: 7.72s\tremaining: 1.71s\n",
            "819:\tlearn: 0.2904231\ttest: 0.3822984\tbest: 0.3767361 (341)\ttotal: 7.73s\tremaining: 1.7s\n",
            "820:\tlearn: 0.2903246\ttest: 0.3822320\tbest: 0.3767361 (341)\ttotal: 7.74s\tremaining: 1.69s\n",
            "821:\tlearn: 0.2903168\ttest: 0.3821988\tbest: 0.3767361 (341)\ttotal: 7.75s\tremaining: 1.68s\n",
            "822:\tlearn: 0.2902677\ttest: 0.3821563\tbest: 0.3767361 (341)\ttotal: 7.76s\tremaining: 1.67s\n",
            "823:\tlearn: 0.2901835\ttest: 0.3821553\tbest: 0.3767361 (341)\ttotal: 7.77s\tremaining: 1.66s\n",
            "824:\tlearn: 0.2901831\ttest: 0.3821609\tbest: 0.3767361 (341)\ttotal: 7.77s\tremaining: 1.65s\n",
            "825:\tlearn: 0.2901553\ttest: 0.3821919\tbest: 0.3767361 (341)\ttotal: 7.78s\tremaining: 1.64s\n",
            "826:\tlearn: 0.2901496\ttest: 0.3822133\tbest: 0.3767361 (341)\ttotal: 7.8s\tremaining: 1.63s\n",
            "827:\tlearn: 0.2901200\ttest: 0.3822254\tbest: 0.3767361 (341)\ttotal: 7.81s\tremaining: 1.62s\n",
            "828:\tlearn: 0.2900229\ttest: 0.3822243\tbest: 0.3767361 (341)\ttotal: 7.81s\tremaining: 1.61s\n",
            "829:\tlearn: 0.2899307\ttest: 0.3821662\tbest: 0.3767361 (341)\ttotal: 7.82s\tremaining: 1.6s\n",
            "830:\tlearn: 0.2899299\ttest: 0.3821735\tbest: 0.3767361 (341)\ttotal: 7.85s\tremaining: 1.59s\n",
            "831:\tlearn: 0.2899133\ttest: 0.3821978\tbest: 0.3767361 (341)\ttotal: 7.86s\tremaining: 1.59s\n",
            "832:\tlearn: 0.2898971\ttest: 0.3822498\tbest: 0.3767361 (341)\ttotal: 7.86s\tremaining: 1.58s\n",
            "833:\tlearn: 0.2897837\ttest: 0.3823670\tbest: 0.3767361 (341)\ttotal: 7.87s\tremaining: 1.57s\n",
            "834:\tlearn: 0.2896951\ttest: 0.3824546\tbest: 0.3767361 (341)\ttotal: 7.88s\tremaining: 1.56s\n",
            "835:\tlearn: 0.2895625\ttest: 0.3824859\tbest: 0.3767361 (341)\ttotal: 7.9s\tremaining: 1.55s\n",
            "836:\tlearn: 0.2895435\ttest: 0.3825451\tbest: 0.3767361 (341)\ttotal: 7.91s\tremaining: 1.54s\n",
            "837:\tlearn: 0.2894731\ttest: 0.3825150\tbest: 0.3767361 (341)\ttotal: 7.91s\tremaining: 1.53s\n",
            "838:\tlearn: 0.2894446\ttest: 0.3825137\tbest: 0.3767361 (341)\ttotal: 7.92s\tremaining: 1.52s\n",
            "839:\tlearn: 0.2893500\ttest: 0.3825238\tbest: 0.3767361 (341)\ttotal: 7.93s\tremaining: 1.51s\n",
            "840:\tlearn: 0.2893263\ttest: 0.3825715\tbest: 0.3767361 (341)\ttotal: 7.94s\tremaining: 1.5s\n",
            "841:\tlearn: 0.2892662\ttest: 0.3825353\tbest: 0.3767361 (341)\ttotal: 7.95s\tremaining: 1.49s\n",
            "842:\tlearn: 0.2892073\ttest: 0.3825375\tbest: 0.3767361 (341)\ttotal: 7.96s\tremaining: 1.48s\n",
            "843:\tlearn: 0.2890152\ttest: 0.3826066\tbest: 0.3767361 (341)\ttotal: 7.97s\tremaining: 1.47s\n",
            "844:\tlearn: 0.2889057\ttest: 0.3825820\tbest: 0.3767361 (341)\ttotal: 7.98s\tremaining: 1.46s\n",
            "845:\tlearn: 0.2888561\ttest: 0.3825611\tbest: 0.3767361 (341)\ttotal: 7.99s\tremaining: 1.45s\n",
            "846:\tlearn: 0.2887511\ttest: 0.3826884\tbest: 0.3767361 (341)\ttotal: 8s\tremaining: 1.45s\n",
            "847:\tlearn: 0.2887452\ttest: 0.3826964\tbest: 0.3767361 (341)\ttotal: 8.01s\tremaining: 1.44s\n",
            "848:\tlearn: 0.2886728\ttest: 0.3826562\tbest: 0.3767361 (341)\ttotal: 8.02s\tremaining: 1.43s\n",
            "849:\tlearn: 0.2886287\ttest: 0.3826658\tbest: 0.3767361 (341)\ttotal: 8.03s\tremaining: 1.42s\n",
            "850:\tlearn: 0.2884929\ttest: 0.3825988\tbest: 0.3767361 (341)\ttotal: 8.04s\tremaining: 1.41s\n",
            "851:\tlearn: 0.2882793\ttest: 0.3826188\tbest: 0.3767361 (341)\ttotal: 8.05s\tremaining: 1.4s\n",
            "852:\tlearn: 0.2881932\ttest: 0.3826206\tbest: 0.3767361 (341)\ttotal: 8.06s\tremaining: 1.39s\n",
            "853:\tlearn: 0.2881461\ttest: 0.3826876\tbest: 0.3767361 (341)\ttotal: 8.06s\tremaining: 1.38s\n",
            "854:\tlearn: 0.2880078\ttest: 0.3826754\tbest: 0.3767361 (341)\ttotal: 8.07s\tremaining: 1.37s\n",
            "855:\tlearn: 0.2877995\ttest: 0.3826705\tbest: 0.3767361 (341)\ttotal: 8.08s\tremaining: 1.36s\n",
            "856:\tlearn: 0.2877246\ttest: 0.3826982\tbest: 0.3767361 (341)\ttotal: 8.09s\tremaining: 1.35s\n",
            "857:\tlearn: 0.2876546\ttest: 0.3827625\tbest: 0.3767361 (341)\ttotal: 8.1s\tremaining: 1.34s\n",
            "858:\tlearn: 0.2875564\ttest: 0.3826981\tbest: 0.3767361 (341)\ttotal: 8.11s\tremaining: 1.33s\n",
            "859:\tlearn: 0.2875066\ttest: 0.3827769\tbest: 0.3767361 (341)\ttotal: 8.12s\tremaining: 1.32s\n",
            "860:\tlearn: 0.2874415\ttest: 0.3828309\tbest: 0.3767361 (341)\ttotal: 8.13s\tremaining: 1.31s\n",
            "861:\tlearn: 0.2873501\ttest: 0.3827803\tbest: 0.3767361 (341)\ttotal: 8.14s\tremaining: 1.3s\n",
            "862:\tlearn: 0.2872340\ttest: 0.3828063\tbest: 0.3767361 (341)\ttotal: 8.15s\tremaining: 1.29s\n",
            "863:\tlearn: 0.2871859\ttest: 0.3827671\tbest: 0.3767361 (341)\ttotal: 8.16s\tremaining: 1.28s\n",
            "864:\tlearn: 0.2871330\ttest: 0.3827828\tbest: 0.3767361 (341)\ttotal: 8.16s\tremaining: 1.27s\n",
            "865:\tlearn: 0.2870696\ttest: 0.3828412\tbest: 0.3767361 (341)\ttotal: 8.17s\tremaining: 1.26s\n",
            "866:\tlearn: 0.2870092\ttest: 0.3828294\tbest: 0.3767361 (341)\ttotal: 8.18s\tremaining: 1.25s\n",
            "867:\tlearn: 0.2869183\ttest: 0.3828602\tbest: 0.3767361 (341)\ttotal: 8.19s\tremaining: 1.25s\n",
            "868:\tlearn: 0.2868801\ttest: 0.3829055\tbest: 0.3767361 (341)\ttotal: 8.2s\tremaining: 1.24s\n",
            "869:\tlearn: 0.2868469\ttest: 0.3829376\tbest: 0.3767361 (341)\ttotal: 8.21s\tremaining: 1.23s\n",
            "870:\tlearn: 0.2867667\ttest: 0.3829601\tbest: 0.3767361 (341)\ttotal: 8.22s\tremaining: 1.22s\n",
            "871:\tlearn: 0.2867520\ttest: 0.3829739\tbest: 0.3767361 (341)\ttotal: 8.23s\tremaining: 1.21s\n",
            "872:\tlearn: 0.2867512\ttest: 0.3829759\tbest: 0.3767361 (341)\ttotal: 8.24s\tremaining: 1.2s\n",
            "873:\tlearn: 0.2867495\ttest: 0.3829811\tbest: 0.3767361 (341)\ttotal: 8.24s\tremaining: 1.19s\n",
            "874:\tlearn: 0.2867039\ttest: 0.3829496\tbest: 0.3767361 (341)\ttotal: 8.25s\tremaining: 1.18s\n",
            "875:\tlearn: 0.2867016\ttest: 0.3829434\tbest: 0.3767361 (341)\ttotal: 8.26s\tremaining: 1.17s\n",
            "876:\tlearn: 0.2866040\ttest: 0.3829823\tbest: 0.3767361 (341)\ttotal: 8.27s\tremaining: 1.16s\n",
            "877:\tlearn: 0.2865771\ttest: 0.3830225\tbest: 0.3767361 (341)\ttotal: 8.28s\tremaining: 1.15s\n",
            "878:\tlearn: 0.2865743\ttest: 0.3830340\tbest: 0.3767361 (341)\ttotal: 8.29s\tremaining: 1.14s\n",
            "879:\tlearn: 0.2864764\ttest: 0.3832645\tbest: 0.3767361 (341)\ttotal: 8.3s\tremaining: 1.13s\n",
            "880:\tlearn: 0.2864257\ttest: 0.3832124\tbest: 0.3767361 (341)\ttotal: 8.31s\tremaining: 1.12s\n",
            "881:\tlearn: 0.2863958\ttest: 0.3832171\tbest: 0.3767361 (341)\ttotal: 8.31s\tremaining: 1.11s\n",
            "882:\tlearn: 0.2863559\ttest: 0.3833126\tbest: 0.3767361 (341)\ttotal: 8.32s\tremaining: 1.1s\n",
            "883:\tlearn: 0.2862390\ttest: 0.3833576\tbest: 0.3767361 (341)\ttotal: 8.33s\tremaining: 1.09s\n",
            "884:\tlearn: 0.2861546\ttest: 0.3834146\tbest: 0.3767361 (341)\ttotal: 8.34s\tremaining: 1.08s\n",
            "885:\tlearn: 0.2861448\ttest: 0.3834392\tbest: 0.3767361 (341)\ttotal: 8.35s\tremaining: 1.07s\n",
            "886:\tlearn: 0.2860815\ttest: 0.3834726\tbest: 0.3767361 (341)\ttotal: 8.36s\tremaining: 1.06s\n",
            "887:\tlearn: 0.2859479\ttest: 0.3834914\tbest: 0.3767361 (341)\ttotal: 8.37s\tremaining: 1.05s\n",
            "888:\tlearn: 0.2859086\ttest: 0.3835398\tbest: 0.3767361 (341)\ttotal: 8.38s\tremaining: 1.05s\n",
            "889:\tlearn: 0.2858330\ttest: 0.3836276\tbest: 0.3767361 (341)\ttotal: 8.39s\tremaining: 1.04s\n",
            "890:\tlearn: 0.2856875\ttest: 0.3836237\tbest: 0.3767361 (341)\ttotal: 8.4s\tremaining: 1.03s\n",
            "891:\tlearn: 0.2855099\ttest: 0.3836474\tbest: 0.3767361 (341)\ttotal: 8.42s\tremaining: 1.02s\n",
            "892:\tlearn: 0.2854634\ttest: 0.3836619\tbest: 0.3767361 (341)\ttotal: 8.43s\tremaining: 1.01s\n",
            "893:\tlearn: 0.2854565\ttest: 0.3836543\tbest: 0.3767361 (341)\ttotal: 8.44s\tremaining: 1s\n",
            "894:\tlearn: 0.2852960\ttest: 0.3836400\tbest: 0.3767361 (341)\ttotal: 8.45s\tremaining: 991ms\n",
            "895:\tlearn: 0.2851716\ttest: 0.3837680\tbest: 0.3767361 (341)\ttotal: 8.46s\tremaining: 982ms\n",
            "896:\tlearn: 0.2850935\ttest: 0.3838244\tbest: 0.3767361 (341)\ttotal: 8.47s\tremaining: 972ms\n",
            "897:\tlearn: 0.2849982\ttest: 0.3839108\tbest: 0.3767361 (341)\ttotal: 8.48s\tremaining: 963ms\n",
            "898:\tlearn: 0.2848992\ttest: 0.3839951\tbest: 0.3767361 (341)\ttotal: 8.48s\tremaining: 953ms\n",
            "899:\tlearn: 0.2848003\ttest: 0.3840825\tbest: 0.3767361 (341)\ttotal: 8.49s\tremaining: 944ms\n",
            "900:\tlearn: 0.2846183\ttest: 0.3840617\tbest: 0.3767361 (341)\ttotal: 8.5s\tremaining: 934ms\n",
            "901:\tlearn: 0.2845544\ttest: 0.3840506\tbest: 0.3767361 (341)\ttotal: 8.51s\tremaining: 925ms\n",
            "902:\tlearn: 0.2845536\ttest: 0.3840537\tbest: 0.3767361 (341)\ttotal: 8.52s\tremaining: 915ms\n",
            "903:\tlearn: 0.2844691\ttest: 0.3840920\tbest: 0.3767361 (341)\ttotal: 8.53s\tremaining: 906ms\n",
            "904:\tlearn: 0.2844181\ttest: 0.3840853\tbest: 0.3767361 (341)\ttotal: 8.54s\tremaining: 897ms\n",
            "905:\tlearn: 0.2843425\ttest: 0.3840073\tbest: 0.3767361 (341)\ttotal: 8.55s\tremaining: 887ms\n",
            "906:\tlearn: 0.2843418\ttest: 0.3840021\tbest: 0.3767361 (341)\ttotal: 8.56s\tremaining: 878ms\n",
            "907:\tlearn: 0.2842338\ttest: 0.3839208\tbest: 0.3767361 (341)\ttotal: 8.57s\tremaining: 868ms\n",
            "908:\tlearn: 0.2841474\ttest: 0.3839900\tbest: 0.3767361 (341)\ttotal: 8.58s\tremaining: 859ms\n",
            "909:\tlearn: 0.2841347\ttest: 0.3839684\tbest: 0.3767361 (341)\ttotal: 8.59s\tremaining: 849ms\n",
            "910:\tlearn: 0.2840526\ttest: 0.3839758\tbest: 0.3767361 (341)\ttotal: 8.6s\tremaining: 840ms\n",
            "911:\tlearn: 0.2840234\ttest: 0.3839899\tbest: 0.3767361 (341)\ttotal: 8.61s\tremaining: 831ms\n",
            "912:\tlearn: 0.2839162\ttest: 0.3840387\tbest: 0.3767361 (341)\ttotal: 8.62s\tremaining: 822ms\n",
            "913:\tlearn: 0.2838627\ttest: 0.3840222\tbest: 0.3767361 (341)\ttotal: 8.63s\tremaining: 812ms\n",
            "914:\tlearn: 0.2837587\ttest: 0.3839584\tbest: 0.3767361 (341)\ttotal: 8.64s\tremaining: 803ms\n",
            "915:\tlearn: 0.2837581\ttest: 0.3839531\tbest: 0.3767361 (341)\ttotal: 8.65s\tremaining: 793ms\n",
            "916:\tlearn: 0.2837390\ttest: 0.3839631\tbest: 0.3767361 (341)\ttotal: 8.66s\tremaining: 784ms\n",
            "917:\tlearn: 0.2836454\ttest: 0.3839521\tbest: 0.3767361 (341)\ttotal: 8.67s\tremaining: 774ms\n",
            "918:\tlearn: 0.2835764\ttest: 0.3839890\tbest: 0.3767361 (341)\ttotal: 8.68s\tremaining: 765ms\n",
            "919:\tlearn: 0.2834390\ttest: 0.3840177\tbest: 0.3767361 (341)\ttotal: 8.69s\tremaining: 755ms\n",
            "920:\tlearn: 0.2834385\ttest: 0.3840184\tbest: 0.3767361 (341)\ttotal: 8.7s\tremaining: 746ms\n",
            "921:\tlearn: 0.2834196\ttest: 0.3840044\tbest: 0.3767361 (341)\ttotal: 8.71s\tremaining: 737ms\n",
            "922:\tlearn: 0.2833896\ttest: 0.3840016\tbest: 0.3767361 (341)\ttotal: 8.72s\tremaining: 727ms\n",
            "923:\tlearn: 0.2833048\ttest: 0.3840358\tbest: 0.3767361 (341)\ttotal: 8.72s\tremaining: 718ms\n",
            "924:\tlearn: 0.2832530\ttest: 0.3840886\tbest: 0.3767361 (341)\ttotal: 8.73s\tremaining: 708ms\n",
            "925:\tlearn: 0.2831143\ttest: 0.3842156\tbest: 0.3767361 (341)\ttotal: 8.74s\tremaining: 699ms\n",
            "926:\tlearn: 0.2830702\ttest: 0.3842994\tbest: 0.3767361 (341)\ttotal: 8.75s\tremaining: 689ms\n",
            "927:\tlearn: 0.2830084\ttest: 0.3842679\tbest: 0.3767361 (341)\ttotal: 8.76s\tremaining: 680ms\n",
            "928:\tlearn: 0.2830037\ttest: 0.3842769\tbest: 0.3767361 (341)\ttotal: 8.77s\tremaining: 670ms\n",
            "929:\tlearn: 0.2828607\ttest: 0.3843830\tbest: 0.3767361 (341)\ttotal: 8.78s\tremaining: 661ms\n",
            "930:\tlearn: 0.2827182\ttest: 0.3844127\tbest: 0.3767361 (341)\ttotal: 8.79s\tremaining: 651ms\n",
            "931:\tlearn: 0.2826317\ttest: 0.3844350\tbest: 0.3767361 (341)\ttotal: 8.8s\tremaining: 642ms\n",
            "932:\tlearn: 0.2825252\ttest: 0.3844213\tbest: 0.3767361 (341)\ttotal: 8.81s\tremaining: 632ms\n",
            "933:\tlearn: 0.2825250\ttest: 0.3844222\tbest: 0.3767361 (341)\ttotal: 8.82s\tremaining: 623ms\n",
            "934:\tlearn: 0.2824526\ttest: 0.3843677\tbest: 0.3767361 (341)\ttotal: 8.84s\tremaining: 615ms\n",
            "935:\tlearn: 0.2823751\ttest: 0.3844051\tbest: 0.3767361 (341)\ttotal: 8.85s\tremaining: 605ms\n",
            "936:\tlearn: 0.2823209\ttest: 0.3844437\tbest: 0.3767361 (341)\ttotal: 8.86s\tremaining: 596ms\n",
            "937:\tlearn: 0.2821640\ttest: 0.3844494\tbest: 0.3767361 (341)\ttotal: 8.87s\tremaining: 586ms\n",
            "938:\tlearn: 0.2821621\ttest: 0.3844381\tbest: 0.3767361 (341)\ttotal: 8.88s\tremaining: 577ms\n",
            "939:\tlearn: 0.2821312\ttest: 0.3844936\tbest: 0.3767361 (341)\ttotal: 8.89s\tremaining: 567ms\n",
            "940:\tlearn: 0.2820685\ttest: 0.3845330\tbest: 0.3767361 (341)\ttotal: 8.9s\tremaining: 558ms\n",
            "941:\tlearn: 0.2820302\ttest: 0.3845189\tbest: 0.3767361 (341)\ttotal: 8.91s\tremaining: 548ms\n",
            "942:\tlearn: 0.2819838\ttest: 0.3845198\tbest: 0.3767361 (341)\ttotal: 8.92s\tremaining: 539ms\n",
            "943:\tlearn: 0.2818856\ttest: 0.3844885\tbest: 0.3767361 (341)\ttotal: 8.93s\tremaining: 530ms\n",
            "944:\tlearn: 0.2818408\ttest: 0.3845630\tbest: 0.3767361 (341)\ttotal: 8.94s\tremaining: 520ms\n",
            "945:\tlearn: 0.2816143\ttest: 0.3845592\tbest: 0.3767361 (341)\ttotal: 8.95s\tremaining: 511ms\n",
            "946:\tlearn: 0.2814596\ttest: 0.3845868\tbest: 0.3767361 (341)\ttotal: 8.95s\tremaining: 501ms\n",
            "947:\tlearn: 0.2813198\ttest: 0.3844892\tbest: 0.3767361 (341)\ttotal: 8.96s\tremaining: 492ms\n",
            "948:\tlearn: 0.2812637\ttest: 0.3845233\tbest: 0.3767361 (341)\ttotal: 8.97s\tremaining: 482ms\n",
            "949:\tlearn: 0.2812630\ttest: 0.3845272\tbest: 0.3767361 (341)\ttotal: 8.98s\tremaining: 473ms\n",
            "950:\tlearn: 0.2812210\ttest: 0.3845168\tbest: 0.3767361 (341)\ttotal: 8.99s\tremaining: 463ms\n",
            "951:\tlearn: 0.2811889\ttest: 0.3845509\tbest: 0.3767361 (341)\ttotal: 9s\tremaining: 454ms\n",
            "952:\tlearn: 0.2811015\ttest: 0.3845645\tbest: 0.3767361 (341)\ttotal: 9.01s\tremaining: 444ms\n",
            "953:\tlearn: 0.2810783\ttest: 0.3845149\tbest: 0.3767361 (341)\ttotal: 9.02s\tremaining: 435ms\n",
            "954:\tlearn: 0.2810767\ttest: 0.3845185\tbest: 0.3767361 (341)\ttotal: 9.03s\tremaining: 425ms\n",
            "955:\tlearn: 0.2810122\ttest: 0.3845766\tbest: 0.3767361 (341)\ttotal: 9.04s\tremaining: 416ms\n",
            "956:\tlearn: 0.2809456\ttest: 0.3845242\tbest: 0.3767361 (341)\ttotal: 9.05s\tremaining: 407ms\n",
            "957:\tlearn: 0.2809240\ttest: 0.3845361\tbest: 0.3767361 (341)\ttotal: 9.06s\tremaining: 397ms\n",
            "958:\tlearn: 0.2808554\ttest: 0.3845318\tbest: 0.3767361 (341)\ttotal: 9.07s\tremaining: 388ms\n",
            "959:\tlearn: 0.2808220\ttest: 0.3845395\tbest: 0.3767361 (341)\ttotal: 9.07s\tremaining: 378ms\n",
            "960:\tlearn: 0.2807992\ttest: 0.3845740\tbest: 0.3767361 (341)\ttotal: 9.08s\tremaining: 369ms\n",
            "961:\tlearn: 0.2806955\ttest: 0.3847050\tbest: 0.3767361 (341)\ttotal: 9.09s\tremaining: 359ms\n",
            "962:\tlearn: 0.2806887\ttest: 0.3847363\tbest: 0.3767361 (341)\ttotal: 9.1s\tremaining: 350ms\n",
            "963:\tlearn: 0.2806503\ttest: 0.3848130\tbest: 0.3767361 (341)\ttotal: 9.11s\tremaining: 340ms\n",
            "964:\tlearn: 0.2806094\ttest: 0.3848578\tbest: 0.3767361 (341)\ttotal: 9.12s\tremaining: 331ms\n",
            "965:\tlearn: 0.2806011\ttest: 0.3848434\tbest: 0.3767361 (341)\ttotal: 9.13s\tremaining: 321ms\n",
            "966:\tlearn: 0.2805990\ttest: 0.3848640\tbest: 0.3767361 (341)\ttotal: 9.14s\tremaining: 312ms\n",
            "967:\tlearn: 0.2805471\ttest: 0.3848593\tbest: 0.3767361 (341)\ttotal: 9.15s\tremaining: 302ms\n",
            "968:\tlearn: 0.2804544\ttest: 0.3848732\tbest: 0.3767361 (341)\ttotal: 9.16s\tremaining: 293ms\n",
            "969:\tlearn: 0.2803926\ttest: 0.3848619\tbest: 0.3767361 (341)\ttotal: 9.16s\tremaining: 283ms\n",
            "970:\tlearn: 0.2803911\ttest: 0.3848609\tbest: 0.3767361 (341)\ttotal: 9.17s\tremaining: 274ms\n",
            "971:\tlearn: 0.2803115\ttest: 0.3848268\tbest: 0.3767361 (341)\ttotal: 9.18s\tremaining: 265ms\n",
            "972:\tlearn: 0.2802665\ttest: 0.3848916\tbest: 0.3767361 (341)\ttotal: 9.19s\tremaining: 255ms\n",
            "973:\tlearn: 0.2802099\ttest: 0.3848853\tbest: 0.3767361 (341)\ttotal: 9.2s\tremaining: 246ms\n",
            "974:\tlearn: 0.2801272\ttest: 0.3848529\tbest: 0.3767361 (341)\ttotal: 9.21s\tremaining: 236ms\n",
            "975:\tlearn: 0.2801122\ttest: 0.3848555\tbest: 0.3767361 (341)\ttotal: 9.22s\tremaining: 227ms\n",
            "976:\tlearn: 0.2801103\ttest: 0.3848586\tbest: 0.3767361 (341)\ttotal: 9.23s\tremaining: 217ms\n",
            "977:\tlearn: 0.2800564\ttest: 0.3849750\tbest: 0.3767361 (341)\ttotal: 9.24s\tremaining: 208ms\n",
            "978:\tlearn: 0.2800152\ttest: 0.3849871\tbest: 0.3767361 (341)\ttotal: 9.25s\tremaining: 198ms\n",
            "979:\tlearn: 0.2799717\ttest: 0.3850639\tbest: 0.3767361 (341)\ttotal: 9.26s\tremaining: 189ms\n",
            "980:\tlearn: 0.2799402\ttest: 0.3850730\tbest: 0.3767361 (341)\ttotal: 9.27s\tremaining: 179ms\n",
            "981:\tlearn: 0.2798951\ttest: 0.3850350\tbest: 0.3767361 (341)\ttotal: 9.28s\tremaining: 170ms\n",
            "982:\tlearn: 0.2798839\ttest: 0.3850608\tbest: 0.3767361 (341)\ttotal: 9.29s\tremaining: 161ms\n",
            "983:\tlearn: 0.2797144\ttest: 0.3850307\tbest: 0.3767361 (341)\ttotal: 9.3s\tremaining: 151ms\n",
            "984:\tlearn: 0.2797139\ttest: 0.3850341\tbest: 0.3767361 (341)\ttotal: 9.31s\tremaining: 142ms\n",
            "985:\tlearn: 0.2796118\ttest: 0.3851855\tbest: 0.3767361 (341)\ttotal: 9.32s\tremaining: 132ms\n",
            "986:\tlearn: 0.2795815\ttest: 0.3852024\tbest: 0.3767361 (341)\ttotal: 9.33s\tremaining: 123ms\n",
            "987:\tlearn: 0.2795119\ttest: 0.3851307\tbest: 0.3767361 (341)\ttotal: 9.34s\tremaining: 113ms\n",
            "988:\tlearn: 0.2793970\ttest: 0.3850848\tbest: 0.3767361 (341)\ttotal: 9.34s\tremaining: 104ms\n",
            "989:\tlearn: 0.2793595\ttest: 0.3850473\tbest: 0.3767361 (341)\ttotal: 9.35s\tremaining: 94.5ms\n",
            "990:\tlearn: 0.2792684\ttest: 0.3851145\tbest: 0.3767361 (341)\ttotal: 9.36s\tremaining: 85ms\n",
            "991:\tlearn: 0.2792635\ttest: 0.3851055\tbest: 0.3767361 (341)\ttotal: 9.38s\tremaining: 75.6ms\n",
            "992:\tlearn: 0.2792632\ttest: 0.3851087\tbest: 0.3767361 (341)\ttotal: 9.38s\tremaining: 66.2ms\n",
            "993:\tlearn: 0.2791455\ttest: 0.3850311\tbest: 0.3767361 (341)\ttotal: 9.39s\tremaining: 56.7ms\n",
            "994:\tlearn: 0.2790316\ttest: 0.3851612\tbest: 0.3767361 (341)\ttotal: 9.4s\tremaining: 47.2ms\n",
            "995:\tlearn: 0.2789343\ttest: 0.3851300\tbest: 0.3767361 (341)\ttotal: 9.41s\tremaining: 37.8ms\n",
            "996:\tlearn: 0.2788343\ttest: 0.3851087\tbest: 0.3767361 (341)\ttotal: 9.43s\tremaining: 28.4ms\n",
            "997:\tlearn: 0.2788127\ttest: 0.3851013\tbest: 0.3767361 (341)\ttotal: 9.44s\tremaining: 18.9ms\n",
            "998:\tlearn: 0.2788124\ttest: 0.3851044\tbest: 0.3767361 (341)\ttotal: 9.45s\tremaining: 9.46ms\n",
            "999:\tlearn: 0.2787546\ttest: 0.3850815\tbest: 0.3767361 (341)\ttotal: 9.46s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.3767360529\n",
            "bestIteration = 341\n",
            "\n",
            "Shrink model to first 342 iterations.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f74ec5caf98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 548
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UZN9ET0DsBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_pred = model_cat.predict(x_val)\n",
        "cat_test = model_cat.predict(test[x_train.columns])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dInGNTtDy45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "dcfc1b72-0237-4b42-dcbb-44ac76c5f322"
      },
      "source": [
        "evaluate_model(cat_pred)"
      ],
      "execution_count": 550,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONFUSION MATRIX\n",
            "True         0     1\n",
            "Predicted           \n",
            "0          249    87\n",
            "1          213  1551\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.54      0.62       462\n",
            "           1       0.88      0.95      0.91      1638\n",
            "\n",
            "    accuracy                           0.86      2100\n",
            "   macro avg       0.81      0.74      0.77      2100\n",
            "weighted avg       0.85      0.86      0.85      2100\n",
            "\n",
            "MATHEWS CORRELATION COEFFICIENT\n",
            "0.5489830896849044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTBN9WpOGC8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(random_state=0,n_estimators=800,class_weight='balanced')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fpQJtJuGi6G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "13e2a154-83ae-4ee4-b21a-36af105141da"
      },
      "source": [
        "clf.fit(x_train,y_train)"
      ],
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=800,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHY5Pk-3GjnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_pred = clf.predict(x_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LY-iebRHXD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "5cd903b9-7732-48a5-c63d-b14c0fe022ca"
      },
      "source": [
        "evaluate_model(rf_pred)"
      ],
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONFUSION MATRIX\n",
            "True         0     1\n",
            "Predicted           \n",
            "0          236   141\n",
            "1          226  1497\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.51      0.56       462\n",
            "           1       0.87      0.91      0.89      1638\n",
            "\n",
            "    accuracy                           0.83      2100\n",
            "   macro avg       0.75      0.71      0.73      2100\n",
            "weighted avg       0.82      0.83      0.82      2100\n",
            "\n",
            "MATHEWS CORRELATION COEFFICIENT\n",
            "0.4584476526705689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOgd3LKH1Ust",
        "colab_type": "text"
      },
      "source": [
        "HYPER PARAMETER TUNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBJlxQ7FH3dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Objective Function\n",
        "train_data = lgb.Dataset(data=x_train, label=y_train, free_raw_data=False)\n",
        "def lgb_eval(learning_rate,num_leaves, feature_fraction,\\\n",
        "             bagging_fraction, max_depth, \\\n",
        "             lambda_l1, lambda_l2,\\\n",
        "             min_split_gain, min_child_weight,subsample):\n",
        "        params = {'application':'binary','num_iterations': 1500,\n",
        "                  'early_stopping_round':150,'class_weight':'balanced',\n",
        "                  'metric':'auc'} # ,'boost_from_average':False}\n",
        "        params['learning_rate'] = max(min(learning_rate, 1), 0)          \n",
        "        params[\"num_leaves\"] = int(round(num_leaves))\n",
        "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
        "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
        "        params['max_depth'] = int(round(max_depth))\n",
        "        params['lambda_l1'] = max(lambda_l1, 0)\n",
        "        params['lambda_l2'] = max(lambda_l2, 0)\n",
        "        params['min_split_gain'] = min_split_gain\n",
        "        params['min_child_weight'] = min_child_weight,\n",
        "        params['subsample'] = max(min(subsample, 1), 0)\n",
        "        cv_result = lgb.cv(params, train_data, nfold=5, seed=11,\n",
        "                           stratified=True,categorical_feature=['DAYTYPE'],\n",
        "                            verbose_eval =None)\n",
        "        return max(cv_result['auc-mean'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2uMxsSH1Yz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pbs = {'learning_rate': (0.01, 1.0),\n",
        "    'num_leaves': (200, 400),\n",
        "        'feature_fraction': (0.1, 0.9),\n",
        "        'bagging_fraction': (0.8, 1),\n",
        "        'max_depth': (11, 29),\n",
        "        'lambda_l1': (0, 2),\n",
        "        'lambda_l2': (0, 3),\n",
        "        'min_split_gain': (0.001, 0.1),\n",
        "        'min_child_weight': (1, 10),\n",
        "       'subsample': (0.01, 1.0)\n",
        "      }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha72IYwx1dks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "outputId": "dd7f0a12-ab59-4d4e-ab21-d202024f6940"
      },
      "source": [
        "!pip install bayesian-optimization\n",
        "from bayes_opt import BayesianOptimization\n",
        "optimizer = BayesianOptimization(lgb_eval, pbs, random_state=0)\n",
        "optimizer.maximize(init_points=5, n_iter=30)"
      ],
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/26/9842333adbb8f17bcb3d699400a8b1ccde0af0b6de8d07224e183728acdf/bayesian_optimization-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.18.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.14.1)\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.1.0\n",
            "|   iter    |  target   | baggin... | featur... | lambda_l1 | lambda_l2 | learni... | max_depth | min_ch... | min_sp... | num_le... | subsample |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7976  \u001b[0m | \u001b[0m 0.9098  \u001b[0m | \u001b[0m 0.6722  \u001b[0m | \u001b[0m 1.206   \u001b[0m | \u001b[0m 1.635   \u001b[0m | \u001b[0m 0.4294  \u001b[0m | \u001b[0m 22.63   \u001b[0m | \u001b[0m 4.938   \u001b[0m | \u001b[0m 0.08929 \u001b[0m | \u001b[0m 392.7   \u001b[0m | \u001b[0m 0.3896  \u001b[0m |\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8036  \u001b[0m | \u001b[95m 0.9583  \u001b[0m | \u001b[95m 0.5231  \u001b[0m | \u001b[95m 1.136   \u001b[0m | \u001b[95m 2.777   \u001b[0m | \u001b[95m 0.08033 \u001b[0m | \u001b[95m 12.57   \u001b[0m | \u001b[95m 1.182   \u001b[0m | \u001b[95m 0.08343 \u001b[0m | \u001b[95m 355.6   \u001b[0m | \u001b[95m 0.8713  \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8005  \u001b[0m | \u001b[0m 0.9957  \u001b[0m | \u001b[0m 0.7393  \u001b[0m | \u001b[0m 0.923   \u001b[0m | \u001b[0m 2.342   \u001b[0m | \u001b[0m 0.1271  \u001b[0m | \u001b[0m 22.52   \u001b[0m | \u001b[0m 2.29    \u001b[0m | \u001b[0m 0.09452 \u001b[0m | \u001b[0m 304.4   \u001b[0m | \u001b[0m 0.4205  \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.8529  \u001b[0m | \u001b[0m 0.7194  \u001b[0m | \u001b[0m 0.9123  \u001b[0m | \u001b[0m 1.705   \u001b[0m | \u001b[0m 0.0286  \u001b[0m | \u001b[0m 22.12   \u001b[0m | \u001b[0m 6.509   \u001b[0m | \u001b[0m 0.06208 \u001b[0m | \u001b[0m 388.7   \u001b[0m | \u001b[0m 0.685   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7895  \u001b[0m | \u001b[0m 0.8719  \u001b[0m | \u001b[0m 0.4496  \u001b[0m | \u001b[0m 1.395   \u001b[0m | \u001b[0m 0.1807  \u001b[0m | \u001b[0m 0.6701  \u001b[0m | \u001b[0m 23.07   \u001b[0m | \u001b[0m 2.893   \u001b[0m | \u001b[0m 0.01376 \u001b[0m | \u001b[0m 263.1   \u001b[0m | \u001b[0m 0.3701  \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7921  \u001b[0m | \u001b[0m 0.9415  \u001b[0m | \u001b[0m 0.2709  \u001b[0m | \u001b[0m 0.6486  \u001b[0m | \u001b[0m 2.534   \u001b[0m | \u001b[0m 0.9341  \u001b[0m | \u001b[0m 11.01   \u001b[0m | \u001b[0m 9.696   \u001b[0m | \u001b[0m 0.06026 \u001b[0m | \u001b[0m 315.9   \u001b[0m | \u001b[0m 0.2315  \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.9556  \u001b[0m | \u001b[0m 0.5801  \u001b[0m | \u001b[0m 0.4694  \u001b[0m | \u001b[0m 0.1298  \u001b[0m | \u001b[0m 0.02768 \u001b[0m | \u001b[0m 28.56   \u001b[0m | \u001b[0m 2.4     \u001b[0m | \u001b[0m 0.04985 \u001b[0m | \u001b[0m 343.9   \u001b[0m | \u001b[0m 0.9038  \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8031  \u001b[0m | \u001b[0m 0.9762  \u001b[0m | \u001b[0m 0.5895  \u001b[0m | \u001b[0m 0.1154  \u001b[0m | \u001b[0m 2.769   \u001b[0m | \u001b[0m 0.1651  \u001b[0m | \u001b[0m 28.82   \u001b[0m | \u001b[0m 1.58    \u001b[0m | \u001b[0m 0.04607 \u001b[0m | \u001b[0m 375.9   \u001b[0m | \u001b[0m 0.8075  \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7933  \u001b[0m | \u001b[0m 0.8863  \u001b[0m | \u001b[0m 0.6369  \u001b[0m | \u001b[0m 1.725   \u001b[0m | \u001b[0m 2.983   \u001b[0m | \u001b[0m 0.7284  \u001b[0m | \u001b[0m 28.4    \u001b[0m | \u001b[0m 1.643   \u001b[0m | \u001b[0m 0.001167\u001b[0m | \u001b[0m 358.3   \u001b[0m | \u001b[0m 0.6204  \u001b[0m |\n",
            "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.8057  \u001b[0m | \u001b[95m 0.8108  \u001b[0m | \u001b[95m 0.3121  \u001b[0m | \u001b[95m 0.1232  \u001b[0m | \u001b[95m 1.61    \u001b[0m | \u001b[95m 0.02277 \u001b[0m | \u001b[95m 27.67   \u001b[0m | \u001b[95m 4.159   \u001b[0m | \u001b[95m 0.06194 \u001b[0m | \u001b[95m 200.2   \u001b[0m | \u001b[95m 0.934   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7882  \u001b[0m | \u001b[0m 0.8546  \u001b[0m | \u001b[0m 0.7823  \u001b[0m | \u001b[0m 0.1277  \u001b[0m | \u001b[0m 2.372   \u001b[0m | \u001b[0m 0.8389  \u001b[0m | \u001b[0m 11.13   \u001b[0m | \u001b[0m 1.017   \u001b[0m | \u001b[0m 0.0946  \u001b[0m | \u001b[0m 204.7   \u001b[0m | \u001b[0m 0.02694 \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7978  \u001b[0m | \u001b[0m 0.9494  \u001b[0m | \u001b[0m 0.1995  \u001b[0m | \u001b[0m 0.03031 \u001b[0m | \u001b[0m 2.68    \u001b[0m | \u001b[0m 0.3392  \u001b[0m | \u001b[0m 12.79   \u001b[0m | \u001b[0m 2.075   \u001b[0m | \u001b[0m 0.08149 \u001b[0m | \u001b[0m 397.3   \u001b[0m | \u001b[0m 0.9814  \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7992  \u001b[0m | \u001b[0m 0.9224  \u001b[0m | \u001b[0m 0.8273  \u001b[0m | \u001b[0m 0.03844 \u001b[0m | \u001b[0m 0.8039  \u001b[0m | \u001b[0m 0.119   \u001b[0m | \u001b[0m 11.08   \u001b[0m | \u001b[0m 1.892   \u001b[0m | \u001b[0m 0.03854 \u001b[0m | \u001b[0m 361.7   \u001b[0m | \u001b[0m 0.04842 \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8019  \u001b[0m | \u001b[0m 0.8108  \u001b[0m | \u001b[0m 0.5922  \u001b[0m | \u001b[0m 0.1038  \u001b[0m | \u001b[0m 2.769   \u001b[0m | \u001b[0m 0.1465  \u001b[0m | \u001b[0m 27.54   \u001b[0m | \u001b[0m 1.286   \u001b[0m | \u001b[0m 0.06818 \u001b[0m | \u001b[0m 203.5   \u001b[0m | \u001b[0m 0.7692  \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7988  \u001b[0m | \u001b[0m 0.8389  \u001b[0m | \u001b[0m 0.3271  \u001b[0m | \u001b[0m 0.8818  \u001b[0m | \u001b[0m 2.637   \u001b[0m | \u001b[0m 0.1268  \u001b[0m | \u001b[0m 28.0    \u001b[0m | \u001b[0m 9.637   \u001b[0m | \u001b[0m 0.07681 \u001b[0m | \u001b[0m 221.2   \u001b[0m | \u001b[0m 0.961   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8026  \u001b[0m | \u001b[0m 0.8858  \u001b[0m | \u001b[0m 0.6017  \u001b[0m | \u001b[0m 1.792   \u001b[0m | \u001b[0m 0.4368  \u001b[0m | \u001b[0m 0.05155 \u001b[0m | \u001b[0m 11.69   \u001b[0m | \u001b[0m 2.921   \u001b[0m | \u001b[0m 0.01387 \u001b[0m | \u001b[0m 310.3   \u001b[0m | \u001b[0m 0.9874  \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8028  \u001b[0m | \u001b[0m 0.9724  \u001b[0m | \u001b[0m 0.8873  \u001b[0m | \u001b[0m 1.994   \u001b[0m | \u001b[0m 2.947   \u001b[0m | \u001b[0m 0.5209  \u001b[0m | \u001b[0m 28.86   \u001b[0m | \u001b[0m 8.589   \u001b[0m | \u001b[0m 0.04304 \u001b[0m | \u001b[0m 200.2   \u001b[0m | \u001b[0m 0.4679  \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7965  \u001b[0m | \u001b[0m 0.8324  \u001b[0m | \u001b[0m 0.8653  \u001b[0m | \u001b[0m 0.2466  \u001b[0m | \u001b[0m 2.12    \u001b[0m | \u001b[0m 0.01249 \u001b[0m | \u001b[0m 28.68   \u001b[0m | \u001b[0m 8.569   \u001b[0m | \u001b[0m 0.09346 \u001b[0m | \u001b[0m 204.1   \u001b[0m | \u001b[0m 0.6297  \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7902  \u001b[0m | \u001b[0m 0.9959  \u001b[0m | \u001b[0m 0.729   \u001b[0m | \u001b[0m 0.2073  \u001b[0m | \u001b[0m 0.6942  \u001b[0m | \u001b[0m 0.63    \u001b[0m | \u001b[0m 23.53   \u001b[0m | \u001b[0m 2.953   \u001b[0m | \u001b[0m 0.008095\u001b[0m | \u001b[0m 200.7   \u001b[0m | \u001b[0m 0.9324  \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7986  \u001b[0m | \u001b[0m 0.8457  \u001b[0m | \u001b[0m 0.2587  \u001b[0m | \u001b[0m 1.331   \u001b[0m | \u001b[0m 2.914   \u001b[0m | \u001b[0m 0.07037 \u001b[0m | \u001b[0m 28.89   \u001b[0m | \u001b[0m 9.962   \u001b[0m | \u001b[0m 0.04441 \u001b[0m | \u001b[0m 298.3   \u001b[0m | \u001b[0m 0.9986  \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7992  \u001b[0m | \u001b[0m 0.9002  \u001b[0m | \u001b[0m 0.694   \u001b[0m | \u001b[0m 0.04374 \u001b[0m | \u001b[0m 2.135   \u001b[0m | \u001b[0m 0.3707  \u001b[0m | \u001b[0m 28.43   \u001b[0m | \u001b[0m 9.97    \u001b[0m | \u001b[0m 0.07603 \u001b[0m | \u001b[0m 398.9   \u001b[0m | \u001b[0m 0.9206  \u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8051  \u001b[0m | \u001b[0m 0.8793  \u001b[0m | \u001b[0m 0.3782  \u001b[0m | \u001b[0m 0.4311  \u001b[0m | \u001b[0m 0.1325  \u001b[0m | \u001b[0m 0.01984 \u001b[0m | \u001b[0m 27.76   \u001b[0m | \u001b[0m 1.53    \u001b[0m | \u001b[0m 0.03643 \u001b[0m | \u001b[0m 389.8   \u001b[0m | \u001b[0m 0.978   \u001b[0m |\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.802   \u001b[0m | \u001b[0m 0.9317  \u001b[0m | \u001b[0m 0.2895  \u001b[0m | \u001b[0m 0.4813  \u001b[0m | \u001b[0m 2.816   \u001b[0m | \u001b[0m 0.1962  \u001b[0m | \u001b[0m 13.53   \u001b[0m | \u001b[0m 1.121   \u001b[0m | \u001b[0m 0.08565 \u001b[0m | \u001b[0m 288.8   \u001b[0m | \u001b[0m 0.9525  \u001b[0m |\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7967  \u001b[0m | \u001b[0m 0.8193  \u001b[0m | \u001b[0m 0.1018  \u001b[0m | \u001b[0m 0.6268  \u001b[0m | \u001b[0m 0.7274  \u001b[0m | \u001b[0m 0.01538 \u001b[0m | \u001b[0m 14.22   \u001b[0m | \u001b[0m 1.231   \u001b[0m | \u001b[0m 0.07529 \u001b[0m | \u001b[0m 324.6   \u001b[0m | \u001b[0m 0.4077  \u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7928  \u001b[0m | \u001b[0m 0.8756  \u001b[0m | \u001b[0m 0.1265  \u001b[0m | \u001b[0m 1.216   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.2559  \u001b[0m | \u001b[0m 11.8    \u001b[0m | \u001b[0m 4.074   \u001b[0m | \u001b[0m 0.05437 \u001b[0m | \u001b[0m 248.7   \u001b[0m | \u001b[0m 0.6896  \u001b[0m |\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.8006  \u001b[0m | \u001b[0m 0.9527  \u001b[0m | \u001b[0m 0.3511  \u001b[0m | \u001b[0m 1.665   \u001b[0m | \u001b[0m 2.878   \u001b[0m | \u001b[0m 0.02773 \u001b[0m | \u001b[0m 15.18   \u001b[0m | \u001b[0m 9.364   \u001b[0m | \u001b[0m 0.06863 \u001b[0m | \u001b[0m 202.9   \u001b[0m | \u001b[0m 0.9259  \u001b[0m |\n",
            "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7971  \u001b[0m | \u001b[0m 0.8251  \u001b[0m | \u001b[0m 0.7476  \u001b[0m | \u001b[0m 0.1422  \u001b[0m | \u001b[0m 0.9539  \u001b[0m | \u001b[0m 0.2472  \u001b[0m | \u001b[0m 26.2    \u001b[0m | \u001b[0m 4.615   \u001b[0m | \u001b[0m 0.04418 \u001b[0m | \u001b[0m 387.4   \u001b[0m | \u001b[0m 0.3017  \u001b[0m |\n",
            "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.8019  \u001b[0m | \u001b[0m 0.8268  \u001b[0m | \u001b[0m 0.3459  \u001b[0m | \u001b[0m 0.5593  \u001b[0m | \u001b[0m 0.09394 \u001b[0m | \u001b[0m 0.2243  \u001b[0m | \u001b[0m 12.06   \u001b[0m | \u001b[0m 9.724   \u001b[0m | \u001b[0m 0.01021 \u001b[0m | \u001b[0m 377.3   \u001b[0m | \u001b[0m 0.9207  \u001b[0m |\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7986  \u001b[0m | \u001b[0m 0.8763  \u001b[0m | \u001b[0m 0.2064  \u001b[0m | \u001b[0m 1.761   \u001b[0m | \u001b[0m 2.848   \u001b[0m | \u001b[0m 0.1837  \u001b[0m | \u001b[0m 28.78   \u001b[0m | \u001b[0m 1.269   \u001b[0m | \u001b[0m 0.03412 \u001b[0m | \u001b[0m 217.7   \u001b[0m | \u001b[0m 0.2774  \u001b[0m |\n",
            "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.8033  \u001b[0m | \u001b[0m 0.9243  \u001b[0m | \u001b[0m 0.6202  \u001b[0m | \u001b[0m 1.317   \u001b[0m | \u001b[0m 2.512   \u001b[0m | \u001b[0m 0.06894 \u001b[0m | \u001b[0m 28.89   \u001b[0m | \u001b[0m 1.21    \u001b[0m | \u001b[0m 0.03454 \u001b[0m | \u001b[0m 269.0   \u001b[0m | \u001b[0m 0.6449  \u001b[0m |\n",
            "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.8019  \u001b[0m | \u001b[0m 0.8638  \u001b[0m | \u001b[0m 0.6505  \u001b[0m | \u001b[0m 1.366   \u001b[0m | \u001b[0m 0.6807  \u001b[0m | \u001b[0m 0.1546  \u001b[0m | \u001b[0m 11.09   \u001b[0m | \u001b[0m 9.848   \u001b[0m | \u001b[0m 0.09848 \u001b[0m | \u001b[0m 349.7   \u001b[0m | \u001b[0m 0.8367  \u001b[0m |\n",
            "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.857   \u001b[0m | \u001b[0m 0.2501  \u001b[0m | \u001b[0m 0.3541  \u001b[0m | \u001b[0m 2.96    \u001b[0m | \u001b[0m 0.2235  \u001b[0m | \u001b[0m 28.22   \u001b[0m | \u001b[0m 3.359   \u001b[0m | \u001b[0m 0.04908 \u001b[0m | \u001b[0m 200.2   \u001b[0m | \u001b[0m 0.8965  \u001b[0m |\n",
            "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.8008  \u001b[0m | \u001b[0m 0.866   \u001b[0m | \u001b[0m 0.7992  \u001b[0m | \u001b[0m 1.498   \u001b[0m | \u001b[0m 2.717   \u001b[0m | \u001b[0m 0.08873 \u001b[0m | \u001b[0m 11.04   \u001b[0m | \u001b[0m 8.636   \u001b[0m | \u001b[0m 0.04569 \u001b[0m | \u001b[0m 321.6   \u001b[0m | \u001b[0m 0.9951  \u001b[0m |\n",
            "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.7959  \u001b[0m | \u001b[0m 0.9314  \u001b[0m | \u001b[0m 0.7526  \u001b[0m | \u001b[0m 1.654   \u001b[0m | \u001b[0m 0.1667  \u001b[0m | \u001b[0m 0.3526  \u001b[0m | \u001b[0m 26.98   \u001b[0m | \u001b[0m 1.066   \u001b[0m | \u001b[0m 0.03762 \u001b[0m | \u001b[0m 397.6   \u001b[0m | \u001b[0m 0.9623  \u001b[0m |\n",
            "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.8039  \u001b[0m | \u001b[0m 0.9815  \u001b[0m | \u001b[0m 0.2147  \u001b[0m | \u001b[0m 0.03308 \u001b[0m | \u001b[0m 1.422   \u001b[0m | \u001b[0m 0.02066 \u001b[0m | \u001b[0m 15.25   \u001b[0m | \u001b[0m 4.945   \u001b[0m | \u001b[0m 0.06054 \u001b[0m | \u001b[0m 370.2   \u001b[0m | \u001b[0m 0.9057  \u001b[0m |\n",
            "=================================================================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSYap8cxHNev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "f1ea65bd-f3d3-4452-c061-2d849964aa1b"
      },
      "source": [
        "for i,n in optimizer.max[\"params\"].items():\n",
        "    print(i,int(round(n)))"
      ],
      "execution_count": 391,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bagging_fraction 1\n",
            "feature_fraction 0\n",
            "lambda_l1 0\n",
            "lambda_l2 2\n",
            "learning_rate 0\n",
            "max_depth 28\n",
            "min_child_weight 4\n",
            "min_split_gain 0\n",
            "num_leaves 200\n",
            "subsample 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_qUGTeO1tvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_params_lg = optimizer.max['params']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIX1IOCcPrf6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "5a68b06a-7e6d-4f6d-dead-dc9c1c059fb0"
      },
      "source": [
        "best_params_lg"
      ],
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bagging_fraction': 0.8107702943680453,\n",
              " 'feature_fraction': 0.3120764601708804,\n",
              " 'lambda_l1': 0.12317908037844316,\n",
              " 'lambda_l2': 1.6097828538878987,\n",
              " 'learning_rate': 0.02277060574675905,\n",
              " 'max_depth': 27.669031398264725,\n",
              " 'min_child_weight': 4.1587376841149295,\n",
              " 'min_split_gain': 0.061937534490027,\n",
              " 'num_leaves': 200.20128897290996,\n",
              " 'subsample': 0.9340330237928358}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMEPHDLcQ6zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_params_lg.update({'is_unbalance':'True','objective':'binary','metric':'auc'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmpZ51e_RSCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# best_params_lg['lambda_l1'] = 2\n",
        "# best_params_lg['lambda_l2']=3\n",
        "best_params_lg['max_depth']=27\n",
        "# best_params_lg['min_child_weight'] = 10\n",
        "best_params_lg['num_leaves']=200\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJtovzAURBHF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "1e533391-8170-48f9-fe6a-d4c0224738a7"
      },
      "source": [
        "lg_train = lgb.Dataset(x_train, label=y_train,free_raw_data = False)\n",
        "lg_valid = lgb.Dataset(x_val, label=y_val,free_raw_data = False)\n",
        "model_lg2 = lgb.train(best_params_lg, lg_train, num_boost_round=500, valid_sets=[lg_valid], categorical_feature=['DAYTYPE'], verbose_eval=100)"
      ],
      "execution_count": 421,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[100]\tvalid_0's auc: 0.831022\n",
            "[200]\tvalid_0's auc: 0.832525\n",
            "[300]\tvalid_0's auc: 0.830745\n",
            "[400]\tvalid_0's auc: 0.829665\n",
            "[500]\tvalid_0's auc: 0.828567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTc-Yi3-RNjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lg_pred = model_lg2.predict(x_val)\n",
        "lg_test = model_lg2.predict(test[x_train.columns])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7reXFTDERqWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tuned_pred = np.where(final_pred>0.37,1,0)\n",
        "# test_pred = np.where(test_pred>0.37,1,0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF08_SGHRe5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "d221fb17-7a1f-42ec-b879-6b912743552c"
      },
      "source": [
        "evaluate_model(tuned_pred)"
      ],
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONFUSION MATRIX\n",
            "True         0     1\n",
            "Predicted           \n",
            "0          276   128\n",
            "1          186  1510\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.60      0.64       462\n",
            "           1       0.89      0.92      0.91      1638\n",
            "\n",
            "    accuracy                           0.85      2100\n",
            "   macro avg       0.79      0.76      0.77      2100\n",
            "weighted avg       0.84      0.85      0.85      2100\n",
            "\n",
            "MATHEWS CORRELATION COEFFICIENT\n",
            "0.5457050345824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GOek05RDPuP",
        "colab_type": "text"
      },
      "source": [
        "RANDOMFOREST tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XwgEV3fDNUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_fold = 10\n",
        "folds = StratifiedKFold(n_splits=n_fold, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57EtlLu2CI-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def randomforest_evaluate(**params):\n",
        "    \n",
        "    params['n_estimators'] = int(round(params['n_estimators'],0))\n",
        "    params['min_samples_split'] = int(round(params['min_samples_split'],0))\n",
        "    params['min_samples_leaf'] = int(round(params['min_samples_leaf'],0))\n",
        "    params['bootstrap'] = int(round(params['bootstrap'],0))\n",
        "        \n",
        "    rfc_cv_score = cross_val_score(RandomForestClassifier(), x_train, y_train, cv=10, scoring='roc_auc')\n",
        "\n",
        "    return np.mean(rfc_cv_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0YHOeTvDgGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "b359f03e-eda6-41d1-efb2-047c58eefc83"
      },
      "source": [
        "rf_param_grid = {\n",
        "                 'max_depth' : (8,100),\n",
        "                 'n_estimators': (50,2000),\n",
        "                 'min_samples_split': (2,10),\n",
        "                 'min_samples_leaf': (2, 10),\n",
        "                 'bootstrap': (True, False),\n",
        "                 }\n",
        "\n",
        "rf_b_o = BayesianOptimization(randomforest_evaluate, rf_param_grid)\n",
        "rf_b_o.maximize(init_points=5, n_iter=20)"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | bootstrap | max_depth | min_sa... | min_sa... | n_esti... |\n",
            "-------------------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7853  \u001b[0m | \u001b[0m 0.7705  \u001b[0m | \u001b[0m 30.53   \u001b[0m | \u001b[0m 6.24    \u001b[0m | \u001b[0m 3.992   \u001b[0m | \u001b[0m 136.2   \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7836  \u001b[0m | \u001b[0m 0.7114  \u001b[0m | \u001b[0m 47.76   \u001b[0m | \u001b[0m 4.445   \u001b[0m | \u001b[0m 3.516   \u001b[0m | \u001b[0m 1.449e+0\u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.782   \u001b[0m | \u001b[0m 0.5043  \u001b[0m | \u001b[0m 85.6    \u001b[0m | \u001b[0m 5.475   \u001b[0m | \u001b[0m 9.326   \u001b[0m | \u001b[0m 1.35e+03\u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7836  \u001b[0m | \u001b[0m 0.1193  \u001b[0m | \u001b[0m 60.47   \u001b[0m | \u001b[0m 7.876   \u001b[0m | \u001b[0m 2.766   \u001b[0m | \u001b[0m 382.9   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7807  \u001b[0m | \u001b[0m 0.5229  \u001b[0m | \u001b[0m 38.9    \u001b[0m | \u001b[0m 3.805   \u001b[0m | \u001b[0m 5.145   \u001b[0m | \u001b[0m 766.0   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7829  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 8.882   \u001b[0m | \u001b[0m 9.638   \u001b[0m | \u001b[0m 3.383   \u001b[0m | \u001b[0m 1.998e+0\u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7837  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 10.09   \u001b[0m | \u001b[0m 2.736   \u001b[0m | \u001b[0m 5.646   \u001b[0m | \u001b[0m 58.23   \u001b[0m |\n",
            "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.7859  \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 99.64   \u001b[0m | \u001b[95m 7.553   \u001b[0m | \u001b[95m 3.88    \u001b[0m | \u001b[95m 64.36   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7831  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 98.54   \u001b[0m | \u001b[0m 4.203   \u001b[0m | \u001b[0m 7.108   \u001b[0m | \u001b[0m 51.86   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7832  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 10.1    \u001b[0m | \u001b[0m 6.63    \u001b[0m | \u001b[0m 4.022   \u001b[0m | \u001b[0m 52.9    \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7839  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 98.16   \u001b[0m | \u001b[0m 8.719   \u001b[0m | \u001b[0m 4.993   \u001b[0m | \u001b[0m 58.96   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7839  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 99.82   \u001b[0m | \u001b[0m 5.682   \u001b[0m | \u001b[0m 8.145   \u001b[0m | \u001b[0m 72.15   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7841  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 8.392   \u001b[0m | \u001b[0m 5.965   \u001b[0m | \u001b[0m 8.806   \u001b[0m | \u001b[0m 54.66   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7828  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 99.55   \u001b[0m | \u001b[0m 2.511   \u001b[0m | \u001b[0m 7.357   \u001b[0m | \u001b[0m 50.42   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7826  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 8.058   \u001b[0m | \u001b[0m 8.554   \u001b[0m | \u001b[0m 2.187   \u001b[0m | \u001b[0m 61.05   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7841  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 99.56   \u001b[0m | \u001b[0m 8.076   \u001b[0m | \u001b[0m 8.159   \u001b[0m | \u001b[0m 70.09   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7849  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 98.13   \u001b[0m | \u001b[0m 8.857   \u001b[0m | \u001b[0m 2.791   \u001b[0m | \u001b[0m 54.9    \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7848  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 98.9    \u001b[0m | \u001b[0m 9.251   \u001b[0m | \u001b[0m 6.252   \u001b[0m | \u001b[0m 54.4    \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7848  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 99.22   \u001b[0m | \u001b[0m 9.819   \u001b[0m | \u001b[0m 4.259   \u001b[0m | \u001b[0m 57.54   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.784   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 98.37   \u001b[0m | \u001b[0m 6.317   \u001b[0m | \u001b[0m 2.447   \u001b[0m | \u001b[0m 56.58   \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7837  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 99.28   \u001b[0m | \u001b[0m 3.251   \u001b[0m | \u001b[0m 5.562   \u001b[0m | \u001b[0m 57.16   \u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7819  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 97.56   \u001b[0m | \u001b[0m 6.331   \u001b[0m | \u001b[0m 9.259   \u001b[0m | \u001b[0m 50.1    \u001b[0m |\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7822  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 9.986   \u001b[0m | \u001b[0m 7.472   \u001b[0m | \u001b[0m 9.175   \u001b[0m | \u001b[0m 52.84   \u001b[0m |\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7845  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 97.87   \u001b[0m | \u001b[0m 9.554   \u001b[0m | \u001b[0m 3.337   \u001b[0m | \u001b[0m 1.995e+0\u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7834  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 98.35   \u001b[0m | \u001b[0m 7.931   \u001b[0m | \u001b[0m 3.025   \u001b[0m | \u001b[0m 1.992e+0\u001b[0m |\n",
            "=====================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0Mw87GZETZ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "8014e576-b42c-47a6-edb6-4dc8c5331ef7"
      },
      "source": [
        "for i,n in rf_b_o.max[\"params\"].items():\n",
        "    print(i,int(round(n)))"
      ],
      "execution_count": 386,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bootstrap 0\n",
            "max_depth 100\n",
            "min_samples_leaf 8\n",
            "min_samples_split 4\n",
            "n_estimators 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUYoP7rEE0Gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf=RandomForestClassifier(n_estimators=100,max_depth=100,min_samples_leaf=8,min_samples_split=4,class_weight='balanced')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EU3sqyHFFkU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "f0cd1236-524b-4a9e-b0e5-3883798f6fa5"
      },
      "source": [
        "rf.fit(x_train,y_train)"
      ],
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
              "                       criterion='gini', max_depth=100, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=8, min_samples_split=4,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE8vue1RGcHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_pred = rf.predict_proba(x_val)\n",
        "rf_test = rf.predict_proba(test[x_train.columns])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geRd2QKxJIYR",
        "colab_type": "text"
      },
      "source": [
        "XG BOOST tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iamwxqTTIQni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pbounds = {\n",
        "    'learning_rate': (0.01, 1.0),\n",
        "    'n_estimators': (100, 1000),\n",
        "    'max_depth': (3,10),\n",
        "    'subsample': (1.0, 1.0),  # Change for big datasets\n",
        "    'colsample': (1.0, 1.0),  # Change for datasets with lots of features\n",
        "    'gamma': (0, 5)}\n",
        "def xgboost_hyper_param(learning_rate,\n",
        "                        n_estimators,\n",
        "                        max_depth,\n",
        "                        subsample,\n",
        "                        colsample,\n",
        "                        gamma):\n",
        "    max_depth = int(max_depth)\n",
        "    n_estimators = int(n_estimators)\n",
        "    clf = XGBClassifier(\n",
        "        max_depth=max_depth,\n",
        "        learning_rate=learning_rate,\n",
        "        n_estimators=n_estimators,\n",
        "        gamma=gamma)\n",
        "    return np.mean(cross_val_score(clf, x_train, y_train, cv=5, scoring='roc_auc'))\n",
        "xg_optimizer = BayesianOptimization(\n",
        "    f=xgboost_hyper_param,\n",
        "    pbounds=pbounds,\n",
        "    random_state=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI06tuT4Ikc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "8e6f6914-5c8b-4692-e8cb-e23c5bcd870d"
      },
      "source": [
        "xg_optimizer.maximize(init_points=5, n_iter=20)"
      ],
      "execution_count": 399,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | colsample |   gamma   | learni... | max_depth | n_esti... | subsample |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7916  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.602   \u001b[0m | \u001b[0m 0.01011 \u001b[0m | \u001b[0m 5.116   \u001b[0m | \u001b[0m 232.1   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7971  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.728   \u001b[0m | \u001b[95m 0.4028  \u001b[0m | \u001b[95m 6.772   \u001b[0m | \u001b[95m 477.3   \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.8032  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 4.391   \u001b[0m | \u001b[95m 0.03711 \u001b[0m | \u001b[95m 7.693   \u001b[0m | \u001b[95m 475.6   \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7798  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9905  \u001b[0m | \u001b[0m 0.8027  \u001b[0m | \u001b[0m 9.778   \u001b[0m | \u001b[0m 382.1   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7972  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.473   \u001b[0m | \u001b[0m 0.09419 \u001b[0m | \u001b[0m 3.273   \u001b[0m | \u001b[0m 252.8   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8002  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.101   \u001b[0m | \u001b[0m 0.118   \u001b[0m | \u001b[0m 4.852   \u001b[0m | \u001b[0m 999.9   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7975  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.843   \u001b[0m | \u001b[0m 0.2855  \u001b[0m | \u001b[0m 3.057   \u001b[0m | \u001b[0m 783.1   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7952  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.739   \u001b[0m | \u001b[0m 0.8075  \u001b[0m | \u001b[0m 3.961   \u001b[0m | \u001b[0m 100.8   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7926  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.973   \u001b[0m | \u001b[0m 0.6737  \u001b[0m | \u001b[0m 3.421   \u001b[0m | \u001b[0m 630.6   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7945  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.873   \u001b[0m | \u001b[0m 0.5638  \u001b[0m | \u001b[0m 3.132   \u001b[0m | \u001b[0m 913.9   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7941  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.914   \u001b[0m | \u001b[0m 0.8589  \u001b[0m | \u001b[0m 3.101   \u001b[0m | \u001b[0m 450.7   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7941  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.646   \u001b[0m | \u001b[0m 0.8734  \u001b[0m | \u001b[0m 9.865   \u001b[0m | \u001b[0m 830.4   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7984  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.795   \u001b[0m | \u001b[0m 0.4419  \u001b[0m | \u001b[0m 9.763   \u001b[0m | \u001b[0m 532.6   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7895  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.34    \u001b[0m | \u001b[0m 0.5068  \u001b[0m | \u001b[0m 9.993   \u001b[0m | \u001b[0m 712.5   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.793   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.824   \u001b[0m | \u001b[0m 0.8667  \u001b[0m | \u001b[0m 9.977   \u001b[0m | \u001b[0m 278.8   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.79    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01422 \u001b[0m | \u001b[0m 0.08229 \u001b[0m | \u001b[0m 4.042   \u001b[0m | \u001b[0m 998.7   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7999  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.491   \u001b[0m | \u001b[0m 0.1636  \u001b[0m | \u001b[0m 9.763   \u001b[0m | \u001b[0m 996.3   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7977  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.766   \u001b[0m | \u001b[0m 0.07937 \u001b[0m | \u001b[0m 3.132   \u001b[0m | \u001b[0m 489.9   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7854  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.983   \u001b[0m | \u001b[0m 0.9437  \u001b[0m | \u001b[0m 9.974   \u001b[0m | \u001b[0m 477.5   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7975  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.3215  \u001b[0m | \u001b[0m 0.04051 \u001b[0m | \u001b[0m 3.928   \u001b[0m | \u001b[0m 144.6   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7863  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2053  \u001b[0m | \u001b[0m 0.09029 \u001b[0m | \u001b[0m 9.765   \u001b[0m | \u001b[0m 591.5   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7853  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.04443 \u001b[0m | \u001b[0m 0.2366  \u001b[0m | \u001b[0m 8.16    \u001b[0m | \u001b[0m 101.6   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7953  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.246   \u001b[0m | \u001b[0m 0.1737  \u001b[0m | \u001b[0m 3.381   \u001b[0m | \u001b[0m 319.1   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[95m 24      \u001b[0m | \u001b[95m 0.8035  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 4.86    \u001b[0m | \u001b[95m 0.1299  \u001b[0m | \u001b[95m 9.908   \u001b[0m | \u001b[95m 135.8   \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7969  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.874   \u001b[0m | \u001b[0m 0.02891 \u001b[0m | \u001b[0m 3.024   \u001b[0m | \u001b[0m 871.4   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "=================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDAwm2qFMWUX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "0bab50d0-6140-4413-fa3b-b5c7daa857ab"
      },
      "source": [
        "xg_optimizer.max[\"params\"]"
      ],
      "execution_count": 402,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample': 1.0,\n",
              " 'gamma': 4.860461768880585,\n",
              " 'learning_rate': 0.1299205238072194,\n",
              " 'max_depth': 9.907886667805784,\n",
              " 'n_estimators': 135.81443205422912,\n",
              " 'subsample': 1.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 402
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoUpCz18I3Mp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "11d7b40a-a526-4c05-9fc0-3a550c4e2ced"
      },
      "source": [
        "for i,n in xg_optimizer.max[\"params\"].items():\n",
        "    print(i,int(round(n)))"
      ],
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "colsample 1\n",
            "gamma 5\n",
            "learning_rate 0\n",
            "max_depth 10\n",
            "n_estimators 136\n",
            "subsample 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYTR2zTiPOz1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "c1ab89de-5197-4de9-e958-30ab4d09f630"
      },
      "source": [
        "xg = XGBClassifier(class_weight='balanced', n_jobs=-1, learning_rate=0.12,\\\n",
        "                  gamma=5, colsample=5,max_depth=10,n_estimators=136,\\\n",
        "                  subsample=1, random_state=0)\n",
        "\n",
        "xg.fit(x_train,y_train)"
      ],
      "execution_count": 425,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',\n",
              "              colsample=5, colsample_bylevel=1, colsample_bynode=1,\n",
              "              colsample_bytree=1, gamma=5, learning_rate=0.12, max_delta_step=0,\n",
              "              max_depth=10, min_child_weight=1, missing=None, n_estimators=136,\n",
              "              n_jobs=-1, nthread=None, objective='binary:logistic',\n",
              "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "              seed=None, silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 425
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SROldUiUPzU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xg_pred = xg.predict_proba(x_val)\n",
        "xg_test = xg.predict_proba(test[x_train.columns])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDK_B6xiPXhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "3b6adc18-2d1b-4f60-ba42-1107d3d9b915"
      },
      "source": [
        "evaluate_model(xg.predict(x_val))"
      ],
      "execution_count": 426,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONFUSION MATRIX\n",
            "True         0     1\n",
            "Predicted           \n",
            "0          241    83\n",
            "1          221  1555\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.52      0.61       462\n",
            "           1       0.88      0.95      0.91      1638\n",
            "\n",
            "    accuracy                           0.86      2100\n",
            "   macro avg       0.81      0.74      0.76      2100\n",
            "weighted avg       0.85      0.86      0.85      2100\n",
            "\n",
            "MATHEWS CORRELATION COEFFICIENT\n",
            "0.5401077332122015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8tzMwJaG6GZ",
        "colab_type": "text"
      },
      "source": [
        "STACKING MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlvjSXYaNRzr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "1f444293-6a6c-47ab-8e53-c64d3c78c016"
      },
      "source": [
        "best_params_lg"
      ],
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bagging_fraction': 0.8107702943680453,\n",
              " 'feature_fraction': 0.3120764601708804,\n",
              " 'is_unbalance': 'True',\n",
              " 'lambda_l1': 0.12317908037844316,\n",
              " 'lambda_l2': 1.6097828538878987,\n",
              " 'learning_rate': 0.02277060574675905,\n",
              " 'max_depth': 27,\n",
              " 'metric': 'auc',\n",
              " 'min_child_weight': 4.1587376841149295,\n",
              " 'min_split_gain': 0.061937534490027,\n",
              " 'num_leaves': 200,\n",
              " 'objective': 'binary',\n",
              " 'subsample': 0.9340330237928358}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 410
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-3dvUr2GrIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install vecstack\n",
        "from vecstack import stacking\n",
        "models = [\n",
        "    lgb.LGBMClassifier(random_state=0, n_jobs=-1,bagging_fraction=0.8,\\\n",
        "                       feature_fraction=0.3, lambda_l1=0.12, lambda_l2=1.6,\\\n",
        "                       learning_rate=0.02, max_depth=27, min_child_weight=4.15, \\\n",
        "                       min_split_gain=0.06, num_leaves=300, subsample=0.9, \\\n",
        "                       is_unbalance=True, objective='binary', metric='auc'),\n",
        "        \n",
        "    RandomForestClassifier(n_estimators=100,max_depth=100,min_samples_leaf=8,\\\n",
        "                           min_samples_split=4,class_weight='balanced',\\\n",
        "                           random_state=0, n_jobs=-1),\n",
        "\n",
        "    XGBClassifier(class_weight='balanced', n_jobs=-1, learning_rate=0.12,\\\n",
        "                  gamma=5, colsample=5,max_depth=10,n_estimators=136,\\\n",
        "                  subsample=1, random_state=0)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1aBvBtjMxGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "e83db1cb-590b-4c02-c47a-5831ef2a996b"
      },
      "source": [
        "S_train, S_test = stacking(models,                   \n",
        "                           x_train, y_train, test[x_train.columns],   \n",
        "                           regression=False, \n",
        "                           mode='oof_pred_bag', \n",
        "                           needs_proba=False,\n",
        "                           save_dir=None, \n",
        "                           metric=accuracy_score, \n",
        "                           n_folds=4,\n",
        "                           stratified=True,\n",
        "                           shuffle=True,  \n",
        "                           random_state=0, verbose=2)"
      ],
      "execution_count": 611,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [2]\n",
            "metric:       [accuracy_score]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [3]\n",
            "\n",
            "model  0:     [LGBMClassifier]\n",
            "    fold  0:  [0.82952381]\n",
            "    fold  1:  [0.84619048]\n",
            "    fold  2:  [0.81000000]\n",
            "    fold  3:  [0.83000000]\n",
            "    ----\n",
            "    MEAN:     [0.82892857] + [0.01282348]\n",
            "    FULL:     [0.82892857]\n",
            "\n",
            "model  1:     [RandomForestClassifier]\n",
            "    fold  0:  [0.82142857]\n",
            "    fold  1:  [0.83476190]\n",
            "    fold  2:  [0.80476190]\n",
            "    fold  3:  [0.82619048]\n",
            "    ----\n",
            "    MEAN:     [0.82178571] + [0.01092842]\n",
            "    FULL:     [0.82178571]\n",
            "\n",
            "model  2:     [XGBClassifier]\n",
            "    fold  0:  [0.85333333]\n",
            "    fold  1:  [0.86000000]\n",
            "    fold  2:  [0.83238095]\n",
            "    fold  3:  [0.85619048]\n",
            "    ----\n",
            "    MEAN:     [0.85047619] + [0.01071164]\n",
            "    FULL:     [0.85047619]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouchHPcAM0X-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "level2_xg = XGBClassifier(class_weight='balanced', n_jobs=-1, learning_rate=0.12,\\\n",
        "                  gamma=5, colsample=5,max_depth=10,n_estimators=136,\\\n",
        "                  subsample=1, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUPJHUi1OLA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "67f7d32a-7429-421d-b974-8cbedcf557a1"
      },
      "source": [
        "level2_xg.fit(S_train,y_train)"
      ],
      "execution_count": 600,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',\n",
              "              colsample=5, colsample_bylevel=1, colsample_bynode=1,\n",
              "              colsample_bytree=1, gamma=5, learning_rate=0.12, max_delta_step=0,\n",
              "              max_depth=10, min_child_weight=1, missing=None, n_estimators=136,\n",
              "              n_jobs=-1, nthread=None, objective='binary:logistic',\n",
              "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "              seed=None, silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 600
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUgAgfx4ObLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm_test = level2_xg.predict_proba(S_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1lOkbaoer1m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "ba1fb703-87ab-460f-fd1d-82785354b7d1"
      },
      "source": [
        "evaluate_model(sm_test)"
      ],
      "execution_count": 591,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONFUSION MATRIX\n",
            "True         0     1\n",
            "Predicted           \n",
            "0          264    99\n",
            "1          198  1539\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.57      0.64       462\n",
            "           1       0.89      0.94      0.91      1638\n",
            "\n",
            "    accuracy                           0.86      2100\n",
            "   macro avg       0.81      0.76      0.78      2100\n",
            "weighted avg       0.85      0.86      0.85      2100\n",
            "\n",
            "MATHEWS CORRELATION COEFFICIENT\n",
            "0.5598043583239918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLenhM88acJb",
        "colab_type": "text"
      },
      "source": [
        "best result obtained for voting mechanism of results between lg, xg, rf and stacked model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwQYyVCaSqaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test['predictions'] = np.where((lg_res + xg_res + rf_res + sm_res)<2,0,1)\n",
        "test['predictions']  = np.where((lg_res + xg_res + rf_res + sm_res + cat_test)<3,0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqTF1BnTT03L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['predictions'] = test['predictions'].replace({0:'male',1:'female'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jndlrDlvUW9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "d57ae156-ba60-4e5e-809c-68d35f9b7b9c"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 608,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SESSION_ID</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>TIME_SPENT_MINS</th>\n",
              "      <th>STARTTIMEMONTH</th>\n",
              "      <th>STARTTIMEWEEK</th>\n",
              "      <th>STARTTIMEDAY</th>\n",
              "      <th>STARTTIMEDAYOFWEEK</th>\n",
              "      <th>STARTTIMEDAYOFYEAR</th>\n",
              "      <th>STARTTIMEIS_MONTH_END</th>\n",
              "      <th>STARTTIMEIS_MONTH_START</th>\n",
              "      <th>STARTTIMEIS_QUARTER_END</th>\n",
              "      <th>STARTTIMEIS_QUARTER_START</th>\n",
              "      <th>STARTTIMEIS_YEAR_END</th>\n",
              "      <th>STARTTIMEIS_YEAR_START</th>\n",
              "      <th>HOUR</th>\n",
              "      <th>DAYTYPE</th>\n",
              "      <th>VIEWED_PRODUCT_NOS</th>\n",
              "      <th>A00002_B00002_C00007</th>\n",
              "      <th>A00001_B00009_C00028</th>\n",
              "      <th>A00001_B00001_C00019</th>\n",
              "      <th>A00002_B00002_C00002</th>\n",
              "      <th>A00002_B00002_C00003</th>\n",
              "      <th>A00002_B00002</th>\n",
              "      <th>A00001_B00001</th>\n",
              "      <th>A00002_B00001</th>\n",
              "      <th>A00001_B00015</th>\n",
              "      <th>A00001_B00004</th>\n",
              "      <th>A00001_B00031</th>\n",
              "      <th>A00003_B00012</th>\n",
              "      <th>A00002_B00007</th>\n",
              "      <th>A00003_B00022</th>\n",
              "      <th>A00002_B00004</th>\n",
              "      <th>A00002_B00005</th>\n",
              "      <th>A00002_B00016</th>\n",
              "      <th>A00002_B00017</th>\n",
              "      <th>A00002</th>\n",
              "      <th>A00001</th>\n",
              "      <th>A00003</th>\n",
              "      <th>A00004</th>\n",
              "      <th>A00005</th>\n",
              "      <th>A00006</th>\n",
              "      <th>A00011</th>\n",
              "      <th>A00007</th>\n",
              "      <th>A00010</th>\n",
              "      <th>A00008</th>\n",
              "      <th>A00009</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u12112</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.068670</td>\n",
              "      <td>12</td>\n",
              "      <td>50</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>342</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.420167</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u19725</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.068670</td>\n",
              "      <td>12</td>\n",
              "      <td>51</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>353</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.420167</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u11795</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.068670</td>\n",
              "      <td>12</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>335</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.544021</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u22639</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.067002</td>\n",
              "      <td>12</td>\n",
              "      <td>50</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>342</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.912945</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>u18034</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.068670</td>\n",
              "      <td>12</td>\n",
              "      <td>51</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>349</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.149877</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  SESSION_ID GENDER  TIME_SPENT_MINS  ...  A00008  A00009  predictions\n",
              "0     u12112    NaN        -0.068670  ...       0       0       female\n",
              "1     u19725    NaN        -0.068670  ...       0       0       female\n",
              "2     u11795    NaN        -0.068670  ...       0       0       female\n",
              "3     u22639    NaN        -0.067002  ...       0       0       female\n",
              "4     u18034    NaN        -0.068670  ...       0       0       female\n",
              "\n",
              "[5 rows x 47 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 608
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ix5TYJdSuRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test[['SESSION_ID','predictions']].to_csv('sm_pred.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5tR8wmTOgbS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "c6be407f-1681-40f2-8623-07dd2b14dadc"
      },
      "source": [
        "evaluate_model(y_pred)"
      ],
      "execution_count": 597,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONFUSION MATRIX\n",
            "True         0     1\n",
            "Predicted           \n",
            "0          233    71\n",
            "1          229  1567\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.50      0.61       462\n",
            "           1       0.87      0.96      0.91      1638\n",
            "\n",
            "    accuracy                           0.86      2100\n",
            "   macro avg       0.82      0.73      0.76      2100\n",
            "weighted avg       0.85      0.86      0.85      2100\n",
            "\n",
            "MATHEWS CORRELATION COEFFICIENT\n",
            "0.5427168714513624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0a4FQq8OrCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "72aec8cb-0830-446b-ac85-bd4b9a45d182"
      },
      "source": [
        "lg_pred"
      ],
      "execution_count": 428,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9104567 , 0.73940987, 0.0507796 , ..., 0.25552808, 0.33899906,\n",
              "       0.73876276])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 428
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mquni7t6QRac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "d849cf19-3fcb-4382-cecf-b6d530e80dd5"
      },
      "source": [
        "xg_pred"
      ],
      "execution_count": 429,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08390027, 0.9160997 ],\n",
              "       [0.10532337, 0.8946766 ],\n",
              "       [0.8451674 , 0.15483259],\n",
              "       ...,\n",
              "       [0.33786446, 0.66213554],\n",
              "       [0.5354876 , 0.4645124 ],\n",
              "       [0.08146149, 0.9185385 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 429
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBov_Q3UQTKn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "ee6b12d0-b600-4727-bcab-5792245cff71"
      },
      "source": [
        "rf_pred"
      ],
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20450501, 0.79549499],\n",
              "       [0.30601134, 0.69398866],\n",
              "       [0.88815819, 0.11184181],\n",
              "       ...,\n",
              "       [0.7086513 , 0.2913487 ],\n",
              "       [0.56242315, 0.43757685],\n",
              "       [0.28621112, 0.71378888]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2flwJJLpQU99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96d7ecc8-ccf9-403a-ccba-6ae11d139c54"
      },
      "source": [
        "len(sm_pred)"
      ],
      "execution_count": 532,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 532
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHDnZHnxQhid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comb = (sm_test+rf_test+xg_test)/3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBsN9c44RJcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hm_comb = 3/((1/sm_test) + (1/rf_test) + (xg_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9E5Jo8QQ64-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "c91a782b-b85d-4364-cdec-5b0012e638ab"
      },
      "source": [
        "evaluate_model(np.argmax(hm_comb,axis=1))"
      ],
      "execution_count": 443,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONFUSION MATRIX\n",
            "True         0     1\n",
            "Predicted           \n",
            "0          276   134\n",
            "1          186  1504\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.60      0.63       462\n",
            "           1       0.89      0.92      0.90      1638\n",
            "\n",
            "    accuracy                           0.85      2100\n",
            "   macro avg       0.78      0.76      0.77      2100\n",
            "weighted avg       0.84      0.85      0.84      2100\n",
            "\n",
            "MATHEWS CORRELATION COEFFICIENT\n",
            "0.5388300243792542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3vjWWD6RCqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lg_res = np.where(lg_test<0.37,0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmKBxa7tR40g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xg_res = np.argmax(xg_test,axis=1)\n",
        "rf_res = np.argmax(rf_test,axis=1)\n",
        "sm_res = np.argmax(sm_test,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0VGiHciSHs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate_model(np.where((lg_res + xg_res + rf_res + sm_res + cat_test)<3,0,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFzojjHuSTB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}